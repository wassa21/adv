fr,en,es,tr,title,speaker,duration,tags
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Mon premier travail
était programmeuse informatique
											durant ma première année à l'université —
											quand j'étais adolescente.
									","
											So, I started my first job
as a computer programmer
											in my very first year of college —
											basically, as a teenager.
									","
											Empecé mi primer trabajo 
como programadora informática
											en mi primer año de universidad,
											básicamente, siendo aún adolescente.
									","
											Bilgisayar programcısı olarak 
ilk çalışmaya başladığımda
											üniversite birinci sınıftaydım,
											yani yeni yetme sayılırdım.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Peu après avoir commencé
à écrire des programmes en entreprise,
											un responsable de l'entreprise
est venu me voir
											et m'a murmuré :
											« Peut-il dire si je mens ? »
											Il n'y avait personne d'autre
dans la pièce.
									","
											Soon after I started working,
											writing software in a company,
											a manager who worked at the company
came down to where I was,
											and he whispered to me,
											""Can he tell if I'm lying?""
											There was nobody else in the room.
									","
											Poco después de empezar a trabajar,
											programando software en una empresa,
											un gerente que trabajaba en la compañía 
vino allí donde estaba yo,
											y me dijo al oído:
											""¿Puede decir ella si estoy mintiendo?""
											No había nadie más en la habitación.
									","
											Bir şirkette program yazma göreviyle
											işe girdikten kısa süre sonra
											şirkette çalışan bir müdür yanıma geldi
											ve fısıltıyla sordu:
											""Yalan söylediğimi anlayabilir mi?""
											Odada başka kimse yoktu.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											« Qui peut dire si vous mentez ?
Et pourquoi chuchotez-vous ? »
									","
											""Can who tell if you're lying?
And why are we whispering?""
									","
											""¿Puede ""quién"" decir si está mintiendo? 
¿Y por qué estamos susurrando?""
									","
											""Yalanı kim anlayabilir mi?
Ayrıca neden fısıldaşıyoruz?"" dedim.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Le responsable a pointé du doigt
l'ordinateur dans la pièce.
											« Peut-il dire si je mens ? »
											Ce responsable avait une aventure
avec la réceptionniste.
									","
											The manager pointed
at the computer in the room.
											""Can he tell if I'm lying?""
											Well, that manager was having
an affair with the receptionist.
									","
											El gerente señaló la computadora 
de la habitación.
											""¿Puede ella decir si estoy mintiendo?""
											Bueno, el gerente tenía 
una aventura con la recepcionista.
									","
											Müdür, odada bulunan bilgisayarı gösterdi.
											""Yalan söyleyip söylemediğimi anlar mı?""
											Bu müdür danışmada çalışan 
biriyle ilişki yaşıyordu.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Rires)
									","
											(Laughter)
									","
											(Risas)
									","
											(Gülüşmeler)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											J'étais toujours adolescente.
											J'ai lui ai murmuré-crié :
											« Oui, l'ordinateur peut dire
si vous mentez. »
									","
											And I was still a teenager.
											So I whisper-shouted back to him,
											""Yes, the computer can tell
if you're lying.""
									","
											Y yo todavía era adolescente.
											Por lo tanto, le susurro yo a él:
											""Sí, la computadora puede determinar 
si Ud. está mintiendo"".
									","
											Ben de yeni yetmeyim tabii.
											Fısıltıyla bağırır gibi cevap verdim:
											""Evet, yalan söylerseniz
bilgisayar anlar."" dedim.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Rires)
									","
											(Laughter)
									","
											(Risas)
									","
											(Gülüşmeler)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											J'ai rigolé, mais c'est de moi
qu'on peut se moquer.
											Il y a aujourd'hui
des systèmes informatiques
											qui peuvent repérer
les états émotionnels et les mensonges
											en traitant les informations
du visage humain.
											Les publicitaires et les gouvernements
sont très intéressés.
									","
											Well, I laughed, but actually,
the laugh's on me.
											Nowadays, there are computational systems
											that can suss out
emotional states and even lying
											from processing human faces.
											Advertisers and even governments
are very interested.
									","
											Bueno, me reí, pero, 
en realidad, me reía de mí.
											Hoy en día, existen sistemas informáticos
											que pueden detectar 
estados emocionales e incluso mentir
											a partir del procesamiento 
de rostros humanos.
											Los anunciantes, e incluso 
hay gobiernos muy interesados.
									","
											Gülüyordum ama aslında
gülünmesi gereken bendim.
											Günümüzde insan yüzlerini
											işlemden geçirerek ruh hâlini 
ve hatta yalan söylediğini
											tespit eden bilgisayar programları var.
											Reklamcılar, hatta devletler de
çok ilgi duyuyor.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											J'étais devenue programmeuse informatique
											car j'étais l'une de ces gamines
folles de maths et de sciences.
											Mais, en chemin, j'avais découvert
les armes nucléaires
											et je me sentais très concernée
par l'éthique de la science.
											J'étais troublée.
											Cependant, du fait
de circonstances familiales,
											je devais aussi commencer à travailler
aussi vite que possible.
											Je me suis dit :
« Choisis un domaine technique
											où tu peux avoir un emploi facilement
											et où je n'ai pas à gérer
des questions d'éthique difficiles. »
											J'ai donc choisi l'informatique.
									","
											I had become a computer programmer
											because I was one of those kids
crazy about math and science.
											But somewhere along the line
I'd learned about nuclear weapons,
											and I'd gotten really concerned
with the ethics of science.
											I was troubled.
											However, because of family circumstances,
											I also needed to start working
as soon as possible.
											So I thought to myself, hey,
let me pick a technical field
											where I can get a job easily
											and where I don't have to deal
with any troublesome questions of ethics.
											So I picked computers.
									","
											Me había convertido en 
programadora informática
											porque yo era una de esas chicas 
locas por las matemáticas y la ciencia.
											Pero también me había 
interesado por las armas nucleares,
											y había empezado a realmente a 
preocuparme por la ética de la ciencia.
											Yo estaba preocupada.
											Sin embargo, 
por circunstancias familiares,
											también debía empezar 
a trabajar lo antes posible.
											Así que me dije, bueno, 
vamos a elegir un campo técnico
											donde poder conseguir un trabajo fácil
											y donde no tenga que lidiar 
con preguntas molestas sobre ética.
											Así que elegí las computadoras.
									","
											Matematik ve fen bilgisini çok seven
											bir çocuk olduğum için
bilgisayar programcısı olmuştum.
											Fakat o sıralarda
nükleer silahlara dair bilgi edinmiş
											ve bilim etiğine de
çok ilgi duymaya başlamıştım.
											Sorunlarım vardı.
											Ne yazık ki ailevi durumlar yüzünden
											mümkün olduğu kadar çabuk
işe girmem gerekiyordu.
											Kendi kendime düşündüm;
kolaylıkla iş bulabileceğim
											teknik bir alan seçeyim ki
											sıkıcı etik problemlerle
uğraşmak zorunda kalmayayım dedim.
											Böylelikle bilgisayarı seçtim.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Rires)
									","
											(Laughter)
									","
											(Risas)
									","
											(Gülüşmeler)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Eh bien, ah ah ah !
On peut se moquer de moi.
											Aujourd'hui, les informaticiens
construisent des plateformes
											qui contrôlent chaque jour
ce que voient un milliard de personnes.
											Ils développent des voitures
pouvant décider qui écraser.
											Ils construisent même
des machines, des armes
											qui pourraient tuer
des êtres humains dans une guerre.
											Il y a de l'éthique partout.
									","
											Well, ha, ha, ha!
All the laughs are on me.
											Nowadays, computer scientists
are building platforms
											that control what a billion
people see every day.
											They're developing cars
that could decide who to run over.
											They're even building machines, weapons,
											that might kill human beings in war.
											It's ethics all the way down.
									","
											Bueno, ¡ja, ja, ja! 
Todas las risas a mi costa.
											Hoy en día, los informáticos 
construyen plataformas
											que controlan lo que millones 
de personas ven todos los días.
											Están desarrollando automóviles que 
podrían decidir a quién atropellar.
											Es más, están construyendo 
máquinas, armas,
											que podrían matar 
a seres humanos en la guerra.
											Esto es ética a fondo.
									","
											Ha, ha, ha!
Herkes bana gülüyordur.
											Günümüzde bilgisayar uzmanları
her gün milyarlarca insanın
											göreceği şeyleri kontrol eden
programlar kuruyor.
											Kime çarpacağına karar verebilecek
arabalar geliştiriyorlar.
											Savaşta insanları öldürecek türden
											makineler, silahlar bile geliştiriyorlar.
											Etik tamamen ortadan kalkıyor.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											L'intelligence artificielle est arrivée.
											Nous utilisons l'informatique
pour prendre toutes sortes de décisions,
											y compris de nouvelles décisions.
											Nous posons à l'informatique
											des questions auxquelles
il n'y a pas d'unique bonne réponse,
											qui sont subjectives,
											ouvertes et reposent sur des valeurs.
									","
											Machine intelligence is here.
											We're now using computation
to make all sort of decisions,
											but also new kinds of decisions.
											We're asking questions to computation
that have no single right answers,
											that are subjective
											and open-ended and value-laden.
									","
											La inteligencia artificial está aquí.
											Estamos usando la computación 
para tomar todo tipo de decisiones,
											además de nuevos tipos de decisiones.
											Planteamos preguntas a las computadoras 
que no tienen respuestas
											correctas individuales, 
por ser subjetivas
											e indefinidas y cargadas de valores.
									","
											Makine zekâsı işin içinde.
											Artık herhangi bir karar verirken
bilgisayar kullanıyoruz,
											üstelik yeni kararlar alırken bile.
											Bilgisayara tek bir doğru 
cevabı olmayan, öznel,
											açık uçlu ve değer yüklü
											sorular soruyoruz.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Nous posons des questions comme :
											« Qui devrait-on embaucher ? »
											« Quelles nouvelles de quel ami
devrait-on vous montrer ? »
											« Quel prisonnier
va probablement récidiver ? »
											« Quel nouvel objet ou film
devrait être recommandé aux gens ? »
									","
											We're asking questions like,
											""Who should the company hire?""
											""Which update from which friend
should you be shown?""
											""Which convict is more
likely to reoffend?""
											""Which news item or movie
should be recommended to people?""
									","
											Planteamos preguntas como:
											""¿A quién debe contratar la empresa?""
											""¿Qué actualización de qué amigo 
debe mostrarse?""
											""¿Qué convicto tiene 
más probabilidades de reincidir?""
											""¿Qué artículo de noticias o película 
se deben recomendar a la gente?""
									","
											Mesela şu gibi sorular:
											""Şirket kimi işe almalı?""
											""Hangi arkadaştan
hangi güncellemeyi görmelisiniz?""
											""Hangi mahkûm tekrar suç işlemeye yatkın?""
											""İnsanlara hangi haber ya da film 
tavsiye edilmeli?""
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Cela fait un certain temps
que nous utilisons des ordinateurs
											mais c'est différent.
											C'est un changement historique :
											car on ne peut pas utiliser l'informatique
pour des décisions si subjectives
											comme on utilise l'informatique
pour piloter un avion, construire un pont,
											aller sur la Lune.
											Les avions sont-ils plus sûrs ?
Un pont a-t-il bougé et est tombé ?
											Là, nous nous accordons
sur des repères assez clairs
											et les lois de la nature nous guident.
											Nous n'avons pas de tels ancres et repères
											pour les décisions
des affaires complexes humaines.
									","
											Look, yes, we've been using
computers for a while,
											but this is different.
											This is a historical twist,
											because we cannot anchor computation
for such subjective decisions
											the way we can anchor computation
for flying airplanes, building bridges,
											going to the moon.
											Are airplanes safer?
Did the bridge sway and fall?
											There, we have agreed-upon,
fairly clear benchmarks,
											and we have laws of nature to guide us.
											We have no such anchors and benchmarks
											for decisions in messy human affairs.
									","
											Miren, sí, hemos venido usando 
computadoras hace tiempo,
											pero esto es diferente.
											Se trata de un giro histórico,
											porque no podemos anclar el cálculo 
para este tipo de decisiones subjetivas
											como anclamos el cálculo para 
pilotar aviones, construir puentes
											o ir a la luna.
											¿Son los aviones más seguros? 
¿Se balanceó el puente y cayó?
											Ahí, hemos acordado puntos 
de referencia bastante claros,
											y tenemos leyes de 
la naturaleza que nos guían.
											Nosotros no tenemos tales anclas 
y puntos de referencia
											para las decisiones sobre cuestiones
humanas desordenadas.
									","
											Bakın, evet bir süredir bilgisayar
kullanıyoruz,
											ama bu farklı bir durum.
											Bu tarihi bir hata,
											çünkü böyle öznel kararlarda
bilgisayara güvenemeyiz,
											bilgisayara uçak uçurmada, 
köprü inşa etmede, aya gitmede
											güvendiğimiz gibi güvenemeyiz.
											Uçaklar daha güvenli mi?
Köprü sallanıp çöker miydi?
											Burada üzerinde anlaşılan, açık ölçütler 
ve bize yol gösteren doğa kanunları
											olduğu konusunda hemfikiriz.
											Karmaşık insan ilişkilerinde
karar verirken
											bu tür dayanak ve ölçütler yok.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Pour compliquer encore les choses,
nos logiciels gagnent en puissance
											mais sont aussi moins transparents
et plus complexes.
											Récemment, les dix dernières années,
											les algorithmes complexes
ont fait de grandes avancées.
											Ils peuvent reconnaître
les visages humains,
											déchiffrer l'écriture,
											détecter la fraude à la carte bancaire,
											bloquer le spam,
											traduire d'une langue à une autre,
											détecter les tumeurs en imagerie médicale,
											battre les humains aux échecs et au go.
									","
											To make things more complicated,
our software is getting more powerful,
											but it's also getting less
transparent and more complex.
											Recently, in the past decade,
											complex algorithms
have made great strides.
											They can recognize human faces.
											They can decipher handwriting.
											They can detect credit card fraud
											and block spam
											and they can translate between languages.
											They can detect tumors in medical imaging.
											They can beat humans in chess and Go.
									","
											Para complicar más las cosas, 
nuestro software es cada vez más potente,
											pero también es cada vez 
menos transparente y más complejo.
											Recientemente, en la última década,
											algunos algoritmos complejos 
han hecho grandes progresos.
											Pueden reconocer rostros humanos.
											Pueden descifrar la letra.
											Pueden detectar 
el fraude de tarjetas de crédito
											y bloquear el spam
											y pueden traducir a otros idiomas.
											Pueden detectar tumores 
en imágenes médicas.
											Puede vencer a los humanos 
en el ajedrez y en el Go.
									","
											İşleri daha çetrefilli hâle getirmek için
yazılımımız gittikçe güçleniyor,
											fakat aynı zamanda daha az şeffaflaşıp
daha karmaşık oluyor.
											Son on yıl içerisinde,
											kompleks algoritmalar
büyük aşamalar katetti.
											İnsan yüzlerini tanıyabiliyorlar.
											El yazılarını çözebiliyorlar.
											Kredi kartı dolandırıcılığını 
tespit edip
											spam postaları engelliyor
											ve diller arası çeviri yapabiliyorlar.
											Tıbbi görüntülemelerde tümörleri
teşhis edebiliyorlar.
											Go ve satrançta insanları yenebiliyorlar.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Beaucoup de ces progrès
découlent d'une méthode :
											« l'apprentissage de la machine ».
											Cette méthode est différente
de la programmation traditionnelle
											où l'on donne des instructions détaillées,
exactes, méticuleuses à l'ordinateur.
											Cela ressemble plus
à un système nourri de données,
											dont des données non structurées,
											comme celles générées
par notre vie numérique.
											Le système apprend
en parcourant ces données.
											Et aussi, c'est crucial,
											ces systèmes n'utilisent pas la logique
de la réponse unique.
											Ils ne produisent pas une seule réponse,
c'est plus probabiliste :
											« Celle-ci est probablement
plus proche de ce que vous cherchez. »
									","
											Much of this progress comes
from a method called ""machine learning.""
											Machine learning is different
than traditional programming,
											where you give the computer
detailed, exact, painstaking instructions.
											It's more like you take the system
and you feed it lots of data,
											including unstructured data,
											like the kind we generate
in our digital lives.
											And the system learns
by churning through this data.
											And also, crucially,
											these systems don't operate
under a single-answer logic.
											They don't produce a simple answer;
it's more probabilistic:
											""This one is probably more like
what you're looking for.""
									","
											Gran parte de este progreso viene de un 
método llamado ""aprendizaje automático"".
											El aprendizaje automático es 
diferente a la programación tradicional,
											donde se da al equipo instrucciones 
exactas, detalladas y meticulosas.
											Es como si uno alimentara el sistema 
con una gran cantidad de datos,
											incluyendo los datos no estructurados,
											como los que generamos 
en nuestras vidas digitales.
											Y el sistema aprende de esos datos.
											Y también, de manera crucial,
											estos sistemas no funcionan 
bajo una lógica de una sola respuesta.
											No producen una respuesta sencilla; 
es más probabilístico:
											""Esto es probablemente parecido 
a lo que estás buscando"".
									","
											Bu gelişmelerin çoğu ""makine öğrenimi""
denilen bir yöntemden geliyor.
											Makine öğrenimi, bilgisayara 
detaylı, doğru ve itinalı
											talimatlar verdiğiniz
geleneksel programlamadan farklıdır.
											Daha çok sistemi kavrayıp onu
dijital yaşamlarımızda ürettiğimiz türden
											yapısal olmayan veri dahil
											bir sürü veriyle desteklemeniz gibidir.
											Sistem bu bilgileri baştan sona
karıştırarak öğrenir.
											Ayrıca en önemlisi
											bu sistemlerin tek cevaplı 
mantıkla çalışmadığıdır.
											Tek bir cevap üretmezler,
daha çok olasılık vardır:
											""Belki de aradığınız şey bu olabilir.""
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											L'avantage est que cette méthode
est très puissante.
											Le chef de l'IA chez Google l'a appelée :
											« l'efficacité irraisonnable
des données ».
											L'inconvénient est :
											nous ne comprenons pas vraiment
ce que le système a appris.
											En fait, c'est sa force.
											C'est moins comme donner
des instructions à un ordinateur ;
											plus comme entraîner
une machine-chiot-créature
											que nous ne comprenons
ni ne contrôlons vraiment.
											Voilà notre problème.
											C'est un problème quand cette intelligence
artificielle comprend mal les choses.
											C'est aussi un problème
quand elle comprend les choses
											car on ne sait pas différencier
ces situations pour un problème subjectif.
											Nous ignorons ce que pense cette chose.
									","
											Now, the upside is:
this method is really powerful.
											The head of Google's AI systems called it,
											""the unreasonable effectiveness of data.""
											The downside is,
											we don't really understand
what the system learned.
											In fact, that's its power.
											This is less like giving
instructions to a computer;
											it's more like training
a puppy-machine-creature
											we don't really understand or control.
											So this is our problem.
											It's a problem when this artificial
intelligence system gets things wrong.
											It's also a problem
when it gets things right,
											because we don't even know which is which
when it's a subjective problem.
											We don't know what this thing is thinking.
									","
											La ventaja es que 
este método es muy potente.
											El jefe de sistemas de inteligencia 
artificial de Google lo llama:
											""la eficacia irrazonable de los datos"".
											La desventaja es que
											realmente no entendemos 
lo que aprendió el sistema.
											De hecho, ese es su poder.
											Esto no se parece a dar instrucciones 
a una computadora;
											se parece más a la formación 
de una criatura cachorro máquina
											que realmente no entendemos o controlamos.
											Así que este es nuestro problema;
un problema cuando el sistema
											de inteligencia artificial 
hace cosas erróneas.
											Es también un problema 
cuando hace bien las cosas,
											porque ni siquiera sabemos qué es qué 
cuando se trata de un problema subjetivo.
											No sabemos qué está pensando esta cosa.
									","
											Şimdi avantajı şu:
Bu yöntem gerçekten çok güçlüdür.
											Google'ın Yapay Zeka'sının dediği gibi
											""verinin akıl almaz etkinliği""dir.
											Dezavantajı ise,
											sistemin ne öğrendiğini
tam olarak anlamıyor olmamızdır.
											Aslında bu onun gücü.
											Bu, bir bilgisayara
talimat vermek gibi değildir;
											nasıl kontrol edeceğimizi bilmediğimiz
bir içecek sıkma makinesini
											çalıştırmak gibidir.
											Yani sorunumuz bu.
											Yapay zeka sistemi bir şeyleri
yanlış anladığında problem olur.
											Aynı zamanda doğru anladığında da
problem olur,
											çünkü öznel bir problem olduğunda
hangisinin hangisi olduğunu bilmiyoruz.
											Bu şeyin ne düşündüğünü bile bilmiyoruz.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Considérez un algorithme d'embauche —
											un système utilisé pour embaucher des gens
en utilisant l'apprentissage des machines.
											Un tel système aurait été entraîné
sur les données des employés
											et chargé de trouver et embaucher
											des gens similaires à ceux
les plus performants de l'entreprise.
											Cela semble bien.
											Une fois, j'ai assisté à une conférence
											qui réunissait responsables
des ressources humaines et des dirigeants,
											des gens de haut niveau,
											avec de tels systèmes d'embauche.
											Ils étaient très excités.
											Ils pensaient que cela rendrait l'embauche
plus objective, moins biaisée
											et donnerait plus de chances
aux femmes et minorités
											face à des responsables RH partiaux.
									","
											So, consider a hiring algorithm —
											a system used to hire people,
using machine-learning systems.
											Such a system would have been trained
on previous employees' data
											and instructed to find and hire
											people like the existing
high performers in the company.
											Sounds good.
											I once attended a conference
											that brought together
human resources managers and executives,
											high-level people,
											using such systems in hiring.
											They were super excited.
											They thought that this would make hiring
more objective, less biased,
											and give women
and minorities a better shot
											against biased human managers.
									","
											Por lo tanto, piensen en 
un algoritmo de contratación,
											un sistema usado para contratar, 
usa sistemas de aprendizaje automático.
											un sistema así habría sido entrenado 
con anteriores datos de empleados
											y tiene la instrucción 
de encontrar y contratar
											personas como las de alto rendimiento 
existentes en la empresa.
											Suena bien.
											Una vez asistí a una conferencia
											que reunió a los responsables 
de recursos humanos y ejecutivos,
											las personas de alto nivel,
											que usaban estos sistemas 
en la contratación.
											Estaban muy emocionados.
											Pensaban que esto haría la contratación 
más objetiva, menos tendenciosa,
											para dar a las mujeres y a las minorías 
mejores oportunidades
											contra los administradores 
humanos tendenciosos.
									","
											Şimdi, insanları işe almak için kullanılan
											makine öğrenimi sistemlerinden yararlanan
bir işe alım algoritma sistemi düşünün.
											Böyle bir sistem önceki 
çalışanların verilerine ayarlı
											ve şirketteki yüksek performansı olan
											çalışanlar gibi insanlar bulmaya ve 
işe almaya kurulmuş olmalı.
											İyi fikir.
											Bir keresinde bir konferansa katıldım,
											işe alımda bu sistemi kullanan
insan kaynakları uzmanları ile
											yöneticileri,
											üst düzey insanları buluşturuyordu.
											Çok heyecanlıydılar.
											Bu yöntemin işe alımı daha nesnel,
daha az ön yargılı yapacağını
											ve kadın ve azınlıkları ön yargılı 
insan kaynakları karşısında
											daha şanslı hâle getireceğini
düşünüyorlardı.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											L'embauche humaine est partiale.
											Je sais.
											Dans l'un de mes premiers postes
en tant que programmeuse,
											ma responsable directe
venait parfois me voir
											très tôt le matin
ou très tard l'après-midi
											et elle disait : « Zeinep,
allons déjeuner ! »
											L'heure étrange me laissait perplexe.
											Il est 16h, déjeuner ?
											J'étais fauchée, le déjeuner était gratuit
donc j'y allais toujours.
											Plus tard, j'ai réalisé
ce qu'il se passait.
											Mes responsables directs
n'avaient pas dit à leurs responsables
											qu'ils avaient embauché
pour un travail sérieux une adolescente
											qui portait un jeans
et des baskets au travail.
											Je faisais du bon travail
mais mon allure clochait,
											j'avais les mauvais âge et sexe.
									","
											And look — human hiring is biased.
											I know.
											I mean, in one of my early jobs
as a programmer,
											my immediate manager would sometimes
come down to where I was
											really early in the morning
or really late in the afternoon,
											and she'd say, ""Zeynep,
let's go to lunch!""
											I'd be puzzled by the weird timing.
											It's 4pm. Lunch?
											I was broke, so free lunch. I always went.
											I later realized what was happening.
											My immediate managers
had not confessed to their higher-ups
											that the programmer they hired
for a serious job was a teen girl
											who wore jeans and sneakers to work.
											I was doing a good job,
I just looked wrong
											and was the wrong age and gender.
									","
											La contratación humana es tendenciosa.
											Lo sé.
											Es decir, en uno de mis primeros 
trabajos como programadora,
											mi jefa a veces venía 
allí donde yo estaba
											muy temprano en la mañana 
o muy tarde por la tarde,
											y decía: ""Zeynep, ¡vayamos a comer!""
											Me dejaba perpleja por el 
momento extraño de preguntar.
											Son las 16. ¿Almuerzo?
											Estaba en la ruina, así que, 
ante un almuerzo gratis, siempre fui.
											Más tarde me di cuenta 
de lo que estaba ocurriendo.
											Mis jefes inmediatos no habían 
confesado a sus altos mandos
											que el programador contratado para 
un trabajo serio era una adolescente
											que llevaba pantalones vaqueros 
y zapatillas de deporte en el trabajo.
											Yo hacía un buen trabajo, 
solo que no encajaba
											por la edad y por el sexo equivocado.
									","
											İşe alımda ön yargılı davranılır.
											Biliyorum.
											Yani, programcı olarak çalıştığım ilk
işlerimden birinde
											ilk patronum bazen sabah çok erken ya da
											öğleden sonra çok geç saatlerde
yanıma gelir
											ve ""Zeynep, hadi yemeğe çıkalım!"" derdi.
											Garip zamanlamasına şaşırırdım.
											Saat dört. Öğle yemeği mi?
											Param yoktu, bedava öğle yemeği vardı.
Her zaman giderdim.
											Neler olduğunu daha sonraları anladım.
											Amirlerim kendi üst düzey müdürlerine
çok ciddi bir iş için
											işe aldıkları programcının 
kot pantolon ve spor ayakkabı giyen
											yeni yetme bir kız olduğunu
söylememişlerdi.
											İyi iş çıkarıyordum,
ama yanlış görünüyordum,
											yanlış yaşta ve cinsiyetteydim.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Embaucher d'une manière
aveugle à la couleur et au sexe
											me semble très bien.
											Mais avec ces systèmes,
c'est plus compliqué, voici pourquoi :
											actuellement, les systèmes informatiques
peuvent déduire beaucoup vous concernant
											grâce à vos miettes numériques,
											même si vous n'avez rien révélé.
											Ils peuvent déduire
votre orientation sexuelle,
											vos traits de personnalité,
											vos tendances politiques.
											Ils ont des pouvoirs prédictifs
ayant une exactitude élevée.
											Pour des choses
que vous n'avez pas révélées.
											C'est de la déduction.
									","
											So hiring in a gender- and race-blind way
											certainly sounds good to me.
											But with these systems,
it is more complicated, and here's why:
											Currently, computational systems
can infer all sorts of things about you
											from your digital crumbs,
											even if you have not
disclosed those things.
											They can infer your sexual orientation,
											your personality traits,
											your political leanings.
											They have predictive power
with high levels of accuracy.
											Remember — for things
you haven't even disclosed.
											This is inference.
									","
											Así que contratar a ciegas 
independiente del género y de la raza
											ciertamente me parece bien.
											Sin embargo, con estos sistemas, 
es más complicado, y he aquí por qué:
											Hoy los sistemas informáticos pueden 
deducir todo tipo de cosas sobre Uds.
											a partir de sus pistas digitales,
											incluso si no las han dado a conocer.
											Pueden inferir su orientación sexual,
											sus rasgos de personalidad,
											sus inclinaciones políticas.
											Tienen poder predictivo 
con altos niveles de precisión.
											Recuerden, por cosas que 
ni siquiera han dado a conocer.
											Esta es la inferencia.
									","
											Dolayısıyla cinsiyet ve ırk 
gözetilmeksizin işe alım
											bence kesinlikle iyi fikir.
											Ancak bu sistemlerle konu 
daha karmaşık oluyor, nedeni şu:
											Şimdilerde bilgisayar sistemleri
paylaşmadığınız şeyler bile olsa
											dijital kırıntılarınızdan
											hakkınızda birçok çıkarım yapabilir.
											Cinsel yöneliminizi,
											kişilik özelliklerinizi,
											siyasi görüşünüzü anlayabiliyor.
											Yüksek doğruluk oranlı öngörü güçleri var.
											Unutmayın - paylaşmadığınız
şeyleri bile.
											Bu, çıkarımda bulunmaktır.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											J'ai une amie qui a développé
de tels systèmes informatiques
											pour prévoir la probabilité
d'une dépression clinique ou post-partum
											grâce à vos médias sociaux.
											Les résultats sont impressionnants.
											Son système peut prévoir
les risques de dépression
											des mois avant l'apparition
de tout symptôme —
											des mois avant.
											Aucun symptôme mais une prédiction.
											Elle espère que cela sera utilisé
pour des interventions précoces, super !
											Mais mettez cela
dans le contexte de l'embauche.
									","
											I have a friend who developed
such computational systems
											to predict the likelihood
of clinical or postpartum depression
											from social media data.
											The results are impressive.
											Her system can predict
the likelihood of depression
											months before the onset of any symptoms —
											months before.
											No symptoms, there's prediction.
											She hopes it will be used
for early intervention. Great!
											But now put this in the context of hiring.
									","
											Tengo una amiga que desarrolló 
este tipo de sistemas informáticos
											para predecir la probabilidad 
de depresión clínica o posparto
											a partir de datos de medios sociales.
											Los resultados son impresionantes.
											Su sistema puede predecir 
la probabilidad de depresión
											meses antes de la aparición 
de cualquier síntoma,
											meses antes.
											No hay síntomas, sí hay predicción.
											Ella espera que se use para 
la intervención temprana. ¡Estupendo!
											Pero ahora pongan esto en el 
contexto de la contratación.
									","
											Sosyal medya verilerinden
klinik depresyon veya
											doğum sonrası depresyon ihtimalini
öngören sayısal sistemler geliştiren
											bir arkadaşım var.
											Sonuçlar etkileyici.
											Sistem depresyon ihtimalini
semptomların başlamasından
											aylar öncesinden öngörebiliyor,
											aylar öncesinden.
											Hiçbir semptom yok, ama öngörü var.
											Erken müdahalede
kullanılacağını umuyor. Muhteşem!
											Şimdi de bunu
işe alım kavramına uygulayın.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Lors de cette conférence
de responsables des ressources humaines,
											j'ai approché une responsable
d'une très grande entreprise
											et lui ai dit : « Et si, à votre insu,
											votre système éliminait les gens
avec de forts risques de dépression ?
											Ils ne sont pas en dépression
mais ont plus de risques pour l'avenir.
											Et s'il éliminait les femmes
ayant plus de chances d'être enceintes
											dans un ou deux ans
mais ne le sont pas actuellement ?
											Et s'il embauchait des gens agressifs
car c'est la culture de l'entreprise ? »
											On ne peut pas le dire en regardant
la répartition par sexe.
											Cela peut être équilibré.
											Puisque c'est de l'apprentissage
de la machine, non du code traditionnel,
											il n'y a pas de variables appelées
« plus de risques de dépression »,
											« plus de risques d'être enceinte »,
											« échelle d'agressivité d'un mec ».
											Non seulement vous ignorez
ce que votre système utilise pour choisir,
											mais vous ignorez où chercher.
											C'est une boîte noire.
											Elle a un pouvoir prédictif
mais vous ne le comprenez pas.
									","
											So at this human resources
managers conference,
											I approached a high-level manager
in a very large company,
											and I said to her, ""Look,
what if, unbeknownst to you,
											your system is weeding out people
with high future likelihood of depression?
											They're not depressed now,
just maybe in the future, more likely.
											What if it's weeding out women
more likely to be pregnant
											in the next year or two
but aren't pregnant now?
											What if it's hiring aggressive people
because that's your workplace culture?""
											You can't tell this by looking
at gender breakdowns.
											Those may be balanced.
											And since this is machine learning,
not traditional coding,
											there is no variable there
labeled ""higher risk of depression,""
											""higher risk of pregnancy,""
											""aggressive guy scale.""
											Not only do you not know
what your system is selecting on,
											you don't even know
where to begin to look.
											It's a black box.
											It has predictive power,
but you don't understand it.
									","
											Así que en esa conferencia 
de recursos humanos,
											me acerqué a una gerenta de alto nivel 
de una empresa muy grande,
											y le dije: ""Mira, ¿qué pasaría si, 
sin su conocimiento,
											el sistema elimina a las personas con 
alta probabilidad futura de la depresión?
											No están deprimidos ahora, solo 
quizá en el futuro, sea probable.
											¿Y si elimina a las mujeres con más 
probabilidades de estar embarazadas
											en el próximo año o dos, 
pero no está embarazada ahora?
											¿Y si contratamos a personas agresivas, 
porque esa es su cultura de trabajo?""
											No se puede saber esto 
mirando un desglose por sexos.
											Estos pueden ser equilibrados.
											Y como esto es aprendizaje automático, 
no la programación tradicional,
											no hay una variable etiquetada 
como ""mayor riesgo de depresión"",
											""mayor riesgo de embarazo"",
											""escala de chico agresivo"".
											Ud. no solo no sabe lo que 
su sistema selecciona,
											sino que ni siquiera sabe 
por dónde empezar a buscar.
											Es una caja negra.
											Tiene capacidad de predicción, 
pero uno no lo entiende.
									","
											Bu insan kaynakları
yöneticileri konferansında
											büyük bir şirketin 
üst düzey bir yöneticisiyle görüştüm.
											Ona, ""Peki sisteminiz size bildirmeden
											gelecekte yüksek depresyon ihtimali olan
insanları ayıklıyorsa?
											Şu an psikolojik bozuklukları yok,
ancak belki ileride olabilir.
											Peki şu an hamile olmayan ancak
gelecek bir ya da iki yıl içinde
											hamile kalma ihtimali olan 
kadınları ayıklıyorsa?
											İş yeri kültürünüz öyle olduğu için
agresif insanları işe alıyorsa?"" dedim.
											Bunu cinsiyet analizlerine bakarak 
anlayamazsınız.
											Dengelenmiş olabilirler.
											Ayrıca bu geleneksel kodlama değil
makine öğrenimi olduğu için
											""yüksek depresyon riski"",
""yüksek hamilelik riski"",
											""agresiflik ölçümü"" gibi
											etiket taşıyan değişkenler yok.
											Sadece sisteminizin neyi seçtiğini değil,
											nereden bakmaya başlayacağınızı
bile bilmiyorsunuz.
											Bir kara kutu.
											Tahmin gücüne sahip ancak
onu anlamıyorsunuz.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											J'ai demandé : « Quelle garantie avez-vous
											pour vous assurer que votre boîte noire
ne fait rien de louche ? »
											Elle m'a regardée comme
si je venais de l'insulter.
									","
											""What safeguards,"" I asked, ""do you have
											to make sure that your black box
isn't doing something shady?""
											She looked at me as if I had
just stepped on 10 puppy tails.
									","
											""¿Qué salvaguardia"", pregunté,
											""puede asegurar que la caja negra 
no hace algo perjudicial?""
											Ella me miró como si acabara 
de romper algo valioso.
									","
											""Ne güvenlikleri var?"" diye sordum,
""kara kutunuzun
											gizli bir şey yapmadığından
emin olmak için?""
											Kuyruğuna basmışım gibi bakakaldı.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Rires)
									","
											(Laughter)
									","
											(Risas)
									","
											(Gülüşmeler)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Elle m'a fixée et m'a dit :
											« Je ne veux rien entendre de plus. »
											Puis elle s'est tournée et est partie.
											Elle n'était pas impolie.
											C'était clairement du :
											« ce que j'ignore n'est pas mon problème,
allez-vous en, regard meurtrier ».
									","
											She stared at me and she said,
											""I don't want to hear
another word about this.""
											And she turned around and walked away.
											Mind you — she wasn't rude.
											It was clearly: what I don't know
isn't my problem, go away, death stare.
									","
											Me miró y dijo:
											""No quiero oír ni una palabra de esto"".
											Dio la vuelta y se alejó.
											Eso sí, ella no fue grosera.
											Era claramente: lo que no sé, no es 
mi problema, vete, encara la muerte.
									","
											Dik dik baktı ve
											""buna dair başka bir şey 
duymak istemiyorum."" dedi.
											Arkasını dönüp gitti.
											Gerçi kaba değildi.
											Açıklaması şu: Bilmediğim şey benim
sorunum değil, bas git, öldürücü bakış.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Rires)
									","
											(Laughter)
									","
											(Risas)
									","
											(Gülüşmeler)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Un tel système pourrait être moins biaisé
											que les responsables humains.
											Et il pourrait être monétairement censé.
											Mais il pourrait aussi mener
											à une fermeture du marché du travail
stable mais dissimulée
											pour les gens avec
plus de risques de dépression.
											Est-ce le genre de société
que nous voulons bâtir,
											sans même savoir que nous l'avons fait,
											car nous avons confié
la prise de décisions à des machines
											que nous ne comprenons pas vraiment ?
									","
											Look, such a system
may even be less biased
											than human managers in some ways.
											And it could make monetary sense.
											But it could also lead
											to a steady but stealthy
shutting out of the job market
											of people with higher risk of depression.
											Is this the kind of society
we want to build,
											without even knowing we've done this,
											because we turned decision-making
to machines we don't totally understand?
									","
											Un sistema de este tipo 
puede ser incluso menos sesgado
											que los administradores humanos 
en algunos aspectos.
											Y podría tener sentido monetario.
											Pero también podría llevar
											a un cierre constante pero sigiloso 
del mercado de trabajo
											a las personas 
con mayor riesgo de depresión.
											¿Es este el tipo de sociedad 
la que queremos construir,
											sin siquiera saber que lo hemos hecho,
											porque nos movemos en torno a decisiones 
de máquinas que no entendemos totalmente?
									","
											Bakın böyle bir sistem bazı açılardan
insan yöneticilerden
											daha az ön yargılı olabilir.
											Parasal anlam taşıyabilir.
											Ancak depresyon riski
											yüksek olan insanların iş piyasasına
istikrarlı ve gizli olarak girmesini
											engellemeye sebep olabilir.
											Ne yapmış olduğumuzu bile bilmeden 

											kurmak istediğimiz toplum modeli bu mu?
											Çünkü karar verme işini tam olarak
anlamadığımız makinelere bırakıyoruz.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Un autre problème :
											ces systèmes sont souvent entraînés
sur des données générées par nos actions,
											des empreintes humaines.
											Elles pourraient refléter nos préjugés
											et ces systèmes pourraient
apprendre nos préjugés,
											les amplifier
											et nous les retourner
											alors que nous nous disons :
											« Nous ne faisons que de l'informatique
neutre et objective. »
									","
											Another problem is this:
											these systems are often trained
on data generated by our actions,
											human imprints.
											Well, they could just be
reflecting our biases,
											and these systems
could be picking up on our biases
											and amplifying them
											and showing them back to us,
											while we're telling ourselves,
											""We're just doing objective,
neutral computation.""
									","
											Otro problema es el siguiente:
											estos sistemas son a menudo 
entrenados con datos generados
											por nuestras acciones, 
por huellas humanas.
											Podrían pues estar reflejando 
nuestros prejuicios,
											y estos sistemas podrían dar cuenta 
de nuestros prejuicios
											y la amplificación de ellos
											volviendo a nosotros,
											mientras que decimos:
											""Somos objetivos, es el cómputo neutral"".
									","
											Diğer bir problemse şu:
											Bu sistemler çoğunlukla bizim 
davranışlarımızla; insan izleri tarafından
											üretilen bilgilerle test edilir.
											Ön yargılarımızı yansıtıyor olabilirler.
											Bu sistemler ön yargılarımıza dönüp
											onları büyütüp
											bize tekrar gösteriyor olabilir,
											biz ise bu arada kendimize
											""Sadece nesnel, tarafsız hesap
yapıyoruz."" diyoruz.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Des chercheurs chez Google ont découvert
											qu'on a moins de chances de montrer
aux femmes plutôt qu'aux hommes
											des offres d'emploi avec un salaire élevé.
											Et chercher des noms afro-américains
											a plus de chances de retourner
											des publicités suggérant
un historique criminel,
											même quand il n'y en a pas.
											De tels préjugés cachés
et des algorithmes boîte noire
											qui sont parfois découverts
par les chercheurs, parfois non,
											peuvent avoir des conséquences
qui changent la vie.
									","
											Researchers found that on Google,
											women are less likely than men
to be shown job ads for high-paying jobs.
											And searching for African-American names
											is more likely to bring up ads
suggesting criminal history,
											even when there is none.
											Such hidden biases
and black-box algorithms
											that researchers uncover sometimes
but sometimes we don't know,
											can have life-altering consequences.
									","
											Los investigadores encontraron 
que en Google las mujeres tienen
											menos probabilidades que los hombres
											de que les aparezcan anuncios 
de trabajo bien remunerados.
											Y buscando nombres afroestadounidenses
											es más probable que aparezcan anuncios 
que sugieren antecedentes penales,
											incluso cuando no existan.
											Estos sesgos ocultos 
y algoritmos de la caja negra
											que descubren los investigadores 
a veces, pero a veces no,
											pueden tener consecuencias 
que cambian la vida.
									","
											Araştırmacılar Google'da
yüksek maaşlı iş ilanlarını
											kadınların görme ihtimalinin 
erkeklerden daha az olduğunu tespit etti.
											Afro-Amerikan isimleri araştırırken
											alakası olmasa bile 
sabıka geçmişi ile ilgili ilanları
											öne sürmesi daha muhtemeldir.
											Araştırmacıların bazen ortaya çıkardığı
ancak bazen bizim bilmediğimiz
											bu tür gizli ön yargıların ve
kara kutu algoritmalarının
											hayat değiştiren sonuçları var.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Dans le Wisconsin, un prévenu
a été condamné à 6 ans de prison
											pour avoir échappé à la police.
											Vous l'ignorez peut-être
											mais des algorithmes sont utilisés
pour les probations et les condamnations.
											Nous voulions savoir
comment ce score était calculé.
											C'est une boîte noire commerciale.
											L'entreprise a refusé que l'on conteste
son algorithme en audience publique.
											Mais ProPublica, une organisation
d'enquête, a audité cet algorithme
											avec des données publiques
											et a découvert
que les résultats étaient biaisés,
											que son pouvoir prédictif était mauvais,
à peine meilleur que la chance,
											et qu'il étiquetait les prévenus noirs
comme de futurs criminels
											avec un taux deux fois plus élevé
que pour les prévenus blancs.
									","
											In Wisconsin, a defendant
was sentenced to six years in prison
											for evading the police.
											You may not know this,
											but algorithms are increasingly used
in parole and sentencing decisions.
											He wanted to know:
How is this score calculated?
											It's a commercial black box.
											The company refused to have its algorithm
be challenged in open court.
											But ProPublica, an investigative
nonprofit, audited that very algorithm
											with what public data they could find,
											and found that its outcomes were biased
											and its predictive power
was dismal, barely better than chance,
											and it was wrongly labeling
black defendants as future criminals
											at twice the rate of white defendants.
									","
											En Wisconsin, un acusado 
fue condenado a seis años de prisión
											por escaparse de la policía.
											Quizá no lo sepan, pero los algoritmos 
se usan cada vez más
											en las decisiones de 
libertad condicional y de sentencia.
											El acusado quiso saber: 
¿Cómo se calcula la puntuación?
											Es una caja negra comercial.
											La empresa se negó a que se cuestionara 
su algoritmo en audiencia pública.
											Pero ProPublica, organización 
no lucrativa de investigación,
											auditó precisamente ese algoritmo
con los datos públicos que encontró,
											y descubrió que sus resultados 
estaban sesgados
											y su capacidad de predicción era pésima, 
apenas mejor que el azar,
											y se etiquetaban erróneamente 
acusados ​​negros como futuros criminales
											con una tasa del doble 
que a los acusados ​​blancos.
									","
											Wisconsin'de bir sanık,
altı yıl hapse mahkûm edildi,
											polisten kaçtığı için.
											Belki bilmiyorsunuzdur,
											algoritmaların şartlı tahliye ve ceza
kararlarında kullanımı giderek artıyor.
											Şunu öğrenmek istiyordu:
Bu sonuç nasıl hesaplanmıştı?
											Ticari bir kara kutu.
											Şirket, halka açık duruşmada
işlemlerinin sorgulanmasını reddetmişti.
											Kâr amacı gütmeyen araştırmacı kurum 
ProPublica, bu algoritmayı
											bulabildiği kamusal verilerle inceledi
											ve sonuçlarının ön yargılı olduğunu,
											öngörü gücününse kötü, olasılıktan
biraz iyi olduğunu
											ve siyahi sanıkları haksız yere 
beyaz sanıklardan iki kat fazla bir oranla
											geleceğin suçluları olarak 
etiketlediğini bulguladı.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Considérez ce cas :
											cette femme était en retard
pour récupérer sa filleule
											à une école du comté de Broward,
en Floride,
											elle courait dans la rue
avec une amie à elle.
											Elles ont repéré une bécane et un vélo
non attachés sur un porche
											et ont bêtement sauté dessus.
											Alors qu'elles partaient,
une femme est sortie et a dit :
											« Hey ! C'est la bécane de mon fils ! »
											Elles l'ont lâchée, sont parties
mais ont été arrêtées.
									","
											So, consider this case:
											This woman was late
picking up her godsister
											from a school in Broward County, Florida,
											running down the street
with a friend of hers.
											They spotted an unlocked kid's bike
and a scooter on a porch
											and foolishly jumped on it.
											As they were speeding off,
a woman came out and said,
											""Hey! That's my kid's bike!""
											They dropped it, they walked away,
but they were arrested.
									","
											Piensen en este caso:
											Esta mujer llegó tarde a 
recoger a la hija de su madrina
											de una escuela en 
el condado de Broward, Florida,
											iba corriendo por la calle con una amiga.
											Vieron la bicicleta de un niño sin candado
y una moto en un porche
											y tontamente saltó sobre ella.
											A medida que aceleraban, 
una mujer salió y dijo,
											""¡Eh, esa es la bicicleta de mi hijo!""
											Se bajaron, se alejaron, 
pero fueron detenidas.
									","
											Şu olayı göz önüne alın:
											Bu kadın, vaftiz kardeşini Florida'nın 
Broward bölgesindeki bir okuldan
											almaya geç kalmış,
											bir arkadaşıyla caddede ilerliyorlar.
											Verandada duran kilitsiz bir 
çocuk bisikleti ve bir kaydırak görüyor
											ve düşünmeden biniyorlar.
											Tam yola koyulacakken 
kadının biri çıkıyor ve
											""Hey! Bu benim çocuğumun 
bisikleti!"" diyor.
											Bırakıp gidiyorlar, ancak tutuklanıyorlar.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Elle avait tort, elle a été idiote
mais elle n'avait que 18 ans.
											Adolescente, elle avait commis
quelques méfaits.
											Pendant ce temps, cet homme a été arrêté
pour vol chez Home Depot —
											pour une valeur de 85$,
un crime mineur similaire.
											Mais il avait deux condamnations
pour vol à main armée.
											L'algorithme l'a considérée elle,
comme étant un risque important, pas lui.
											Deux ans plus tard, ProPublica a découvert
qu'elle n'avait pas récidivé.
											Son casier judiciaire compliquait
sa recherche d'emploi.
											Lui, d'un autre côté, avait récidivé
											et avait été condamné à 8 ans
pour un autre crime.
											Clairement, nous devons
auditer nos boîtes noires
											et ne pas leur laisser
ce genre de pouvoir incontrôlé.
									","
											She was wrong, she was foolish,
but she was also just 18.
											She had a couple of juvenile misdemeanors.
											Meanwhile, that man had been arrested
for shoplifting in Home Depot —
											85 dollars' worth of stuff,
a similar petty crime.
											But he had two prior
armed robbery convictions.
											But the algorithm scored her
as high risk, and not him.
											Two years later, ProPublica found
that she had not reoffended.
											It was just hard to get a job
for her with her record.
											He, on the other hand, did reoffend
											and is now serving an eight-year
prison term for a later crime.
											Clearly, we need to audit our black boxes
											and not have them have
this kind of unchecked power.
									","
											Estaba equivocada, fue una tontería, 
pero también tenía solo 18 años.
											Tenía un par de faltas menores.
											Mientras tanto, detenían al hombre 
por hurto en Home Depot,
											por un valor de USD 85, 
un delito menor similar.
											Pero él tenía dos condenas anteriores
por robo a mano armada.
											Sin embargo, el algoritmo la anotó 
a ella como de alto riesgo, y no a él.
											Dos años más tarde, ProPublica descubrió 
que ella no había vuelto a delinquir.
											Pero le era difícil conseguir un trabajo 
con sus antecedentes registrados.
											Él, por el contrario, era reincidente
											y ahora cumple una pena de ocho años 
de prisión por un delito posterior.
											Es evidente que necesitamos 
auditar nuestras cajas negras
											para no tener 
este tipo de poder sin control.
									","
											Haksızdı, aptalca davranmıştı,
ama henüz 18 yaşındaydı.
											Çocukken ciddi olmayan bir iki suç işlemişti.
											Bu arada, adam da Home Depot'da
hırsızlık yapmaktan tutuklanmıştı.
											85 dolar değerinde,
benzeri bir hafif suç.
											Ama öncesinde iki silahlı
soygun sabıkası vardı.
											Ancak algoritma, adamı değil
kadını yüksek riskli olarak işaretledi.
											İki yıl sonra ProPublica kadının
tekrar suç işlemediğini tespit etti.
											Sabıka puanıyla iş bulması çok zordu.
											Öte yandan adam tekrar suç işlemişti
											ve şimdi daha sonra işlediği bir suç
yüzünden sekiz yıllık hapis cezasında.
											Belli ki kara kutularımızı
kontrol etmemiz
											ve onlara böyle kontrolsüz güç
vermememiz gerekiyor.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Applaudissements)
									","
											(Applause)
									","
											(Aplausos)
									","
											(Alkışlar)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Les audits sont importants,
											mais ils ne résolvent pas
tous nos problèmes.
											Prenez le puissant algorithme
du fil d'actualités Facebook,
											celui qui classe tout
et décide quoi vous montrer
											des amis et des pages que vous suivez.
											Devrait-on vous montrer
une autre photo de bébé ?
									","
											Audits are great and important,
but they don't solve all our problems.
											Take Facebook's powerful
news feed algorithm —
											you know, the one that ranks everything
and decides what to show you
											from all the friends and pages you follow.
											Should you be shown another baby picture?
									","
											Las auditorías son grandes e importantes, 
pero no resuelven todos los problemas.
											Tomemos el potente algoritmo 
de noticias de Facebook,
											ese que sabe todo y decide qué mostrarles
											de las páginas de los amigos que siguen.
											¿Debería mostrarles otra imagen de bebé?
									","
											Kontroller önemli ve etkili,
ancak tüm sorunlarımızı çözmüyorlar.
											Facebook'un muhteşem
haber akışı algoritmasına bakın,
											yani takip ettiğiniz tüm arkadaşlarınız
ve sayfalardan her şeyi sıralayıp
											size ne göstereceğine 
karar veren algoritma.
											Başka bir bebek fotoğrafı görmeli misiniz?
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Rires)
									","
											(Laughter)
									","
											(Risas)
									","
											(Gülüşmeler)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Une note maussade d'une connaissance ?
											Une actualité importante mais dure ?
											Il n'y a pas de bonne réponse.
											Facebook optimise
pour vous engager envers le site :
											les j'aime, partages, commentaires.
									","
											A sullen note from an acquaintance?
											An important but difficult news item?
											There's no right answer.
											Facebook optimizes
for engagement on the site:
											likes, shares, comments.
									","
											¿Una nota deprimente de un conocido?
											¿Una noticia importante pero difícil?
											No hay una respuesta correcta.
											Facebook optimiza para 
que se participe en el sitio:
											con Me gusta, Compartir 
y con Comentarios.
									","
											Bir tanıdıktan somurtkan bir not?
											Önemli ama üzücü haberler?
											Doğru bir cevap yok.
											Facebook meşgul olacaklarınızı
en uygun hâle getiriyor:
											Beğeniler, paylaşımlar, yorumlar.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											En août 2014,
											des manifestations ont éclaté
à Ferguson, dans le Missouri,
											après qu'un adolescent afro-américain
a été tué par un officier de police blanc
											dans des circonstances douteuses.
											La nouvelle des manifestations remplissait
mon fil d'actualité Twitter non filtré
											mais n'était pas sur mon Facebook.
											Était-ce mes amis Facebook ?
											J'ai désactivé l'algorithme Facebook,
											ce qui est difficile car Facebook
veut vous faire passer
											sous le contrôle de l'algorithme,
											et j'ai vu que mes amis en parlaient.
											C'est juste que l'algorithme
ne me le montrait pas.
											Après des recherches, j'ai découvert
que le problème est répandu.
									","
											In August of 2014,
											protests broke out in Ferguson, Missouri,
											after the killing of an African-American
teenager by a white police officer,
											under murky circumstances.
											The news of the protests was all over
											my algorithmically
unfiltered Twitter feed,
											but nowhere on my Facebook.
											Was it my Facebook friends?
											I disabled Facebook's algorithm,
											which is hard because Facebook
keeps wanting to make you
											come under the algorithm's control,
											and saw that my friends
were talking about it.
											It's just that the algorithm
wasn't showing it to me.
											I researched this and found
this was a widespread problem.
									","
											En agosto de 2014,
											estallaron protestas 
en Ferguson, Missouri,
											tras la muerte de un adolescente 
afroestadounidense por un policía blanco,
											en circunstancias turbias.
											La noticia de las protestas llegaron
											en mi cuenta de Twitter 
algorítmicamente sin filtrar
											pero en ninguna parte en mi Facebook.
											¿Y qué pasaba con mis amigos de Facebook?
											Desactivé el algoritmo de Facebook,
											lo cual es difícil ya que Facebook 
quiere seguir manteniéndonos
											bajo el control del algoritmo,
											y vi que mis amigos 
estaban hablando de ello.
											Pero el algoritmo no me lo mostraba.
											He investigado esto y encontré 
que era un problema generalizado.
									","
											Ağustos 2014'te,
											Missouri, Ferguson'da
Afro-Amerikan bir gencin
											beyaz bir polis tarafından şüpheli 
bir şekilde öldürülmesi sonrası
											protestolar başladı.
											Protesto haberleri
											algoritmik olarak filtrelenmeyen
Twitter akışımda vardı
											ancak Facebook'ta hiçbir yerde yoktu.
											Facebook arkadaşlarım ne hâldeydi?
											Facebook'un algoritmasını 
devre dışı bıraktım,
											ki bu çok zordur, çünkü Facebook 
sizi algoritmanın
											kontrolü altında tutmak ister.
											Baktım ki arkadaşlarım da
bunu konuşuyor.
											Bunu bana göstermeyen
algoritmanın ta kendisiydi.
											Bunu araştırdım ve 
yaygın bir problem olduğunu gördüm.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											L'histoire de Ferguson
ne plaisait pas à l'algorithme.
											Ce n'était pas « aimable »,
qui allait cliquer sur « j'aime » ?
											Ce n'est même pas facile à commenter.
											Sans j'aime et commentaires,
											l'algorithme allait le montrer
à un nombre décroissant de gens,
											donc nous ne pouvions le voir.
											Cette semaine-là,
											Facebook a plutôt souligné ceci,
											le Ice Bucket Challenge.
											Cause méritante, lâcher d'eau glacée,
donner à une charité, très bien.
											Cela plaisait beaucoup à l'algorithme.
											La machine a pris
cette décision pour nous.
											Une conversation
très importante mais difficile
											aurait pu être étouffée
											si Facebook avait été le seul canal.
									","
											The story of Ferguson
wasn't algorithm-friendly.
											It's not ""likable.""
											Who's going to click on ""like?""
											It's not even easy to comment on.
											Without likes and comments,
											the algorithm was likely showing it
to even fewer people,
											so we didn't get to see this.
											Instead, that week,
											Facebook's algorithm highlighted this,
											which is the ALS Ice Bucket Challenge.
											Worthy cause; dump ice water,
donate to charity, fine.
											But it was super algorithm-friendly.
											The machine made this decision for us.
											A very important
but difficult conversation
											might have been smothered,
											had Facebook been the only channel.
									","
											La historia de Ferguson no era 
compatible con el algoritmo.
											No es ""gustable"".
											¿Quién va a hacer clic en ""Me gusta""?
											Ni siquiera es fácil de comentar.
											Sin Me gusta y sin comentarios,
											el algoritmo era probable de 
mostrarse a aún menos personas,
											así que no tuvimos 
oportunidad de ver esto.
											En cambio, esa semana,
											el algoritmo de Facebook destacó esto,
											el ALS que era 
el desafío del cubo de hielo.
											Noble causa; verter agua con hielo, 
donar a la caridad, bien.
											Esa causa era súper compatible 
con el algoritmo.
											La máquina tomó 
esta decisión por nosotros.
											Una conversación 
muy importante pero difícil
											podría haber sido silenciada
											si Facebook hubiese sido el único canal.
									","
											Ferguson haberi algoritma dostu değildi.
											""Beğenilebilir"" değildi.
											Kim ""beğen""e tıklayacaktı?
											Yorum yapılması bile kolay değildi.
											Beğeniler ve yorumlar olmayınca
											algoritma bunu daha az insana
gösteriyor olmalıydı,
											dolayısıyla görmüyorduk.
											Onun yerine, o hafta
											Facebook'un algoritması 
şunu ön plana çıkardı:
											ALS Buz Kovası Düellosu.
											İyi bir sebep; buzlu su dök,
bağış yap, tamam.
											Fakat süper algoritma dostuydu.
											Makine bu kararı bizim için almıştı.
											Facebook tek kanal olsaydı
çok önemli ancak
											etkili bir sohbet
											engellenmiş olabilirdi.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Finalement, ces systèmes
peuvent aussi avoir tort
											de façons qui ne ressemblent pas
aux systèmes humains.
											Vous souvenez-vous de Watson,
le système d'IA d'IBM
											qui a éliminé les participants humains
dans Jeopardy ?
											C'était un super joueur.
											Mais, pour la finale de Jeopardy,
on a posé cette question à Watson :
											« Le plus grand aéroport
ayant le nom d'un héros de 39-45,
											le second plus grand
pour une bataille de 39-45. »
									","
											Now, finally, these systems
can also be wrong
											in ways that don't resemble human systems.
											Do you guys remember Watson,
IBM's machine-intelligence system
											that wiped the floor
with human contestants on Jeopardy?
											It was a great player.
											But then, for Final Jeopardy,
Watson was asked this question:
											""Its largest airport is named
for a World War II hero,
											its second-largest
for a World War II battle.""
									","
											Ahora, por fin, estos sistemas 
pueden también equivocarse
											de formas que no se parecen a los humanos.
											¿Se acuerdan de Watson, el sistema 
de inteligencia artificial de IBM
											que arrasó con los concursantes 
humanos en Jeopardy?
											Fue un gran jugador.
											Pero entonces, para la final de Jeopardy, 
a Watson se le hizo esta pregunta:
											""Su mayor aeropuerto lleva el nombre 
de un héroe de la 2ª Guerra Mundial,
											la 2ª batalla más grande 
de la 2ª Guerra Mundial"".
									","
											Şimdi sonuç olarak bu sistemler
insan sistemlerine
											benzememesi bakımından da
yanlış olabilir.
											Watson'ı hatırlıyor musunuz?
IBM'in Riziko'da
											insan rakiplerini yenilgiye uğratan 
makine zekâsı sistemini?
											Harika bir oyuncuydu.
											Ancak o zaman, Riziko'nun finalinde
Watson'a şu soru soruldu:
											""En büyük havaalanı adını İkinci
Dünya Savaşı kahramanından alır,
											ikincisi İkinci Dünya Savaşı savaşından.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Signal sonore de fin)
									","
											(Hums Final Jeopardy music)
									","
											(Música final de Jeopardy)
									","
											(Final Riziko müziği çalar)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Chicago.
											Les deux humains avaient raison.
											Watson, par contre,
a répondu « Toronto » —
											à une question
sur les villes des États-Unis !
											L'impressionnant système
a aussi fait une erreur
											qu'un humain ne ferait jamais,
qu'un CE1 ne ferait jamais.
									","
											Chicago.
											The two humans got it right.
											Watson, on the other hand,
answered ""Toronto"" —
											for a US city category!
											The impressive system also made an error
											that a human would never make,
a second-grader wouldn't make.
									","
											Chicago.
											Los dos humanos lo hicieron bien.
											Watson, por otra parte, 
respondió ""Toronto""
											para una categoría de ciudad de EE.UU.
											El impresionante sistema 
también cometió un error
											que un humano nunca cometería, que
un estudiante de segundo grado tampoco.
									","
											Chicago.
											İki insan soruyu doğru anladı.
											Buna karşın Watson,
Birleşik Devletler şehri olarak
											""Toronto"" cevabını verdi.
											Bu etkileyici sistem
											bir insanın, ikinci sınıfa giden birinin
asla yapmayacağı bir hata yapmıştı.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Notre intelligence artificielle
peut échouer
											de façons ne correspondant pas
aux schémas d'erreurs humaines,
											de façons inattendues et imprévues.
											Il serait lamentable de ne pas obtenir
un emploi pour lequel on est qualifié
											mais ce serait pire si c'était à cause
d'un dépassement de pile
											dans une sous-routine.
									","
											Our machine intelligence can fail
											in ways that don't fit
error patterns of humans,
											in ways we won't expect
and be prepared for.
											It'd be lousy not to get a job
one is qualified for,
											but it would triple suck
if it was because of stack overflow
											in some subroutine.
									","
											La inteligencia artificial puede fallar
											en formas que no se ajustan a 
los patrones de error de los humanos,
											de maneras que no esperamos
y para las que no estamos preparados.
											Sería pésimo no conseguir trabajo, 
una vez que uno se cualifica para ello,
											pero sería el triple de pésimo 
si fue por un desbordamiento de pila
											en algunas subrutinas.
									","
											Makine zekâmız
											insanların hata şekline
uymayan şekilde,
											beklemediğimiz ve hazırlıksız olduğumuz
şekilde hata yapabilir.
											Kalifiye biri için işe alınmamak
kötü olabilirdi,
											fakat bu, bazı alt programlarda 
bellek dolu dediği için oluyorsa
											üç kat daha kötü olurdu.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Rires)
									","
											(Laughter)
									","
											(Risas)
									","
											(Gülüşmeler)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											En mai 2010,
											un crash éclair sur Wall Street
alimenté par une boucle de rétroaction
											dans un algorithme de vente de Wall Street
											a fait perdre mille milliards de dollars
en 36 minutes.
											Je refuse de penser
au sens du mot « erreur »
											dans le contexte des armes
mortelles autonomes.
									","
											In May of 2010,
											a flash crash on Wall Street
fueled by a feedback loop
											in Wall Street's ""sell"" algorithm
											wiped a trillion dollars
of value in 36 minutes.
											I don't even want to think
what ""error"" means
											in the context of lethal
autonomous weapons.
									","
											En mayo del 2010
											un flash crash de Wall Street alimentado 
por un circuito de retroalimentación
											por el algoritmo de ""venta"" de Wall Street
											borró un billón de dólares en 36 minutos.
											Yo no quiero ni pensar 
lo que significa ""error""
											en el contexto de 
las armas autónomas letales.
									","
											Mayıs 2010'da
											Wall Steet'te olan Wall Street'in
""satış"" algoritmalarını
											bir geri bildirim döngüsünün
körüklediği ani bir düşüş
											36 dakika içinde trilyon dolarları sildi.
											Ölümcül otonom silahlar bağlamında
											""hata yapmak"" ne demek bunu
düşünmek bile istemiyorum.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Oui, les humains
ont toujours été partiaux.
											Les preneurs de décision et gardiens,
											dans les tribunaux,
les actualités, en guerre...
											Ils font des erreurs ;
mais c'est de cela dont je parle.
											Nous ne pouvons pas échapper
à ces questions difficiles.
											Nous ne pouvons pas sous-traiter
nos responsabilités aux machines.
									","
											So yes, humans have always made biases.
											Decision makers and gatekeepers,
											in courts, in news, in war ...
											they make mistakes;
but that's exactly my point.
											We cannot escape
these difficult questions.
											We cannot outsource
our responsibilities to machines.
									","
											Los humanos siempre 
hemos tenido prejuicios.
											Los que toman decisiones y los guardias,
											en los tribunales, 
en la actualidad, en la guerra...
											cometen errores; pero ese 
es exactamente mi tema.
											No podemos escapar 
a estas preguntas difíciles.
											No podemos delegar nuestra
responsabilidad a las máquinas.
									","
											Evet, insanlar her zaman 
ön yargıda bulunur.
											Karar vericiler ve geçit deneticiler
											mahkemelerde, haberlerde, savaşlarda...
											Hata yaparlar; işte benim 
asıl dikkat çekmek istediğim bu.
											Bu zor sorulardan kaçamayız.
											Kendi sorumluluklarımızı 
makinelere yaptıramayız.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Applaudissements)
									","
											(Applause)
									","
											(Aplausos)
									","
											(Alkışlar)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											L'intelligence artificielle n'offre pas
une carte « sortie de l'éthique ».
									","
											Artificial intelligence does not give us
a ""Get out of ethics free"" card.
									","
											La inteligencia artificial 
no nos da una tarjeta libre de ética.
									","
											Yapay zekâ bize ""etikten kurtul geç""
kartı vermiyor.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Le scientifique des données Fred Benenson
qualifie cela de lavage des maths.
											Il nous faut l'opposé.
											Nous devons cultiver la suspicion,
le contrôle et l'enquête de l'algorithme.
											Nous devons nous assurer
de la responsabilité des algorithmes,
											les auditer et avoir
une transparence significative.
											Nous devons accepter
qu'apporter les maths et l'informatique
											dans les affaires humaines
désordonnées et basées sur des valeurs
											n'apporte pas l'objectivité
											mais plutôt que la complexité
des affaires humaines
											envahit les algorithmes.
											Nous devrions utiliser l'informatique
											pour prendre de meilleures décisions.
											Mais nous devons assumer
notre responsabilité morale de jugement
											et utiliser les algorithmes dans ce cadre,
											pas comme un moyen d'abdiquer
et sous-traiter nos responsabilités
											d'un humain à un autre.
									","
											Data scientist Fred Benenson
calls this math-washing.
											We need the opposite.
											We need to cultivate algorithm suspicion,
scrutiny and investigation.
											We need to make sure we have
algorithmic accountability,
											auditing and meaningful transparency.
											We need to accept
that bringing math and computation
											to messy, value-laden human affairs
											does not bring objectivity;
											rather, the complexity of human affairs
invades the algorithms.
											Yes, we can and we should use computation
											to help us make better decisions.
											But we have to own up
to our moral responsibility to judgment,
											and use algorithms within that framework,
											not as a means to abdicate
and outsource our responsibilities
											to one another as human to human.
									","
											El experto en datos Fred Benenson lo 
llama ""mathwashing"" o lavado matemático.
											Necesitamos lo contrario.
											Necesitamos fomentar un algoritmo 
de sospecha, escrutinio e investigación.
											Tenemos que asegurarnos de tener 
responsabilidad algorítmica,
											auditoría y transparencia significativa.
											Tenemos que aceptar que llevar 
las matemáticas y la computación
											a los asuntos humanos, 
desordenados y cargados de valores
											no conlleva a la objetividad;
											más bien, la complejidad de los asuntos 
humanos invaden los algoritmos.
											Sí, podemos y debemos 
usar la computación
											para ayudar a tomar mejores decisiones.
											Pero tenemos que apropiarnos de 
nuestra responsabilidad moral de juicio,
											y usar algoritmos dentro de ese marco,
											no como un medio para abdicar 
y delegar nuestras responsabilidades
											el uno al otro, como de humano a humano.
									","
											Veri uzmanı Fred Benenson 
buna matematiksel yıkama diyor.
											Tam tersine ihtiyacımız var.
											Algoritmayı şüphe, gözlem ve 
inceleme ile desteklemeliyiz.
											Algoritmik izlenebilirlik, denetim ve
											anlamlı şeffaflığımız olduğundan
emin olmamız gerek.
											Matematik ve programlamayı 
karmaşık, değer yüklü
											insani ilişkilere uygulamanın
											nesnellik getirmeyeceğini 
kabul etmemiz gerekiyor;
											aksine, insan ilişkilerinin karmaşıklığı
algoritmaları ele geçiriyor.
											Tabii ki daha iyi kararlar almamız için
bilgisayar kullanabiliriz,
											kullanmalıyız da.
											Ancak doğru karar vermek için, 
ahlaki sorumluluk alıp
											algoritmaları bu çerçevede 
kullanmak zorundayız,
											insan olarak birbirimize karşı olan
sorumluluklarımızı üstümüzden atıp
											dış kaynaktan temin etmenin 
bir yolu gibi görmemeliyiz.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											L'intelligence artificielle est arrivée.
											Cela signifie que nous devons
nous accrocher encore plus
											aux valeurs et éthiques humaines.
									","
											Machine intelligence is here.
											That means we must hold on ever tighter
											to human values and human ethics.
									","
											La inteligencia artificial está aquí.
											Eso significa que hay que 
ajustarla cada vez más
											a los valores humanos y a la ética humana.
									","
											Makine zekâsı işte böyledir.
											Bu demektir ki, insani değerlere ve etiğe
											hiç olmadığı kadar
sıkı sarılmamız gerekiyor.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											Merci.
									","
											Thank you.
									","
											Gracias.
									","
											Teşekkür ederim.
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
											(Applaudissements)
									","
											(Applause)
									","
											(Aplausos)
									","
											(Alkışlar)
									",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
"
","
","
","
",Machine intelligence makes human morals more important,Zeynep Tufekci,17:42,"AI,choice,computers,algorithm,data,humanity,decision-making,intelligence,machine learning,potential,morality,privacy,robots,society,science,software,technology"
