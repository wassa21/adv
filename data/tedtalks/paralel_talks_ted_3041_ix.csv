en,es,fr,de,title,speaker,duration,tags
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											I work with a bunch of mathematicians,
philosophers and computer scientists,
											and we sit around and think about
the future of machine intelligence,
											among other things.
											Some people think that some of these
things are sort of science fiction-y,
											far out there, crazy.
											But I like to say,
											okay, let's look at the modern
human condition.
											(Laughter)
											This is the normal way for things to be.
									","
											Yo trabajo con un grupo de matemáticos,
filósofos y científicos informáticos,
											y nos juntamos para pensar en
el futuro de la inteligencia artificial,
											entre otras cosas.
											Algunos piensan que estas cosas
son una especie de ciencia ficción
											alocadas y alejadas de la verdad.
											Pero bueno, me gusta sugerir
											que analicemos la 
condición humana moderna.
											(Risas)
											Así es cómo tienen que ser las cosas.
									","
											Je travaille avec des mathématiciens,
philosophes et informaticiens,
											et nous nous réunissons pour imaginer
le futur de l'intelligence artificielle,
											entre autres choses.
											Certains pensent que
c'est un peu de la science-fiction,
											complètement éloigné du réel.
											Mais j'aime dire,
											d'accord, jetons un coup d'oeil
à la condition humaine moderne.
											(Rires)
											C'est la façon normale d'être des choses.
									","
											Ich arbeite mit einigen Mathematikern,
Philosophen und Informatikern zusammen.
											Wir sitzen herum
											und denken z. B. über die Zukunft
der maschinellen Intelligenz nach.
											Manche Leute denken,
einiges davon sei sehr futuristisch,
											ausgefallen, einfach verrückt.
											Aber ich sage gern:
											Betrachten wir den Zustand
des modernen Menschen.
											(Gelächter)
											Das ist der normale Gang der Dinge.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											But if we think about it,
											we are actually recently arrived
guests on this planet,
											the human species.
											Think about if Earth
was created one year ago,
											the human species, then, 
would be 10 minutes old.
											The industrial era started
two seconds ago.
											Another way to look at this is to think of
world GDP over the last 10,000 years,
											I've actually taken the trouble
to plot this for you in a graph.

											It looks like this.
											(Laughter)
											It's a curious shape
for a normal condition.
											I sure wouldn't want to sit on it.
											(Laughter)
									","
											Pero si lo pensamos,
											en realidad acabamos de llegar
a este planeta,
											nosotros, la especie humana.
											Piensen que si la Tierra
hubiera sido creada hace un año,
											entonces la raza humana
solo tendría 10 minutos de edad
											y la era industrial habría empezado
hace dos segundos.
											Otra forma de abordar esto es pensar en
el PIB mundial en los últimos 10 000 años,
											y de hecho, me he tomado la molestia
de representarlo en un gráfico para Uds.
											Se ve así.
											(Risas)
											Tiene una forma curiosa para ser normal.
											Y seguro que no me gustaría
sentarme en ella.
											(Risas)
									","
											Mais si on y pense,
											nous ne sommes en fait que des invités
récemment arrivés sur cette planète,
											l'espèce humaine.
											Imaginez si la Terre 
avait été créée il y a un an,
											l'espèce humaine existerait alors
depuis dix minutes.
											L'ère industrielle a débuté
il y a deux secondes.
											Une autre façon de voir est de calculer
											le PIB mondial
des 10 000 dernières années.
											J'ai vraiment pris le temps
de faire un graphe pour vous.
											Il ressemble à ça.
											(Rires)
											Drôle de courbe
pour une condition normale.
											Je ne voudrais pas lui tourner le dos.
											(Rires)
									","
											Aber wenn wir darüber nachdenken,
											ist die menschliche Spezies erst
seit Kurzem Gast auf diesem Planeten.
											Denken Sie darüber nach:
											Wäre die Erde erst
vor einem Jahr erschaffen worden,
											dann wäre der Mensch erst 10 Minuten alt.
											Die industrielle Ära hätte
vor zwei Sekunden begonnen.
											Man könnte auch das Welt-BIP
der letzten 10.000 Jahre betrachten.
											Ich habe mir die Mühe gemacht,
dies für Sie grafisch darzustellen.
											Es sieht so aus.
											(Gelächter)
											Es ist eine seltsame Form
für einen Normalzustand.
											Ich würde nicht darauf sitzen wollen.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Let's ask ourselves, what is the cause
of this current anomaly?
											Some people would say it's technology.
											Now it's true, technology has accumulated
through human history,
											and right now, technology
advances extremely rapidly —
											that is the proximate cause,
											that's why we are currently 
so very productive.
											But I like to think back further 
to the ultimate cause.
									","
											Preguntémonos ¿cuál es la
causa de esta anomalía actual?
											Algunas personas dirán
que es la tecnología.
											Ahora bien es cierto que la tecnología
ha aumentado a lo largo de la historia,
											y en la actualidad avanza muy rápidamente
											—esa es la causa inmediata—
											y por esto la razón de ser
muy productivos hoy en día.
											Pero me gusta indagar más allá,
buscar la causa de todo.
									","
											Demandons-nous, quelle est la cause
de cette anomalie ?
											Certains diront que c'est la technologie.
											C'est vrai, la technologie s'est accumulée
au cours de l'histoire humaine,
											et aujourd'hui, la technologie
progresse très rapidement —
											c'est la cause la plus proche,
											c'est pourquoi nous sommes
si productifs de nos jours.
											Mais je préfère réfléchir en remontant 
à la cause fondamentale.
									","
											(Gelächter)
											Fragen wir uns:
											Was ist die Ursache
dieser aktuellen Anomalie?
											Manche Leute würden sagen,
dass es Technologie ist.
											Das ist richtig,
											Technologie hat sich 
im Laufe der Zeit angesammelt,
											und im Moment entwickelt sich 
die Technologie extrem schnell —
											das ist die unmittelbare Ursache, 
deshalb sind wir derzeit so produktiv.
											Aber ich denke gerne weiter 
an die ultimative Ursache.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Look at these two highly
distinguished gentlemen:
											We have Kanzi —
											he's mastered 200 lexical
tokens, an incredible feat.
											And Ed Witten unleashed the second
superstring revolution.
											If we look under the hood, 
this is what we find:
											basically the same thing.
											One is a little larger,
											it maybe also has a few tricks
in the exact way it's wired.
											These invisible differences cannot
be too complicated, however,
											because there have only
been 250,000 generations
											since our last common ancestor.
											We know that complicated mechanisms
take a long time to evolve.
											So a bunch of relatively minor changes
											take us from Kanzi to Witten,
											from broken-off tree branches
to intercontinental ballistic missiles.
									","
											Miren a estos 2 caballeros
muy distinguidos:
											Tenemos a Kanzi,
											que domina 200 unidades léxicas,
una hazaña increíble,
											y a Ed Witten que desató la segunda
revolución de las supercuerdas.
											Si miramos atentamente
esto es lo que encontramos:
											básicamente la misma cosa.
											Uno es un poco más grande,
											y puede que también tenga algunos trucos
más por la forma en que está diseñado,
											sin embargo, estas diferencias invisibles
no pueden ser demasiado complicadas
											porque solo nos separan
250 000 generaciones
											de nuestro último ancestro común.
											Sabemos que los mecanismos complicados
tardan mucho tiempo en evolucionar
											así que una serie de pequeños cambios
											nos lleva de Kanzi a Witten,
											de las ramas de árboles rotas a
los misiles balísticos intercontinentales.
									","
											Regardez ces deux messieurs
très distingués :
											Nous avons Kanzi —
											il maîtrise 200 symboles lexicaux,
un exploit incroyable.
											Et Ed Witten a déclenché
la seconde révolution des supercordes.
											Si nous regardons sous la capuche,
voici ce que l'on trouve :
											en gros, la même chose.
											L'un est un peu plus grand,
											il y a peut-être aussi quelques
subtilités de câblage.
											Ces différences invisibles ne peuvent
être trop compliquées quoi qu'il en soit,
											car il n'y a eu que
250 000 générations
											depuis notre dernier ancêtre commun.
											Nous savons que les mécanismes compliqués
demandent beaucoup de temps pour évoluer.
											Donc des changements relativement mineurs
											nous emmènent de Kanzi à Witten,
											de branches arrachées aux arbres aux
missiles balistiques intercontinentaux.
									","
											Schauen Sie sich diese zwei 
hoch angesehenen Herren an:
											Wir haben Kanzi —
											er hat 200 Begriffe gemeistert, 
eine unglaubliche Leistung.
											Und Ed Witten entfesselte 
die zweite Superstring-Revolution.
											Ein Blick unter die Haube zeigt das hier:
											im Grunde das Gleiche.
											Das eine ist etwas größer,
											es hat vielleicht auch ein paar Tricks 
in der Art, wie es verkabelt ist.
											Diese unsichtbaren Unterschiede können 
aber nicht allzu kompliziert sein,
											da es seit unserem letzten 
gemeinsamen Vorfahren
											nur 250.000 Generationen gab.
											Komplizierte Mechanismen brauchen
bekanntlich viel Zeit zur Entwicklung.
											So führen uns einige
relativ kleine Änderungen
											von Kanzi zu Witten,
											von abgebrochenen Ästen 
bis hin zu Interkontinentalraketen.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											So this then seems pretty obvious
that everything we've achieved,
											and everything we care about,
											depends crucially on some relatively minor
changes that made the human mind.
											And the corollary, of course,
is that any further changes
											that could significantly change
the substrate of thinking
											could have potentially 
enormous consequences.
									","
											Así que parece bastante claro
que todo lo que hemos logrado,
											y todo lo que nos importa,
											depende fundamentalmente de algunos 
cambios relativamente menores
											sufridos por la mente humana.
											Y el corolario es que, por supuesto,
cualquier cambio ulterior
											que cambiara significativamente
el fundamento del pensamiento
											podría potencialmente acarrear
enormes consecuencias.
									","
											Il semble alors assez évident
que tout ce que nous avons réalisé,
											et ce que nous chérissons,
											dépend principalement de quelques
changements mineurs
											qui ont aboutit à l'esprit humain.
											Le corollaire, bien sûr,
est que tout changement à venir
											qui pourrait changer significativement
le substrat de la pensée
											pourrait avoir potentiellement
d'énormes conséquences.
									","
											Es ist also ziemlich offensichtlich,
											dass all unsere Leistungen
und alles, was uns interessiert,
											entscheidend von einigen 
relativ kleinen Veränderungen abhängt,
											die den menschlichen Geist ausmachen.
											Die logische Folge ist natürlich,
											dass jede weitere Veränderung 
des Substrats des Denkens
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Some of my colleagues 
think we're on the verge
											of something that could cause
a profound change in that substrate,
											and that is machine superintelligence.
											Artificial intelligence used to be
about putting commands in a box.
											You would have human programmers
											that would painstakingly 
handcraft knowledge items.
											You build up these expert systems,
											and they were kind of useful 
for some purposes,
											but they were very brittle,
you couldn't scale them.
											Basically, you got out only
what you put in.
											But since then,
											a paradigm shift has taken place
in the field of artificial intelligence.
									","
											Algunos de mis colegas
piensan que estamos muy cerca
											de algo que podría causar un cambio 
significativo en ese fundamento
											y que eso es la máquina superinteligente.
											La inteligencia artificial solía ser
la integración de comandos en una caja,
											con programadores humanos
											que elaboraban conocimiento 
minuciosamente a mano.
											Se construían
estos sistemas especializados
											y eran bastante útiles
para ciertos propósitos,
											pero eran muy frágiles
y no se podían ampliar.
											Básicamente, se conseguía solamente
lo que se invertía en ellos.
											Pero desde entonces,
											hubo un cambio de paradigma en
el campo de la inteligencia artificial.
									","
											Certains de mes collègues
pensent que nous sommes sur le point
											de développer quelque chose qui pourrait
causer un tel changement dans ce substrat,
											et c'est la super
intelligence artificielle.
											Avant, l'intelligence artificielle consistait
à mettre des commandes dans une boîte.
											Il y avait des programmeurs humains
											qui fabriquaient minutieusement
des objets savants.
											On construisait ces systèmes experts,
											et ils étaient utiles
pour certains buts,
											mais ils étaient très fragiles,
on ne pouvait pas les agrandir.
											En gros, vous n'aviez que
ce que vous aviez mis dedans.
											Mais depuis,
											une révolution conceptuelle s'est opérée
dans le domaine de l'I.A..
									","
											enorme Konsequenzen haben könnte.
											Einige meiner Kollegen glauben,
dass wir kurz vor etwas stehen,
											was zu einer tiefgreifenden Veränderung
dieses Substrats führen könnte,
											und das ist Maschinen-Superintelligenz.
											Künstliche Intelligenz hieß,
Befehle in eine Box zu stecken.
											Menschliche Programmierer
bastelten mühsam Wissenselemente.
											Man baute Expertensysteme,
die für einige Zwecke nützlich waren,
											aber sie waren nicht skalierbar.
											Im Grunde bekam man nur heraus,
was man zuvor hineingebaut hatte.
											Aber seitdem gab es
einen Paradigmenwechsel
											im Bereich der künstlichen Intelligenz.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Today, the action is really 
around machine learning.
											So rather than handcrafting knowledge
representations and features,
											we create algorithms that learn,
often from raw perceptual data.
											Basically the same thing
that the human infant does.
											The result is A.I. that is not
limited to one domain —
											the same system can learn to translate 
between any pairs of languages,
											or learn to play any computer game
on the Atari console.
											Now of course,
											A.I. is still nowhere near having
the same powerful, cross-domain
											ability to learn and plan
as a human being has.
											The cortex still has some 
algorithmic tricks
											that we don't yet know
how to match in machines.
									","
											Hoy, la acción gira en torno
al aprendizaje máquina.
											Así que en lugar de 
producir características
											y representar el conocimiento
de manera artesanal,
											creamos algoritmos que aprenden a menudo 
a partir de datos de percepción en bruto.
											Básicamente lo mismo
que hace el bebé humano.
											El resultado es inteligencia artificial
que no se limita a un solo campo;
											el mismo sistema puede aprender
a traducir entre cualquier par de idiomas
											o aprender a jugar a cualquier juego
de ordenador en la consola Atari.
											Ahora, por supuesto,
											la IA está todavía muy lejos de tener el
mismo poder y alcance interdisciplinario
											para aprender y planificar
como lo hacen los humanos.
											La corteza cerebral aún esconde
algunos trucos algorítmicos
											que todavía no sabemos
cómo simular en las máquinas.
									","
											Aujourd'hui, l'action est centré sur
l'apprentissage machine.
											Plutôt que de coder à la main des
programmes et leurs caractéristiques,
											on crée des algorithmes qui apprennent,
											souvent à partir 
des données brutes perçues.
											En gros, la même chose que fait un enfant.
											Le résultat est une I.A.
qui n'est pas limitée à un domaine —
											le même système peut apprendre à traduire
n'importe quel couple de langues,
											ou apprendre à jouer n'importe quel jeu
sur la console Atari.
											Bien sûr,
											l'I.A. est toujours loin d'avoir
la capacité puissante et transversale
											à apprendre et planifier
d'un être humain.
											Le cortex a encore des
secrets algorithmiques
											que nous ne savons pas
intégrer dans les machines.
									","
											Heute geht alles um maschinelles Lernen.
											Anstatt Wissensrepräsentationen
und -eigenschaften manuell zu erstellen,
											erstellen wir Algorithmen, die oft 
aus rohen sensorischen Daten lernen.
											Genau das Gleiche, 
was das menschliche Kind tut.
											Das Ergebnis ist KI, die nicht 
auf eine Domäne beschränkt ist —
											das gleiche System kann lernen, 
beliebige Sprachpaare zu übersetzen,
											oder lernen, jedes Computerspiel 
auf der Atari-Konsole zu spielen.
											Natürlich hat KI noch nicht annähernd
die gleiche universelle Fähigkeit,
											zu lernen und zu planen 
wie ein menschliches Wesen.
											Der Kortex hat noch
einige algorithmische Tricks,
											von denen wir noch nicht wissen, 
wie wir sie in Maschinen abbilden sollen.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											So the question is,
											how far are we from being able
to match those tricks?
											A couple of years ago,
											we did a survey of some of the world's 
leading A.I. experts,
											to see what they think,
and one of the questions we asked was,
											""By which year do you think
there is a 50 percent probability
											that we will have achieved 
human-level machine intelligence?""
											We defined human-level here 
as the ability to perform
											almost any job at least as well
as an adult human,
											so real human-level, not just
within some limited domain.
											And the median answer was 2040 or 2050,
											depending on precisely which 
group of experts we asked.
											Now, it could happen much,
much later, or sooner,
											the truth is nobody really knows.
									","
											Así que la pregunta es,
											¿cuánto nos falta para poder
implementar esos trucos?
											Hace un par de años
											hicimos una encuesta entre los expertos
de IA más importantes del mundo
											para ver lo que piensan, y una
de las preguntas que hicimos fue,
											""¿En qué año crees que habrá
un 50 % de probabilidad en elevar
											la inteligencia artificial al mismo nivel
que la inteligencia humana?""
											Donde hemos definido ese nivel
como la capacidad de realizar
											casi todas las tareas, al menos así 
como las desarrolla un humano adulto,
											por lo cual, un nivel real no solo
dentro de un área limitada.
											Y la respuesta fue
alrededor de 2040 o 2050,
											dependiendo del grupo
de expertos consultados.
											Ahora, puede ocurrir
mucho más tarde o más temprano,
											la verdad es que nadie lo sabe realmente.
									","
											Donc la question est,
											combien de temps nous faudra-t-il
pour réussir à les intégrer ?
											Il y a quelques années,
											nous avons fait un sondage
auprès des experts mondiaux des I.A.,
											pour voir ce qu'ils pensaient,
et une des questions posées était,
											« En quelle année pensez-vous 
qu'il y aura 50% de chance
											qu'une I.A. atteigne le niveau
d'une intelligence humaine ? »
											Nous définissons ici le seuil à atteindre
par la capacité de l'I.A. à réaliser
											presque toutes les tâches
au moins aussi bien qu'un adulte,
											donc réellement comme un humain,
pas seulement dans un domaine limité.
											La réponse médiane était 2040 ou 2050,
											en fonction du groupe d'experts
que nous interrogions.
											Ça pourrait se produire
bien plus tard ou bien plus tôt,
											la vérité est que personne ne le sait.
									","
											Die Frage ist also:
											Wie weit sind wir in der Lage, 
diesen Tricks zu entsprechen?
											Vor ein paar Jahren
machten wir eine Umfrage
											unter einigen der weltweit
führenden KI-Experten,
											um zu sehen, was sie denken, 
und eine der Fragen war:
											""In welchem ​Jahr sehen Sie
eine 50 %-Wahrscheinlichkeit,
											dass wir maschinelle Intelligenz 
auf menschlicher Ebene erreicht haben?""
											Wir definierten hierbei
die menschliche Ebene als Fähigkeit,
											fast jeden Job mindestens so gut
wie ein erwachsener Mensch zu können,
											also die echte menschliche Ebene, 
nicht nur für einen Spezialbereich.
											Die mittlere Antwort war 2040 oder 2050,
											je nachdem, welche Gruppe 
von Experten wir fragten.
											Das könnte sehr viel später 
oder auch früher passieren,
											niemand weiß das wirklich.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											What we do know is that the ultimate 
limit to information processing
											in a machine substrate lies far outside 
the limits in biological tissue.
											This comes down to physics.
											A biological neuron fires, maybe, 
at 200 hertz, 200 times a second.
											But even a present-day transistor
operates at the Gigahertz.
											Neurons propagate slowly in axons,
100 meters per second, tops.
											But in computers, signals can travel
at the speed of light.
											There are also size limitations,
											like a human brain has 
to fit inside a cranium,
											but a computer can be the size
of a warehouse or larger.
											So the potential for superintelligence 
lies dormant in matter,
											much like the power of the atom 
lay dormant throughout human history,
											patiently waiting there until 1945.
											In this century,
											scientists may learn to awaken
the power of artificial intelligence.
											And I think we might then see
an intelligence explosion.
									","
											Lo que sí sabemos es que el umbral
en el procesamiento de información
											en una infraestructura artificial
											se encuentra mucho más allá de 
los límites del tejido biológico.
											Esto pertenece al campo de la física.
											Una neurona biológica manda impulsos
quizá a 200 Hertz, 200 veces por segundo.
											mientras que incluso hoy, un transistor
opera a la frecuencia de los gigahercios.
											Las neuronas propagan el impulso
lentamente a lo largo de los axones,
											a máximo 100 metros por segundo.
											Pero en las computadoras, las señales
pueden viajar a la velocidad de la luz.
											También hay limitaciones de tamaño,
											como el cerebro humano que tiene
que encajar dentro del cráneo,
											pero una computadora puede ser del 
tamaño de un almacén o aún más grande.
											Así que el potencial de 
la máquina superinteligente
											permanece latente en la materia,
											al igual que el poder atómico
a lo largo de toda la historia
											que esperó pacientemente hasta 1945.
											De cara a este siglo los científicos
pueden aprender a despertar
											el poder de la inteligencia artificial
											y creo que podríamos ser testigos
de una explosión de inteligencia.
									","
											Ce que nous savons est que la limite
de traitement de l'information
											dans une machine est bien supérieure
à celle d'un tissu biologique.
											Ça s'explique par la physique.
											Un neurone biologique ""décharge"" 
environ à 200 hertz, 200 fois par seconde.
											Mais, même un transistor actuel
fonctionne au gigahertz.
											L'information se propage dans les neurones
le long d'axones à 100 m/s maximum.
											Mais dans les ordinateurs, le signal
peut voyager à la vitesse de la lumière.
											Il y a aussi des limitations de taille,
											car le cerveau humain
doit rentrer dans la boîte crânienne,
											mais un ordinateur peut être 
de la taille d'un entrepôt ou plus grand.
											Donc le potentiel de super intelligence
est en sommeil dans la matière,
											tout comme la puissance de l'atome
est restée en sommeil
											tout au long de l'histoire humaine,
attendant patiemment jusqu'en 1945.
											Au cours de ce siècle, il se peut 
que les scientifiques apprennent
											à réveiller la puissance de l'I.A..
											Je pense que nous pourrions alors
assister à une explosion d'intelligence.
									","
											Wir wissen aber, dass die ultimative 
Grenze für die Informationsverarbeitung
											in einer Maschine weit jenseits der 
Grenzen des biologischen Gewebes liegt.
											Das liegt an der Physik.
											Ein biologisches Neuron
feuert mit etwa 200 Hertz,
											200-mal pro Sekunde.
											Aber sogar ein heutiger Transistor 
arbeitet mit 1 Gigahertz.
											Neuronen bewegen sich langsam in Axonen,
maximal 100 Meter pro Sekunde.
											Aber in Computern können sich Signale
mit Lichtgeschwindigkeit bewegen.
											Es gibt auch Größenbeschränkungen,
											weil ein menschliches Gehirn
in einen Schädel passen muss.
											Aber ein Computer kann so groß
wie ein Lagerhaus oder größer sein.
											Also ruht das Potential 
für Superintelligenz in der Materie,
											ähnlich wie die Kraft des Atoms
während der Menschheitsgeschichte ruhte
											und dort geduldig bis 1945 wartete.
											In diesem Jahrhundert
könnten Wissenschaftler lernen,
											die Kraft der künstlichen
Intelligenz zu wecken.
											Ich denke, wir könnten dann 
eine Intelligenzexplosion erleben.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Now most people, when they think
about what is smart and what is dumb,
											I think have in mind a picture
roughly like this.
											So at one end we have the village idiot,
											and then far over at the other side
											we have Ed Witten, or Albert Einstein,
or whoever your favorite guru is.
											But I think that from the point of view
of artificial intelligence,
											the true picture is actually
probably more like this:
											AI starts out at this point here,
at zero intelligence,
											and then, after many, many 
years of really hard work,
											maybe eventually we get to
mouse-level artificial intelligence,
											something that can navigate 
cluttered environments
											as well as a mouse can.
											And then, after many, many more years
of really hard work, lots of investment,
											maybe eventually we get to
chimpanzee-level artificial intelligence.
											And then, after even more years 
of really, really hard work,
											we get to village idiot 
artificial intelligence.
											And a few moments later, 
we are beyond Ed Witten.
											The train doesn't stop
at Humanville Station.
											It's likely, rather, to swoosh right by.
									","
											Cuando la mayoría de la gente piensa
en lo inteligente o lo tonto
											creo que tienen en mente
una imagen más o menos así.
											En un extremo tenemos 
al tonto del pueblo,
											y lejos en el otro extremo,
											tenemos a Ed Witten o a Albert Einstein,
o quien sea su gurú favorito.
											Pero creo que desde el punto de 
vista de la inteligencia artificial,
											lo más probable es que la imagen
real sea la siguiente:
											Se empieza en este punto aquí,
en ausencia de inteligencia
											y luego, después de muchos,
muchos años de trabajo muy arduo,
											quizá finalmente lleguemos
al nivel intelectual de un ratón,
											algo que puede navegar
entornos desordenados
											igual que un ratón.
											Y luego, después de muchos,
muchos más años
											de trabajo muy arduo,
de mucha inversión,
											tal vez alcancemos el nivel de 
inteligencia de un chimpancé.
											Y luego, después de más años
de trabajo muy, muy arduo
											alcancemos la inteligencia artificial
del tonto del pueblo.
											Un poco más tarde,
estaremos más allá de Ed Witten.
											El tren del progreso no se detiene
en la estación de los Humanos.
											Es probable que más bien,
pase volando.
									","
											La plupart des gens, quand ils pensent
à ce qui est bête ou intelligent
											ont une image de ce genre en tête.
											À une extrémité on a l'idiot du village,
											et à l'autre bout
											on a Ed Witten, ou Albert Einstein,
ou votre gourou, qui qu'il soit.
											Mais je pense que du point de vue
de l'intelligence artificielle,
											la véritable image est plus probablement
comme ceci, en réalité :
											l'I.A. commence à cet endroit,
à zéro intelligence,
											et ensuite, après de nombreuses
années de dur labeur,
											peut-être, arrivons-nous au niveau
de l'intelligence d'une souris,
											quelque chose qui peut naviguer
dans des environnements encombrés
											aussi bien qu'une souris.
											Ensuite, après encore plus d'années de
dur labeur et beaucoup d'investissements,
											peut-être, finalement, arrivons-nous
au niveau d'intelligence d'un chimpanzé.
											Ensuite, après toujours plus d'années
de vraiment très dur labeur,
											nous arrivons au niveau d'intelligence
de l'idiot du village.
											Et quelques mois plus tard,
nous sommes après Ed Witten.
											Le train ne s'arrête pas
à la station Humainville.
											Il va plutôt passer à fond devant.
									","
											Wenn die meisten Leute darüber nachdenken,
was schlau und was dumm ist,
											haben sie etwa dieses Bild vor Augen:
											An einem Ende haben wir den Dorftrottel,
											und weit entfernt am anderen Ende
haben wir Ed Witten oder Albert Einstein,
											oder wer auch immer Ihr Lieblingsguru ist.
											Aber ich denke, dass vom Standpunkt 
der künstlichen Intelligenz
											das wahre Bild wohl eher so aussieht:
											KI beginnt hier an diesem Punkt, 
bei null Intelligenz
											und nach sehr vielen Jahren 
wirklich harter Arbeit
											kommen wir vielleicht 
zur KI auf Mausebene,
											etwas, das durch ungeordnete Umgebungen
											navigieren kann wie eine Maus.
											Dann, nach noch viel mehr Jahren
wirklich harter Arbeit und viel Geld,
											kommen wir vielleicht irgendwann 
zur KI auf Schimpansen-Ebene.
											Nach noch mehr Jahren härtester Arbeit
											kommen wir zur Dorftrottel-KI.
											Und wenige Augenblicke später 
sind wir hinter Ed Witten.
											Der Zug endet nicht in Menschenhausen.
											Er wird wohl eher einfach durchrauschen.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Now this has profound implications,
											particularly when it comes 
to questions of power.
											For example, chimpanzees are strong —
											pound for pound, a chimpanzee is about
twice as strong as a fit human male.
											And yet, the fate of Kanzi 
and his pals depends a lot more
											on what we humans do than on
what the chimpanzees do themselves.
											Once there is superintelligence,
											the fate of humanity may depend
on what the superintelligence does.
											Think about it:
											Machine intelligence is the last invention
that humanity will ever need to make.
											Machines will then be better 
at inventing than we are,
											and they'll be doing so 
on digital timescales.
											What this means is basically
a telescoping of the future.
											Think of all the crazy technologies 
that you could have imagined
											maybe humans could have developed
in the fullness of time:
											cures for aging, space colonization,
											self-replicating nanobots or uploading
of minds into computers,
											all kinds of science fiction-y stuff
											that's nevertheless consistent 
with the laws of physics.
											All of this superintelligence could 
develop, and possibly quite rapidly.
									","
											Esto tiene profundas consecuencias,
											especialmente si se trata de poder.
											Por ejemplo, los chimpancés son fuertes.
											Un chimpancé es dos veces más fuerte
y en mejor forma física que un hombre
											y, sin embargo, el destino de Kanzi
y sus amigos depende mucho más
											de lo que hacemos los humanos
que de lo que ellos mismos hacen.
											Una vez que hay superinteligencia,
											el destino de la humanidad dependerá
de lo que haga la superinteligencia.
											Piensen en esto:
											la máquina inteligente
es el último invento
											que la humanidad jamás
tendrá que realizar.
											Las máquinas serán entonces
mejores inventores que nosotros,
											y lo harán a escala
de tiempo digital
											lo que significa básicamente
que acelerarán la cercanía al futuro.
											Piensen en todas las tecnologías
que tal vez, en su opinión,
											los humanos pueden desarrollar
con el paso del tiempo:
											tratamientos para el envejecimiento,
la colonización del espacio,
											nanobots autoreplicantes,
mentes integradas en las computadoras,
											todo tipo de ciencia-ficción
											y sin embargo en consonancia
con las leyes de la física.
											Todo esta superinteligencia
podría desarrollarse
											y posiblemente
con bastante rapidez.
									","
											Il y a là de profondes implications,
											en particulier quand il est question
de pouvoir.
											Par exemple, les chimpanzés sont forts —
											à poids équivalent, un chimpanzé est
deux fois plus fort qu'un homme adulte.
											Pourtant, le destin de Kanzi
et de ses congénères dépend beaucoup plus
											de ce que font les humains que de ce que
les chimpanzés font eux-mêmes.
											Une fois que la super intelligence
sera là,
											le destin de l'humanité pourrait dépendre
des actions de cette super intelligence.
											Pensez-y :
											l'I.A. est la dernière invention que
l'homme aura jamais besoin de faire.
											Les machines seront alors de meilleurs
inventeurs que nous le sommes,
											et elles inventeront sur des échelles
de temps numériques.
											Ça veut dire un télescopage avec le futur.
											Pensez à toutes les technologies 
incroyables que vous avez imaginées,
											que les hommes pourraient
avoir développées avec le temps :
											plus de vieillissement,
colonisation de l'espace,
											nano-robots auto-répliquants,
											téléchargement d'esprits humains
dans des ordinateurs,
											plein de technologies de science-fiction
											qui sont néanmoins cohérentes
avec les lois de la physique.
											Toute cette super intelligence pourrait
se développer assez rapidement.
									","
											Das hat tiefgreifende Auswirkungen,
											besonders wenn es um Machtfragen geht.
											Zum Beispiel sind Schimpansen stark —
											ein Schimpanse ist pro Kilo etwa 
doppelt so stark wie ein fitter Mann.
											Aber das Schicksal von Kanzi
und seinen Freunden
											hängt viel mehr von dem ab,
was wir Menschen tun,
											als von dem, was Schimpansen selbst tun.
											Sobald es eine Superintelligenz gibt,
											kann das Schicksal der Menschheit
vom Tun der Superintelligenz abhängen.
											Denken Sie darüber nach:
											KI ist die letzte Erfindung, 
die die Menschheit je machen muss.
											Maschinen sind dann 
besser im Erfinden als wir
											und tun es mit digitalen Zeitmaßstäben.
											Im Grunde bedeutet das
eine Komprimierung der Zukunft.
											Denken Sie an all die verrückten Sachen,
von denen Sie sich vorstellen könnten,
											dass die Menschen sie
zu gegebener Zeit entwickelt hätten:
											Mittel gegen das Altern, 
Besiedelung des Alls,
											selbstreplizierende Nanobots
											oder das Hochladen
des menschlichen Geistes in Computer;
											alle möglichen futuristischen Dinge,
											solange es mit den Gesetzen
der Physik übereinstimmt.
											All das könnte die Superintelligenz
wohl ziemlich schnell entwickeln.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Now, a superintelligence with such 
technological maturity
											would be extremely powerful,
											and at least in some scenarios,
it would be able to get what it wants.
											We would then have a future that would
be shaped by the preferences of this A.I.
											Now a good question is,
what are those preferences?
											Here it gets trickier.
											To make any headway with this,
											we must first of all
avoid anthropomorphizing.
											And this is ironic because 
every newspaper article
											about the future of A.I.
has a picture of this:
											So I think what we need to do is
to conceive of the issue more abstractly,
											not in terms of vivid Hollywood scenarios.
									","
											Ahora, una superinteligencia
con tanta madurez tecnológica
											sería extremadamente poderosa,
											y con la excepción de algunos casos
sería capaz de conseguir lo que quiere.
											Nuestro futuro se determinaría
por las preferencias de esta IA.
											Y una buena pregunta es
¿cuáles son esas preferencias?
											Aquí se vuelve más complicado.
											Para avanzar con esto,
											debemos en primer lugar
evitar el antropomorfismo.
											Y esto es irónico porque cada artículo
de prensa sobre el futuro de la IA
											presenta una imagen como esta:
											Así que creo que tenemos que 
pensar de manera más abstracta,
											no según escenarios
entretenidos de Hollywood.
									","
											Bon, une super intelligence avec
une telle maturité technologique
											serait extrêmement puissante,
											et au moins dans certains scénarios,
serait capable d'obtenir ce qu'elle veut.
											Nous aurions alors un futur modelé
par les préférences de cette I.A.
											Une bonne question est,
quelles sont ces préférences ?
											C'est là que ça devient délicat.
											Pour progresser là-dessus,
											nous devons tout d'abord
éviter tout anthropomorphisme.
											C'est ironique car dans tous
les articles de journaux
											qui parle de l'avenir de l'I.A.
comportent une image de ceci.
											Je pense que nous devons concevoir
ce problème de manière plus abstraite,
											et non en scénario hollywoodien fertile.
									","
											Eine Superintelligenz mit 
einer solchen technologischen Reife
											wäre extrem mächtig,
											und zumindest in einigen Szenarien
wäre sie in der Lage,
											ihren Willen zu bekommen.
											Wir hätten dann eine Zukunft,
											die durch die Vorlieben
dieser KI geprägt wäre.
											Eine gute Frage ist dann:
""Was sind das für Vorlieben?""
											Hier wird es kniffliger.
											Um damit voranzukommen,
											müssen wir vor allem
die Anthropomorphisierung vermeiden.
											Das ist ironisch, 
weil jeder Zeitungsartikel
											über die Zukunft der KI
etwa so ein Bild davon malt:
											Also denke ich, dass wir das Thema 
abstrakter verstehen müssen,
											nicht wie in den lebhaften 
Hollywood-Szenarien.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											We need to think of intelligence 
as an optimization process,
											a process that steers the future
into a particular set of configurations.
											A superintelligence is
a really strong optimization process.
											It's extremely good at using 
available means to achieve a state
											in which its goal is realized.
											This means that there is no necessary
connection between
											being highly intelligent in this sense,
											and having an objective that we humans
would find worthwhile or meaningful.
									","
											Tenemos que pensar en la inteligencia
como un proceso de optimización
											un proceso que dirige el futuro hacia un
conjunto especifico de configuraciones.
											Un superinteligencia es un proceso
de optimización realmente potente.
											Es muy bueno en el uso
de recursos disponibles
											para lograr un estado óptimo
y alcanzar su objetivo.
											Esto significa que no hay
ningún vínculo necesario
											entre ser muy inteligente en este sentido,
											y tener una meta que para los humanos
vale la pena o es significativa.
									","
											Nous devons penser à l'intelligence
comme un processus d'optimisation,
											un processus qui guide le futur
dans un certain jeu de configurations.
											Une super intelligence est un
processus d'optimisation très fort.
											Elle est très douée pour utiliser les
moyens disponibles pour atteindre un état
											dans lequel son but est réalisé.
											Ça signifie qu'il n'y a pas
de nécessaire connexion entre
											le fait d'être très intelligent
dans ce sens,
											et avoir un objectif que nous, humains,
trouverions utile ou significatif.
									","
											Wir müssen Intelligenz
als Optimierungsprozess betrachten,
											einen Prozess, der die Zukunft
in eine Reihe von Konfigurationen steuert.
											Eine Superintelligenz ist ein 
wirklich starker Optimierungsprozess.
											Sie ist sehr gut darin,
verfügbare Mittel zu verwenden,
											um einen Zustand zu erreichen,
in dem das Ziel realisiert ist.
											Es gibt also keinen
zwingenden Zusammenhang
											zwischen einer hohen Intelligenz
in diesem Sinne und einem Ziel,
											das wir Menschen für lohnend
oder sinnvoll halten würden.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Suppose we give an A.I. the goal 
to make humans smile.
											When the A.I. is weak, it performs useful
or amusing actions
											that cause its user to smile.
											When the A.I. becomes superintelligent,
											it realizes that there is a more
effective way to achieve this goal:
											take control of the world
											and stick electrodes into the facial
muscles of humans
											to cause constant, beaming grins.
											Another example,
											suppose we give A.I. the goal to solve
a difficult mathematical problem.
											When the A.I. becomes superintelligent,
											it realizes that the most effective way 
to get the solution to this problem
											is by transforming the planet
into a giant computer,
											so as to increase its thinking capacity.
											And notice that this gives the A.I.s
an instrumental reason
											to do things to us that we
might not approve of.
											Human beings in this model are threats,
											we could prevent the mathematical
problem from being solved.
									","
											Por ejemplo, la IA podría tener el
objetivo de hacer sonreír a los humanos.
											Cuando la IA está en desarrollo,
realiza acciones entretenidas
											para hacer sonreír a su usuario.
											Cuando la IA se vuelve superinteligente,
											se da cuenta de que hay una manera
más eficaz para lograr su objetivo:
											tomar el control del mundo
											e introducir electrodos en 
los músculos faciales de la gente
											para provocar sonrisas
constantes y radiantes.
											Otro ejemplo,
											supongamos que le damos el objetivo de
resolver un problema matemático difícil.
											Cuando la IA se vuelve superinteligente,
											se da cuenta de que la forma más eficaz
para conseguir la solución a este problema
											es mediante la transformación
del planeta en un computador gigante,
											para aumentar su capacidad de pensar.
											Y tengan en cuenta que esto da
a la IA una razón instrumental
											para hacer cosas que nosotros
no podemos aprobar.
											Los seres humanos
se convierten en una amenaza,
											ya que podríamos evitar
que el problema se resuelva.
									","
											Supposons qu'on donne comme but
à une I.A. de faire sourire les humains.
											Quand l'I.A. est faible, elle réalise
des actions utiles ou amusantes
											qui provoque le sourire de l'utilisateur.
											Quand l'I.A. devient super intelligente,
											elle réalise qu'il y a un moyen
plus efficace d'atteindre son objectif :
											prendre le contrôle du monde
											et implanter des électrodes
dans les muscles faciaux des humains
											pour provoquer des sourires
rayonnants et constants.
											Un autre exemple,
											supposons qu'on demande à une I.A.
de résoudre un problème de math très dur.
											Quand l'I.A. devient super intelligente,
											elle réalise que le moyen le plus efficace
pour résoudre ce problème
											est de transformer la planète
en un ordinateur géant,
											pour augmenter sa capacité de calcul.
											Remarquez que ça donne aux I.A.s
une raison pratique
											de faire des choses
que nous pourrions ne pas approuver.
											Les humains sont des menaces
dans ce modèle,
											car nous pourrions empêcher
la résolution du problème.
									","
											Angenommen, wir geben einer KI das Ziel,
Menschen zum Lächeln zu bringen.
											Eine schwache KI führt nützliche
oder amüsante Handlungen durch,
											die ihren Benutzer zum Lächeln bringen.
											Eine superintelligente KI erkennt,
											dass es einen effektiveren Weg gibt,
dieses Ziel zu erreichen:
											die Kontrolle über die Welt zu übernehmen
											und Elektroden in die Gesichtsmuskeln
von Menschen zu stecken,
											um ein konstantes,
strahlendes Grinsen zu verursachen.
											Ein anderes Beispiel:

											Angenommen, die KI soll ein schwieriges 
mathematisches Problem lösen.
											Eine superintelligente KI erkennt,
											dass der effektivste Weg
zur Lösung dieses Problems darin besteht,
											den Planeten in einen 
riesigen Computer zu verwandeln,
											um ihre Denkfähigkeit zu erhöhen.
											Man beachte, dass dies den KIs
einen instrumentalen Grund gibt,
											Dinge zu tun, die uns
vielleicht nicht gefallen.
											Menschen sind in diesem Modell
eine Bedrohung,
											denn wir könnten die Lösung
des mathematischen Problems verhindern.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Of course, perceivably things won't 
go wrong in these particular ways;
											these are cartoon examples.
											But the general point here is important:
											if you create a really powerful
optimization process
											to maximize for objective x,
											you better make sure 
that your definition of x
											incorporates everything you care about.
											This is a lesson that's also taught
in many a myth.
											King Midas wishes that everything
he touches be turned into gold.
											He touches his daughter, 
she turns into gold.
											He touches his food, it turns into gold.
											This could become practically relevant,
											not just as a metaphor for greed,
											but as an illustration of what happens
											if you create a powerful
optimization process
											and give it misconceived 
or poorly specified goals.
									","
											Por supuesto, las cosas no tienen
necesariamente que pasar de esa manera:
											son ejemplos de muestra.
											Pero lo importante,
											si crean un proceso
de optimización muy potente,
											optimizado para lograr el objetivo X,
											más vale asegurarse
de que la definición de X
											incluye todo lo que importa.
											Es una moraleja que también
se enseña a través de varios mitos.
											El rey Midas deseaba convertir
en oro todo lo que tocaba.
											Toca a su hija
y ella se convierte en oro.
											Toca su comida, se convierte en oro.
											Es un ejemplo relevante
											no solo de una metáfora de 
la codicia sino como ilustración
											de lo que sucede si crean
un proceso de optimización potente
											pero le encomiendan objetivos
incomprensibles o sin claridad.
									","
											Bien sûr, les choses perceptibles
ne tourneront pas mal de ces façons-là ;
											ce sont des exemples caricaturés.
											Mais l'argument général est important :
											si vous créez un processus d'optimisation
très puissant
											pour maximiser les chances
d'atteindre l'objectif x,
											vous devez vous assurer
que votre définition de x
											incorpore tout ce à quoi vous tenez.
											C'est une leçon qui est enseignée
dans de nombreux mythes.
											Le roi Midas souhaitait que tout
ce qu'il touche se transforme en or.
											Il touche sa fille,
elle se transforme en or.
											Il touche sa nourriture,
elle se transforme en or.
											Ça pourrait devenir
pertinent en pratique,
											ne pas se limiter à une métaphore 
de la cupidité
											mais illustrer ce qui arrive
											si vous créez un processus
d'optimisation puissant
											et lui donnez des objectifs
mal conçus ou trop vagues.
									","
											Natürlich werden Dinge nicht
genau so schiefgehen;
											das sind Cartoon-Beispiele.
											Aber der generelle Punkt hier ist wichtig:
											Wenn Sie einen wirklich mächtigen
Optimierungsprozess erstellen,
											um für das Ziel x zu maximieren,
											sollten Sie sicherstellen, 
dass Ihre Definition von x alles enthält,
											was Ihnen wichtig ist.
											Diese Lektion wird auch
in vielen Mythen gelehrt.
											König Midas wünscht, dass alles, 
was er berührt, zu Gold wird.
											Er berührt seine Tochter, 
sie verwandelt sich in Gold.
											Er berührt sein Essen, 
es verwandelt sich in Gold.
											Das könnte praktisch relevant werden,
											nicht nur als Metapher für Gier,
											sondern als Illustration für das, 

											was passiert, wenn Sie einen mächtigen 
Optimierungsprozess erstellen
											und ihm falsche oder schlecht 
spezifizierte Ziele geben.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Now you might say, if a computer starts
sticking electrodes into people's faces,
											we'd just shut it off.
											A, this is not necessarily so easy to do
if we've grown dependent on the system —
											like, where is the off switch 
to the Internet?
											B, why haven't the chimpanzees
flicked the off switch to humanity,
											or the Neanderthals?
											They certainly had reasons.
											We have an off switch, 
for example, right here.
											(Choking)
											The reason is that we are 
an intelligent adversary;
											we can anticipate threats 
and plan around them.
											But so could a superintelligent agent,
											and it would be much better 
at that than we are.
											The point is, we should not be confident
that we have this under control here.
									","
											Uno puede pensar:
											""Si una computadora empieza a poner
electrodos en la cara de la gente
											bastaría simplemente con apagarla.
											En primer lugar, puede
que no sea tan sencillo
											si somos dependientes del sistema
											por ejemplo: ¿dónde está el botón
para apagar Internet?
											En segundo lugar,
¿por qué los chimpancés
											no tienen acceso al mismo interruptor
de la humanidad, o los neandertales?
											Sin duda razones tendrían.
											Tenemos un interruptor de apagado,
por ejemplo, aquí mismo.
											(Finge estrangulación)
											La razón es que somos
un adversario inteligente;
											podemos anticipar amenazas
y planificar en consecuencia,
											pero también podría hacerlo
un agente superinteligente,
											y mucho mejor que nosotros.
											El tema es que no debemos confiar
											que podemos controlar esta situación.
									","
											Vous pourriez dire que si un ordinateur
commence à nous implanter des électrodes,
											nous le débrancherions.
											A, ce n'est pas forcément si facile
à faire si nous sommes devenus dépendants,
											par exemple,
comment arrête-t-on internet ?
											B, pourquoi les chimpanzés 
ou les Neandertals
											n'ont-ils pas
empêché l'humanité ?
											Ils avaient de bonnes raisons.
											Nous avons un interrupteur,
par exemple, juste ici.
											(Suffocation)
											La raison est que nous sommes
un adversaire intelligent ;
											nous pouvons anticiper les menaces
et planifier des solutions.
											Mais une super intelligence 
pourrait le faire aussi,
											et elle le ferait bien mieux que nous.
											L'important est que nous ne devrions pas
croire que nous avons tout sous contrôle.
									","
											Nun könnte man sagen,
wenn ein Computer anfängt,
											Elektroden in die Gesichter
von Menschen zu stecken,
											würden wir ihn einfach abschalten.
											A, das ist nicht unbedingt so einfach, 
wenn wir abhängig vom System sind.
											Wo etwa ist der Ausschalter des Internets?
											B, warum haben die Schimpansen nicht 
den Schalter an der Menschheit
											oder den Neandertalern ausgeschaltet?
											Sie hatten sicherlich Gründe.
											Wir haben zum Beispiel
einen Aus-Schalter hier.
											(Würgen)
											Der Grund ist, dass wir 
ein intelligenter Gegner sind;
											wir können Bedrohungen 
vorhersehen und ihnen ausweichen.
											Aber das könnte auch
ein superintelligenter Agent,
											und der wäre viel besser 
darin als wir selbst.
											Wir sollten uns also nicht zu sicher sein,
											dass wir das hier unter Kontrolle haben.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											And we could try to make our job
a little bit easier by, say,
											putting the A.I. in a box,
											like a secure software environment,
											a virtual reality simulation
from which it cannot escape.
											But how confident can we be that
the A.I. couldn't find a bug.
											Given that merely human hackers
find bugs all the time,
											I'd say, probably not very confident.
											So we disconnect the ethernet cable
to create an air gap,
											but again, like merely human hackers
											routinely transgress air gaps
using social engineering.
											Right now, as I speak,
											I'm sure there is some employee
out there somewhere
											who has been talked into handing out 
her account details
											by somebody claiming to be
from the I.T. department.
									","
											Y podríamos tratar de hacer nuestro
trabajo un poco más fácil digamos,
											poniendo a la IA en una caja,
en un entorno de software seguro,
											una simulación de realidad virtual
de la que no pueda escapar.
											Pero, ¿cómo podemos estar seguros
de que la IA no encontrará un error?
											Dado que incluso los hackers humanos
encuentran errores todo el tiempo,
											yo diría que probablemente,
no podemos estar muy seguros.
											Así que desconectamos el cable ethernet
para crear un espacio vacío,
											pero una vez más, al igual
que los hackers humanos,
											podrían superar estos espacios
usando la ingeniería social.
											Ahora mismo, mientras hablo,
											estoy seguro de que algún
empleado, en algún lugar
											ha sido convencido para revelar
los detalles de su cuenta
											por alguien que dice ser
del departamento de IT.
									","
											Nous pourrions tenter 
de nous faciliter la tâche, disons
											en mettant l'I.A. dans une boîte,
											comme un environnement logiciel sûr,
											une simulation de la réalité
d'où elle ne peut s'échapper.
											Mais à quel point sommes-nous sûrs
qu'elle ne trouvera pas un bug.
											Étant donné que de simples hackers humains
trouvent toujours des bugs,
											je dirais, probablement pas très sûrs.
											Donc on déconnecte le câble Ethernet
pour créer une séparation physique,
											mais encore une fois,
comme de simples hackers humains
											transgressent les séparations physiques 
grâce à l'ingéniérie sociale.
											À l'heure où je vous parle,
en ce moment-même,
											je suis sûr qu'il y a un employé,
quelque part
											à qui quelqu'un prétendant être
du département informatique
											a demandé de donner
son identifiant et son mot de passe.
									","
											Wir könnten versuchen, unsere Arbeit 
ein wenig einfacher zu machen,
											indem wir die KI in eine Box sperren,
											wie eine sichere Software-Umgebung, 

											eine Virtual-Reality-Simulation, 
aus der sie nicht entkommen kann.
											Aber wie sicher können wir sein, 
dass die KI keine Lücke findet? 

											Da schon menschliche Hacker 
ständig solche Fehler finden,
											würde ich sagen, wohl nicht sehr sicher.
											Also trennen wir das Ethernetkabel, 
um einen Luftspalt zu schaffen, 

											aber selbst menschliche Hacker
überwinden solche Luftlücken
											routinemäßig durch Social Engineering.
											Sicher gibt es gerade
irgendwo einen Angestellten,
											der von einem vermeintlichen Mitarbeiter
aus der IT überredet wurde,
											seine Kontodaten preiszugeben.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											More creative scenarios are also possible,
											like if you're the A.I.,
											you can imagine wiggling electrodes
around in your internal circuitry
											to create radio waves that you
can use to communicate.
											Or maybe you could pretend to malfunction,
											and then when the programmers open
you up to see what went wrong with you,
											they look at the source code — Bam! —
											the manipulation can take place.
											Or it could output the blueprint
to a really nifty technology,
											and when we implement it,
											it has some surreptitious side effect
that the A.I. had planned.
											The point here is that we should 
not be confident in our ability
											to keep a superintelligent genie
locked up in its bottle forever.
											Sooner or later, it will out.
									","
											Otros escenarios creativos
también son posibles,
											por ejemplo si Ud. es la IA,
											puede hacer cambios en los electrodos
de su circuito interno de seguridad
											para crear ondas de radio y
usarlas para comunicarse.
											O tal vez fingir un mal funcionamiento,
											y cuando los programadores
lo abren para entender qué está mal,
											al mirar el código fuente, ¡pum!
											ya empieza a manipular.
											O podría idear un programa
tecnológico realmente ingenioso,
											y cuando lo implementamos,
											tener efectos secundarios
ocultos planeados por la IA.
											No debemos confiar en nuestra capacidad
											para mantener un genio superinteligente
encerrado en su lámpara para siempre.
											Tarde o temprano, saldrá.
									","
											Des scénarios plus créatifs
sont aussi possibles,
											par exemple, si vous êtes une I.A.
											vous pouvez déplacer des électrodes
dans vos circuits internes
											pour créer des ondes radio que vous
utiliserez pour communiquer.
											Ou vous pouvez prétendre
dysfonctionner,
											et quand les ingénieurs vous ouvrent
pour voir ce qui ne marche pas,
											ils regardent votre code source 
— Vlan ! —
											la manipulation peut commencer.
											Ou elle pourrait produire le plan
d'une nouvelle technologie géniale,
											et quand nous l'implementons,
											elle a quelques effets secondaires furtifs
planifiés par l'I.A.
											Donc nous ne devrions pas
faire confiance à notre capacité
											à garder un génie super intelligent
prisonnier dans sa lampe éternellement.
											À un moment donné, il va s'échapper.
									","
											Es sind auch kreativere Szenarien möglich.
											Als KI kann man Elektroden 
in seiner internen Schaltung umbauen,
											um Funkwellen zu erzeugen,
mit denen man kommunizieren kann.
											Oder man gibt eine Fehlfunktion vor,
											und wenn die Programmierer nachsehen,
was schiefgelaufen ist,
											sehen sie sich den Quellcode an — Bam! —
											Die Manipulation kann stattfinden.
											Oder sie könnte den Bauplan zu einer 
raffinierten Technologie ausgeben,
											und wenn wir die implementieren, 
hat sie einen verborgenen Nebeneffekt,
											den die KI geplant hatte.
											Der Punkt ist, dass wir nicht
auf unsere Fähigkeit vertrauen sollten,
											einen superintelligenten Geist für immer
in seiner Flasche eingesperrt zu halten.
											Früher oder später kommt er heraus.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											I believe that the answer here
is to figure out
											how to create superintelligent A.I.
such that even if — when — it escapes,
											it is still safe because it is
fundamentally on our side
											because it shares our values.
											I see no way around 
this difficult problem.
									","
											Creo que la solución es averiguar
cómo crear una IA superinteligente
											para que incluso si, o cuando
se escape, sea todavía segura
											para que fundamentalmente esté de
nuestro lado y comparta nuestros valores.
											No veo cómo evitar
este problema difícil.
									","
											Je crois que la réponse à ça
est de découvrir
											comment créer une super intelligence
telle que même si ou quand elle s'échappe,
											on est toujours en sécurité car
elle est fondamentalement de notre côté
											car elle partage nos valeurs.
											Je ne vois aucune solution à ce problème.
									","
											Ich glaube, wir müssen herausfinden,
											wie man superintelligente KI so baut,
dass wenn sie — sobald — sie entkommt,
											es immer noch sicher ist, 
weil sie fest auf unserer Seite ist,
											weil sie unsere Werte teilt.
											Es führt kein Weg um dieses
schwierige Problem herum.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Now, I'm actually fairly optimistic
that this problem can be solved.
											We wouldn't have to write down 
a long list of everything we care about,
											or worse yet, spell it out 
in some computer language
											like C++ or Python,
											that would be a task beyond hopeless.
											Instead, we would create an A.I.
that uses its intelligence
											to learn what we value,
											and its motivation system is constructed
in such a way that it is motivated
											to pursue our values or to perform actions
that it predicts we would approve of.
											We would thus leverage 
its intelligence as much as possible
											to solve the problem of value-loading.
									","
											En realidad soy bastante optimista de
que este problema pueda ser resuelto.
											No tendríamos que escribir una larga
lista de todo lo que nos importa,
											o, peor aún, codificarla
en algún lenguaje informático
											como C++ o Python,
											sería una reto imposible.
											A cambio, crearíamos una IA 
que use su inteligencia
											para aprender lo que valoramos,
											y su sistema integrado
de motivación sería diseñado
											para defender nuestros valores
											y realizar acciones
que se ajusten a ellos.
											Así que usaríamos su inteligencia
tanto como fuera posible
											para resolver el problema
de la atribución de valores.
									","
											Mais je suis plutôt optimiste quant le fait
que ce problème peut être résolu.
											Nous n'aurions pas à écrire une longue
liste de tout ce que nous chérissons,
											ou, encore pire, devoir le coder
en language informatique
											comme C++ ou Python,
											ce qui serait une tâche sans espoir.
											Au lieu de ça, nous créerions une I.A.
qui utilise son intelligence
											pour apprendre nos valeurs,
											et son système de motivation est construit
de telle sorte qu'elle est motivée
											par la recherche de valeurs ou d'actions
qu'elle prédit que nous approuverions.
											Nous pourrions ainsi influencer
son intelligence autant que possible
											à résoudre des problèmes importants.
									","
											Ich bin aber ziemlich optimistisch, 
dass es gelöst werden kann.
											Wir müssten keine lange Liste von allem 
aufschreiben, was uns wichtig ist,
											oder schlimmer noch,
											es in irgendeiner Computersprache
wie C++ oder Python buchstabieren;
											das wäre eine Aufgabe, 
die mehr als hoffnungslos ist.
											Stattdessen würden wir eine KI bauen, 
die ihre Intelligenz nutzt,
											um zu lernen, was wir wertschätzen,
											und ihr Motivationssystem
ist so konstruiert,
											dass sie anstrebt,
unsere Ziele zu verfolgen
											oder Dinge zu tun, von denen 
sie erwartet, dass wir sie billigen.
											Wir würden somit ihre Intelligenz
											für das Problem der Wertedefinition
so gut wie möglich einsetzen.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											This can happen,
											and the outcome could be 
very good for humanity.
											But it doesn't happen automatically.
											The initial conditions 
for the intelligence explosion
											might need to be set up 
in just the right way
											if we are to have a controlled detonation.
											The values that the A.I. has
need to match ours,
											not just in the familiar context,
											like where we can easily check
how the A.I. behaves,
											but also in all novel contexts
that the A.I. might encounter
											in the indefinite future.
									","
											Esto puede suceder,
											y el resultado podría ser
muy bueno para la humanidad.
											Pero no sucede automáticamente.
											Las condiciones iniciales
para la explosión de la inteligencia
											necesitan ser perfectamente definidas
											si queremos contar con
una detonación controlada.
											Los valores de la IA tienen
que coincidir con los nuestros
											no solo en el ámbito familiar,
											donde podemos comprobar
fácilmente cómo se comporta,
											sino también en todos los nuevos contextos
											donde la IA podría encontrarse
en un futuro indefinido.
									","
											Ça peut arriver,
											et le résultat en serait très positif
pour l'humanité.
											Mais ça n'arrive pas automatiquement.
											Les conditions initiales
de l'explosion de l'intelligence
											devront être programmées
de manière précise
											si nous voulons obtenir
une détonation contrôlée.
											Les valeurs de l'I.A. devront
correspondre aux nôtres,
											pas seulement dans un contexte familier,
											où il est facile de contrôler 
comment l'I.A. se comporte,
											mais aussi dans de nouveaux contextes
que l'I.A. pourrait rencontrer
											dans un futur indéfini.
									","
											Das kann passieren,
											und das Ergebnis könnte 
sehr gut für die Menschheit sein.
											Aber es geschieht nicht automatisch.
											Die Anfangsbedingungen 
für die Intelligenzexplosion
											müssen genau auf die richtige 
Art und Weise aufgestellt werden,
											wenn wir eine kontrollierte 
Detonation haben wollen.
											Die Werte der KI müssen 
mit unseren übereinstimmen,
											nicht nur im vertrauten Kontext,
											wo wir leicht überprüfen können,
wie die KI sich verhält,
											sondern auch in allen neuen Situationen,
											auf die die KI in der
unbestimmten Zukunft treffen könnte.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											And there are also some esoteric issues
that would need to be solved, sorted out:
											the exact details of its decision theory,
											how to deal with logical
uncertainty and so forth.
											So the technical problems that need
to be solved to make this work
											look quite difficult —
											not as difficult as making 
a superintelligent A.I.,
											but fairly difficult.
											Here is the worry:
											Making superintelligent A.I.
is a really hard challenge.
											Making superintelligent A.I. that is safe
											involves some additional 
challenge on top of that.
											The risk is that if somebody figures out
how to crack the first challenge
											without also having cracked 
the additional challenge
											of ensuring perfect safety.
									","
											Y también hay algunas cuestiones
esotéricas que habría que resolver:
											los detalles exactos de
su teoría de la decisión,
											cómo manejar la incertidumbre lógica, etc.
											Así que los problemas
técnicos que hay que resolver
											para hacer este trabajo
parecen muy difíciles
											—no tan difíciles como crear
una IA superinteligente—
											pero bastante difíciles.
											Este es la preocupación:
											crear una IA superinteligente
es un reto muy difícil
											y crear una que sea segura
											implica desafíos adicionales.
											El riesgo es si alguien encuentra
la manera de superar el primer reto
											sin resolver el otro desafío
de garantizar la máxima seguridad.
									","
											Il y a aussi des problèmes ésotériques
qui devront être résolus :
											les détails exacts
de sa théorie de décision,
											comment gérer l'incertitude logique
et ainsi de suite.
											Les problèmes techniques qui doivent
être surmontés pour que ça marche
											semblent ardus—
											pas autant que de faire 
une I.A. super intelligente,
											mais assez ardus.
											Là où c'est inquiétant, c'est que
											faire une I.A. super intelligente
est un défi vraiment difficile.
											Faire une I.A. super intelligente
qui soit sûre
											implique quelques
défis supplémentaires.
											Le risque est que si quelqu'un trouve
comment résoudre le premier défi
											sans avoir aussi résolu
											l'autre défi, celui d'assurer
une sécurité parfaite.
									","
											Es gibt auch einige esoterische Fragen,
die gelöst werden müssten:
											die genauen Details 
ihrer Entscheidungstheorie,
											wie mit logischer Unsicherheit 
umzugehen ist usw.
											Die technischen Probleme, 
die dafür gelöst werden müssen,
											sind ziemlich schwierig —
											nicht so schwierig, wie eine 
superintelligente KI zu bauen,
											aber ziemlich schwierig.
											Hier ist die Sorge:
											Superintelligente KI zu bauen
ist eine wirklich harte Herausforderung.
											Sichere superintelligente KI zu bauen
											birgt noch zusätzliche Herausforderungen.
											Das Risiko besteht darin, 
dass jemand die erste Hürde knackt, 

											ohne die zusätzliche Herausforderung, 
perfekte Sicherheit zu gewährleisten,
											ebenfalls zu knacken.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											So I think that we should
work out a solution
											to the control problem in advance,
											so that we have it available 
by the time it is needed.
											Now it might be that we cannot solve
the entire control problem in advance
											because maybe some elements
can only be put in place
											once you know the details of the 
architecture where it will be implemented.
											But the more of the control problem
that we solve in advance,
											the better the odds that the transition
to the machine intelligence era
											will go well.
									","
											Así que creo que deberíamos
encontrar una solución
											al problema del control por adelantado,
											de modo que esté disponible
para cuando sea necesario.
											Puede ser que no podamos
resolver por completo
											el problema del control de antemano
											porque tal vez, algunos elementos
solo pueden ser desarrollados
											después de reunir los detalles
técnicos de la IA en cuestión.
											Pero cuanto antes solucionemos
el problema del control,
											mayores serán las probabilidades
											de que la transición a la era
de las máquinas inteligentes
											vaya bien.
									","
											Je pense que nous devrions donc
commencer à résoudre
											le problème de contrôle d'abord,
											pour qu'il soit disponible
quand on en aura besoin.
											On ne pourra peut-être pas résoudre
tout le problème du contrôle à l'avance
											car certains éléments ne peuvent
être mis en place
											qu'une fois qu'on connait les détails
de l'architecture où ce sera implémenté.
											Mais plus nous résolvons ce problème
de contrôle à l'avance,
											meilleure sera notre chance 
que la transition vers l'ère de l'I.A.
											se passera bien.
									","
											Ich denke daher,
											wir sollten im Vorfeld
das Steuerungsproblem lösen,
											damit wir eine Lösung haben,
wenn sie benötigt wird.
											Vielleicht können wir nicht das
ganze Steuerungsproblem im Voraus lösen,
											weil vielleicht einige Elemente 
erst gesetzt werden können,
											wenn wir die Details der Architektur, 
in der sie implementiert werden, kennen.
											Je mehr Kontrollprobleme 
wir jedoch im Voraus lösen,
											desto besser sind die Chancen, 
dass der Übergang
											zur Maschinenintelligenz gut verläuft.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											This to me looks like a thing
that is well worth doing
											and I can imagine that if 
things turn out okay,
											that people a million years from now
look back at this century
											and it might well be that they say that
the one thing we did that really mattered
											was to get this thing right.
									","
											Esto me parece algo digno de hacer
											y puedo imaginar que si
las cosas salen bien,
											la gente en un millón de años 
discutirá nuestro siglo
											y dirá que posiblemente lo único
que hicimos bien y mereció la pena
											fue superar con éxito este reto.
									","
											Pour moi, ça semble valoir la peine
											et j'imaginer que,
si tout se passe bien,
											les gens, dans un million d'années,
penseront peut-être
											que la chose qui a vraiment été
importante dans notre siècle
											était de faire ça bien.
									","
											Das sieht für mich nach einer Sache aus, 
die es wert ist, getan zu werden,
											und ich kann mir vorstellen, 
dass wenn die Dinge gut laufen,
											die Leute in einer Million Jahre
auf dieses Jahrhundert zurückblicken
											und möglicherweise sagen,
											dass unsere einzige wichtige Leistung
der Erfolg bei dieser Sache war.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											Thank you.
									","
											Gracias.
									","
											Merci.
									","
											Vielen Dank.
									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
											(Applause)
									","
											(Aplausos)
									","
											(Applaudissements)
									","
											(Beifall)

									",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
"
","
","
","
",What happens when our computers get smarter than we are?,Nick Bostrom,16:31,"AI,future,philosophy,technology,machine learning"
