en,fr,tr,pt,title,speaker,duration,tags
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											So, on April 23 of 2013,
											the Associated Press
put out the following tweet on Twitter.
											It said, ""Breaking news:
											Two explosions at the White House
											and Barack Obama has been injured.""
											This tweet was retweeted 4,000 times
in less than five minutes,
											and it went viral thereafter.
									","
											Le 23 avril 2013,
											l'Associated Press a publié
le tweet suivant sur Twitter.
											Il disait : « Flash info :
											deux explosions à la Maison-Blanche
											et Barack Obama a été blessé. »
											Ce tweet a été retweeté 4 000 fois
en moins de cinq minutes
											et est ensuite devenu viral.
									","
											23 Nisan 2013'te
											Associated Press, Twitter'da
şöyle bir tweet attı.
											""Flaş haber:
											Beyaz Saray'da iki patlama.
											Barack Obama yaralandı.""
											Bu tweet beş dakikadan kısa sürede
4000 kere paylaşıldı
											ve sonrasında viral oldu.
									","
											No dia 23 de abril de 2013,
											a Associated Press publicou 
o seguinte ""tweet"":
											""Notícia de última hora:
											""Houve duas explosões na Casa Branca
											""e o presidente Barack Obama foi ferido.""
											O ""tweet"" foi reenviado 4000 vezes
em menos de 5 minutos,
											e depois tornou-se viral.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											Now, this tweet wasn't real news
put out by the Associated Press.
											In fact it was false news, or fake news,
											that was propagated by Syrian hackers
											that had infiltrated
the Associated Press Twitter handle.
											Their purpose was to disrupt society,
but they disrupted much more.
											Because automated trading algorithms
											immediately seized
on the sentiment on this tweet,
											and began trading based on the potential
											that the president of the United States
had been injured or killed
											in this explosion.
											And as they started tweeting,
											they immediately sent
the stock market crashing,
											wiping out 140 billion dollars
in equity value in a single day.
									","
											Ce tweet n'était pas une vraie info
publiée par l'Associated Press.
											C'était une fausse info, ou une infox,
											qui a été propagée par des pirates syriens
											qui avaient piraté le compte
de l'Associated Press sur Twitter.
											Leur objectif était
de perturber la société,
											mais ils ont perturbé bien plus que cela.
											Car les algorithmes automatisés de trading
											ont immédiatement saisi
le sentiment de ce tweet
											et ont commencé à faire des opérations
basées sur la possibilité
											que le président des États-Unis
ait été blessé ou tué
											dans une explosion.
											Alors qu'ils ont commencé à tweeter,
											ils ont immédiatement causé
l’écroulement du cours de la bourse,
											anéantissant 140 milliards de dollars
de valeur de fonds propres en un jour.
									","
											Bu tweet, Associated Press tarafından 
paylaşılan gerçek bir haber değildi.
											Aslında sahte veya yalan bir haberdi.
											Associated Press'in
Twitter hesabını ele geçiren
											Suriyeli bilgisayar korsanlarınca 
paylaşılmıştı.
											Amaçları toplumda kargaşa çıkarmaktı
ama çok daha fazlasını yaptılar.
											Çünkü otomatik borsa algoritmaları
											bu tweet'teki hissiyatı hemen yakaladı
											ve ABD Başkanı'nın bu patlamada
											yaralanmış veya öldürülmüş olması
ihtimaline göre alım satım
											yapmaya başladı.
											Tweet atmaya başladıklarında
											borsayı çöküşe soktular,
											bir günde 140 milyar dolarlık
değer kaybına yol açtılar.
									","
											No entanto, o ""tweet"" em questão
não foi feito pela Associated Press.
											Na verdade, era uma notícia falsa,
ou ""fake news"",
											que tinha sido divulgada 
por ""hackers"" sírios
											que se tinham infiltrado
na conta da AP no Twitter.
											O seu propósito era criar ruturas na
sociedade, mas foram ainda mais além,
											porque os algoritmos automatizados
de ""trading""
											captaram imediatamente 
o sentimento deste ""tweet""
											e começaram a trabalhar
baseados na possibilidade
											de o presidente dos EUA 
ter sido ferido ou morto
											nesta explosão.
											Assim que começaram a publicar ""tweets""
											provocaram imediatamente
o colapso do mercado de ações,
											liquidando 140 mil milhões de dólares 
num único dia.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											Robert Mueller, special counsel
prosecutor in the United States,
											issued indictments
against three Russian companies
											and 13 Russian individuals
											on a conspiracy to defraud
the United States
											by meddling in the 2016
presidential election.
											And what this indictment tells as a story
											is the story of the Internet
Research Agency,
											the shadowy arm of the Kremlin
on social media.
											During the presidential election alone,
											the Internet Agency's efforts
											reached 126 million people
on Facebook in the United States,
											issued three million individual tweets
											and 43 hours' worth of YouTube content.
											All of which was fake —
											misinformation designed to sow discord
in the US presidential election.
									","
											Robert Mueller,
procureur spécial aux États-Unis,
											a prononcé des chefs d'accusation
contre trois entreprises russes
											et 13 ressortissants russes
											au sujet d'un complot
pour escroquer les États-Unis
											via une ingérence durant les élections
présidentielles de 2016.
											L'histoire que raconte
ce chef d'accusation
											est celle de l'Internet Research Agency,
											le bras armé du Kremlin
sur les réseaux sociaux.
											Durant les élections
présidentielles uniquement,
											les efforts de l'Internet Agency
											ont touché 126 millions de personnes
sur Facebook aux États-Unis,
											ont publié trois millions de tweets
											et 43 heures de contenu sur YouTube.
											Tout cela était faux —
											de la désinformation
conçue pour semer la discorde
											au sein des élections
présidentielles américaines.
									","
											Özel yetkili ABD savcısı Robert Mueller
											üç Rus şirketine ve 13 Rus bireye karşı
											2016 başkanlık seçimine müdahale ederek
											ABD'yi dolandırmak amacıyla
											komplo kurmaktan dava açtı.
											Bu iddianamenin hikâyesi,
											Kremlin'in sosyal medyadaki 
gizli kolu olan
											Internet Research Agency'nin hikâyesidir.
											Sırf başkanlık seçimlerinde
											Internet Agency'nin çabaları
											ABD'de Facebook üzerinden
126 milyon kişiye ulaştı,
											üç milyon tekil tweet attı
											ve 43 saatlik YouTube içeriği yayınladı.
											Bunların hepsi sahteydi.
											ABD başkanlık seçimlerine şüphe tohumları 
ekme amaçlı yanlış bilgilendirmelerdi.
									","
											O procurador especial dos EUA,
Robert Mueller,
											emitiu acusações contra
três empresas russas
											e treze indivíduos russos
											por conspiração para
defraudar os EUA
											interferindo nas eleições
presidenciais de 2016.
											Essas acusações contam-nos uma história,
											a história sobre
a Internet Research Agency,
											o braço sombrio do Kremlin
nas redes sociais.
											Só durante as eleições presidenciais,
											as publicações da Internet Agency
											alcançaram 126 milhões de pessoas
nos EUA através do Facebook,
											publicaram três milhões
de ""tweets"" individuais
											e 43 horas de conteúdos no YouTube.
											Era tudo falso
											— desinformação destinada
a semear a discórdia
											nas eleições presidenciais dos EUA.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											A recent study by Oxford University
											showed that in the recent
Swedish elections,
											one third of all of the information
spreading on social media
											about the election
											was fake or misinformation.
									","
											Une étude récente de l'université d'Oxford
											a montré que durant
les récentes élections suédoises,
											un tiers de toutes les informations
se propageant sur les réseaux sociaux
											au sujet des élections
											étaient fausses ou de la désinformation.
									","
											Oxford Üniversitesi'nin 
yakın tarihli bir araştırması
											geçtiğimiz İsveç seçimlerinde
											sosyal medyada yayınlanan
seçimle ilgili bilgilerin
											üçte birinin
											yalan veya sahte olduğunu
ortaya koydu.
									","
											Um estudo recente feito
na Universidade de Oxford
											mostrou que, nas recentes 
eleições da Suécia,
											um terço de todas informações
a circular nas redes sociais
											sobre as eleições
											eram falsas ou desinformação.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											In addition, these types
of social-media misinformation campaigns
											can spread what has been called
""genocidal propaganda,""
											for instance against
the Rohingya in Burma,
											triggering mob killings in India.
									","
											De plus, ce genre de campagne
de désinformation sur les réseaux sociaux
											peut propager ce qu’on en est venu à
appeler de la « propagande génocidaire »,
											par exemple contre
les Rohingyas en Birmanie,
											ou entraînant des massacres
collectifs en Inde.
									","
											Ek olarak, yanlış bilgilendirme amaçlı
bu tür sosyal medya kampanyaları
											Burma'da Rohingya'ya karşı yürütülen
											veya Hindistan'da linçlere yol açan
""soykırımcı propaganda""ların
											yayılmasına yol açabilir.
									","
											Além do mais, este tipo de campanhas
de desinformação nas redes sociais
											podem difundir o que vem sendo
chamado de ""propaganda genocida"",
											por exemplo contra os Rohingya em Myanmar,
											desencadeando assassínios
por parte de multidões na Índia.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											We studied fake news
											and began studying it
before it was a popular term.
											And we recently published
the largest-ever longitudinal study
											of the spread of fake news online
											on the cover of ""Science""
in March of this year.
											We studied all of the verified
true and false news stories
											that ever spread on Twitter,
											from its inception in 2006 to 2017.
											And when we studied this information,
											we studied verified news stories
											that were verified by six
independent fact-checking organizations.
											So we knew which stories were true
											and which stories were false.
											We can measure their diffusion,
											the speed of their diffusion,
											the depth and breadth of their diffusion,
											how many people become entangled
in this information cascade and so on.
											And what we did in this paper
											was we compared the spread of true news
to the spread of false news.
											And here's what we found.
									","
											Nous avons étudié l'infox
											et avons commencé à l'étudier
avant que ce ne soit un terme populaire.
											Nous avons récemment publié la plus longue
étude longitudinale qui soit
											sur la propagation de l'infox en ligne
											en couverture de « Science »
en mars cette année.
											Nous avons étudié toutes les infos
confirmées comme étant vraies ou fausses
											qui se sont propagées sur Twitter,
											depuis son lancement en 2006 jusqu'à 2017.
											Quand nous avons étudié ces informations,
											nous avons étudié des informations
											qui avaient été vérifiées
											par six organisations
de vérification indépendantes.
											Nous savions donc
quelles informations étaient vraies
											et quelles informations étaient fausses.
											Nous pouvons mesurer leur diffusion,
											la vitesse de leur diffusion,
											la portée et l'ampleur de leur diffusion,
											combien de gens se sont empêtrés
dans cette cascade d'informations, etc.
											Dans cette publication,
											nous avons comparé la propagation
d'informations vraies et d'infox.
											Voici ce que nous avons découvert.
									","
											Biz yalan haberleri araştırdık
											ve onları araştırmaya bu terim
popüler olmadan önce başladık.
											Bu yıl Mart ayında,
""Science"" dergisinin kapağında
											internette yayılan sahte haberleri
konu alan en geniş kapsamlı
											panel araştırmasını yayımladık.
											2006'daki kuruluşundan 2017'ye kadar
Twitter'da yayılan
											doğru veya yalan olduğu ispatlanmış
											tüm haberleri inceledik.
											Bu bilgileri ele alırken
											bilgi kontrolü yapan 
altı bağımsız kuruluşun
											doğruladığı haberleri inceledik.
											Yani hangilerinin doğru,
											hangilerinin sahte olduğunu biliyorduk.
											Yayılışlarını ölçebiliyoruz,
											yayılışlarının hızını, derinliğini
											ve kapsamını ölçebiliyoruz,
											kaç kişinin bu bilgi yağmuruna
kapıldığını da.
											Bu araştırmada yaptığımız,
											gerçek haberlerin yayılışıyla
yalan haberlerin yayılışını kıyaslamaktı.
											Bulduklarımız şunlar:
									","
											Nós estudámos as notícias falsas
											e começámos a estudar isso bem antes 
de este termo se tornar popular.
											Recentemente publicámos o maior
estudo longitudinal de sempre
											sobre o crescimento ""online""
das notícias falsas
											na capa da revista Science
em março deste ano.
											Estudámos todas as notícias 
verificadas como verdadeiras ou falsas
											que já se propagaram pelo Twitter
											desde o seu início, em 2006, até 2017.
											Ao estudarmos estas informações,
											estudámos notícias verificadas
											por seis ONG independentes
que verificam factos.
											Por isso sabíamos quais
as notícias verdadeiras
											e quais as falsas.
											Podemos medir a sua propagação,
											a rapidez da propagação,
											a profundidade e a amplitude
da propagação,
											e quantas pessoas são enganadas
nessa torrente de informação.
											O que fizemos neste trabalho,
											foi comparar a propagação de factos
e a propagação de notícias falsas.
											E o que encontrámos foi o seguinte.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											We found that false news
diffused further, faster, deeper
											and more broadly than the truth
											in every category of information
that we studied,
											sometimes by an order of magnitude.
											And in fact, false political news
was the most viral.
											It diffused further, faster,
deeper and more broadly
											than any other type of false news.
											When we saw this,
											we were at once worried but also curious.
											Why?
											Why does false news travel
so much further, faster, deeper
											and more broadly than the truth?
									","
											Nous avons découvert
											que l'infox se diffusait plus loin,
plus vite, plus profondément
											et plus largement que la vérité
											dans chacune des catégories d'informations
que nous avons étudiées,
											la différence étant parfois
d'un ordre de grandeur.
											Les infox politiques
étaient les plus virales.
											Elles se diffusaient plus loin, vite,
profondément et largement
											que n'importe quel autre type d'infox.
											Quand nous avons vu cela,
											nous étions à la fois inquiets
mais aussi curieux.
											Pourquoi ?
											Pourquoi est-ce que l'infox circule
tellement plus loin, vite, profondément
											et largement que la vérité ?
									","
											Yalan haberlerin araştırdığımız 
her haber kategorisinde
											doğru haberlerden
											kimi zaman birkaç kat
daha uzağa, daha hızlı,
											daha geniş kapsamlı
yayıldığını tespit ettik.
											Siyasi yalan haberler en viral olanlardı.
											Diğer tür yalan haber türlerinden
daha uzağa, daha derine
											ve daha geniş kitlelere yayılıyorlardı.
											Bunu gördüğümüzde
											hem endişelendik hem meraklandık.
											Neden?
											Neden yalan haberler, gerçeklerden
daha uzağa, daha hızlı,
											daha geniş çaplı yayılıyor?
									","
											As notícias falsas eram propagadas
muito mais rapidamente
											e mais amplamente do que os factos
											em todas as categorias
de informações que estudámos,
											por vezes por uma ordem de magnitude.
											De facto, as notícias políticas falsas
eram as mais virais.
											Espalhavam-se mais rapidamente,
com maior profundidade e abrangência
											do que qualquer outro tipo
de notícias falsas.
											Quando notámos isto,
											ficámos preocupados mas também curiosos.
											Porquê?
											Por que razão as notícias falsas vão mais
longe, mais rápida e profundamente
											e mais extensamente do que a verdade?
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											The first hypothesis
that we came up with was,
											""Well, maybe people who spread false news
have more followers or follow more people,
											or tweet more often,
											or maybe they're more often 'verified'
users of Twitter, with more credibility,
											or maybe they've been on Twitter longer.""
											So we checked each one of these in turn.
											And what we found
was exactly the opposite.
											False-news spreaders had fewer followers,
											followed fewer people, were less active,
											less often ""verified""
											and had been on Twitter
for a shorter period of time.
											And yet,
											false news was 70 percent more likely
to be retweeted than the truth,
											controlling for all of these
and many other factors.
									","
											Notre première hypothèse était :
											« Peut-être que les gens
diffusant de l'infox
											ont plus de suiveurs
ou suivent plus de monde,
											tweetent plus souvent,
											peut-être sont-ils plus souvent
des utilisateurs « vérifiés » de Twitter,
											avec plus de crédibilité,
											ou sont-ils là depuis plus longtemps. »
											Nous avons vérifié
chacune de ces hypothèses.
											Nous avons découvert
exactement le contraire.
											Les diffuseurs d'infox
avaient moins de suiveurs,
											suivaient moins de gens,
étaient moins actifs,
											moins souvent « vérifiés »
											et étaient sur Twitter
depuis moins longtemps.
											Et pourtant,
											les infox avaient 
70% de probabilités de plus
											d'être retweetées par rapport à la vérité,
											en contrôlant ces facteurs
et de nombreux autres.
									","
											İlk hipotezimiz
											""Belki yalan haberleri yayanların 
takipçisi, takip ettikleri daha çok,
											daha çok tweet atıyorlar,
											geneli ""doğrulanmış"" Twitter kullanıcıları
											veya daha uzun süredir Twitter'dalar.
											Sırayla bunların hepsine baktık.
											Tam tersini bulduk.
											Yalan haberleri yayanların 
takipçileri daha azdı,
											daha az kişiyi takip ediyorlardı,
daha az aktif,
											ender olarak ""doğrulanmış""tılar.
											Daha kısa süredir Twitter'daydılar.
											Yine de
											bunlar ve başka faktörler dâhilinde
yalan haberin tekrar tweetlenmesi ihtimali
											
yüzde 70 daha fazlaydı.
									","
											A primeira hipótese que formulámos foi:
											""Talvez as pessoas
que espalham notícias falsas
											""tenham mais seguidores
ou sigam mais pessoas,
											""ou publiquem mais ""tweets"",
											""ou talvez tenham contas 'verificadas'
no Twitter, com mais credibilidade,
											""ou talvez estejam
há mais tempo no Twitter.""
											Examinámos todas as opções, uma a uma.
											Porém, descobrimos exatamente o oposto.
											Os propagadores de notícias falsas
tinham menos seguidores,
											seguiam poucas pessoas, 
não eram tão ativos,
											não eram tão verificados
											e estavam no Twitter há menos tempo.
											Ainda assim,
											era 70% mais provável que fossem enviadas
											notícias falsas do que verdadeiras
											mesmo tendo em conta estes
e muitos outros fatores.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											So we had to come up
with other explanations.
											And we devised what we called
a ""novelty hypothesis.""
											So if you read the literature,
											it is well known that human attention
is drawn to novelty,
											things that are new in the environment.
											And if you read the sociology literature,
											you know that we like to share
novel information.
											It makes us seem like we have access
to inside information,
											and we gain in status
by spreading this kind of information.
									","
											Nous devions trouver
d'autres explications.
											Nous avons formulé
											ce que nous avons appelé
« l'hypothèse de la nouveauté ».
											Si vous lisez la littérature,
											il est bien connu que l'attention humaine
est attirée par la nouveauté,
											les choses nouvelles dans l'environnement.
											Si vous lisez la littérature sociologique,
											vous savez que nous aimons partager
des informations nouvelles.
											Cela nous donne l'impression d'avoir
un accès privilégié à des informations
											et nous gagnons en statut
en diffusant ce genre d'informations.
									","
											Öyleyse başka açıklamalar bulmalıydık.
											""Yenilik hipotezi"" diye 
bir şey geliştirdik.
											Araştırmalara bakarsanız
											insanın dikkatinin yeni şeylere,
çevrede yeni olan şeylere
											kaydığı iyi bilinir.
											Sosyoloji külliyatına bakarsanız
											yeni bilgileri paylaşmayı
sevdiğimizi görürsünüz.
											Gizli bir bilgiye
erişimimiz varmış gibi hissettirir
											ve bu tür bilgileri yayarak
statü kazanırız.
									","
											Então tivemos de encontrar
outras explicações.
											E criámos algo a que chamámos
de ""hipótese da novidade"".
											Se lerem a literatura sobre este tema,
											saberão que a novidade
atrai a atenção humana,
											isto é, coisas que são novas no ambiente.
											Se lerem literatura sobre sociologia,
											saberão que gostamos de partilhar
informações novas.
											Faz parecer que temos acesso
a informações privilegiadas,
											e ganhamos estatuto por partilhar
esse tipo de informações.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											So what we did was we measured the novelty
of an incoming true or false tweet,
											compared to the corpus
of what that individual had seen
											in the 60 days prior on Twitter.
											But that wasn't enough,
because we thought to ourselves,
											""Well, maybe false news is more novel
in an information-theoretic sense,
											but maybe people
don't perceive it as more novel.""
									","
											Nous avons alors mesuré la nouveauté
d'un tweet, qu'il soit vrai ou faux,
											l'avons comparé au corpus
de ce que l'individu avait vu
											sur Twitter les 60 derniers jours.
											Mais cela ne suffisait pas
car nous avons pensé :
											« Peut-être que l'infox
représente plus de nouveauté
											dans un sens théorique,
											mais peut-être que les gens
n'y perçoivent pas plus de nouveauté. »
									","
											Gelen doğru veya yalan bir tweet'in
o bireyin önceki 60 günde
											Twitter'da gördüklerine kıyasla
ne kadar yeni bir bilgi
											olduğunu ölçtük.
											Ama bu, yeterli değildi. ""Yalan haber,
											bilgi teorisi anlamında daha yeni olabilir
											ama belki insanlar onu
yeni olarak algılamıyordur."" dedik.
									","
											Então, medimos a novidade
de um novo ""tweet"", verdadeiro ou falso,
											e comparámos com
o que cada pessoa já tinha visto
											nos últimos 60 dias no Twitter.
											Mas não foi o suficiente, 
pois pensámos:
											""Talvez uma notícia falsa seja mais nova
num sentido mais teórico-informativo,
											""mas talvez as pessoas não
vejam isso como novidade.""
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											So to understand people's
perceptions of false news,
											we looked at the information
and the sentiment
											contained in the replies
to true and false tweets.
											And what we found
											was that across a bunch
of different measures of sentiment —
											surprise, disgust, fear, sadness,
											anticipation, joy and trust —
											false news exhibited significantly more
surprise and disgust
											in the replies to false tweets.
											And true news exhibited
significantly more anticipation,
											joy and trust
											in reply to true tweets.
											The surprise corroborates
our novelty hypothesis.
											This is new and surprising,
and so we're more likely to share it.
									","
											Pour comprendre la perception
que les gens avaient des infox,
											nous avons considéré
l'information et le sentiment
											que les réponses des tweets
vrais et faux incluaient.
											Nous avons découvert
											que parmi tout un tas
de mesures différentes des sentiments —
											la surprise, le dégoût,
la peur, la tristesse,
											l'anticipation, la joie et la confiance —
											les infox présentaient notablement
plus de surprise et de dégoût
											dans les réponses aux tweets.
											Les informations avérées présentaient
notablement plus d'anticipation,
											de joie et de confiance
											dans les réponses aux tweets.
											La surprise corrobore
notre hypothèse de la nouveauté.
											C'est nouveau et surprenant,
											nous allons donc
plus probablement le partager.
									","
											İnsanların yalan haberi
nasıl algıladığını anlamak için
											doğru ve yalan haberlere 
verilen tepkilerdeki
											bilgilere ve hislere baktık.
											Sürpriz, iğrenme, korku,
											üzüntü, beklenti, neşe ve güven gibi
											farklı duyguların ölçümlerine baktığımızda
											bulduğumuz şey
											yalan haberler söz konusu olduğunda
bu sahte tweet'lere verilen yanıtların
											çok daha fazla sürpriz 
ve iğrenme hissine yol açtığıydı.
											Doğru haberlerdeyse 
doğru tweet'lere verilen yanıtlarda
											daha çok beklenti,
											neşe ve güven vardı.
											Sürpriz, yenilik hipotezine uyuyor.
											Bu, yeni ve şaşırtıcı, dolayısıyla onu
paylaşma ihtimalimiz daha yüksek.
									","
											Então, para compreender a perceção 
das pessoas sobre notícias falsas,
											estudámos as informações e o sentimento
											contido nas respostas dos ""tweets""
verdadeiros e falsos.
											E descobrimos
											que, através de um conjunto
de diferentes medidas de sentimentos
											— surpresa, repugnância, medo, tristeza,
											expetativa, alegria e confiança —
											as notícias falsas exibiam
maior surpresa e repugnância
											em reação aos ""tweets"" falsos.
											E as notícias verdadeiras
exibiam maior expetativa,
											alegria e confiança
											em reação aos ""tweets"" verdadeiros.
											Esta surpresa confirma
a nossa hipótese de novidade.
											Isto é novo e surpreendente, 
por isso é mais provável que partilhemos.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											At the same time,
there was congressional testimony
											in front of both houses of Congress
in the United States,
											looking at the role of bots
in the spread of misinformation.
											So we looked at this too —
											we used multiple sophisticated
bot-detection algorithms
											to find the bots in our data
and to pull them out.
											So we pulled them out,
we put them back in
											and we compared what happens
to our measurement.
											And what we found was that, yes indeed,
											bots were accelerating
the spread of false news online,
											but they were accelerating
the spread of true news
											at approximately the same rate.
											Which means bots are not responsible
											for the differential diffusion
of truth and falsity online.
											We can't abdicate that responsibility,
											because we, humans,
are responsible for that spread.
									","
											En même temps, il y avait
un témoignage au Congrès,
											devant les deux chambres
du Congrès des États-Unis,
											considérant le rôle des robots
dans la diffusion de la désinformation.
											Nous l'avons envisagé —
											nous avons utilisé
											de multiples algorithmes sophistiqués
de détection de robots
											pour trouver les robots
dans nos données et les en extraire.
											Nous les en avons extraits,
les avons inclus à nouveau
											et avons comparé
ce qu'il arrivait à nos mesures.
											Nous avons découvert que oui, en effet,
											les robots accéléraient
la diffusion d'infox en ligne,
											mais ils accéléraient
la diffusion d'informations avérées
											approximativement au même rythme.
											Ce que signifie que les robots
ne sont pas responsables
											pour l'écart dans la diffusion
de la vérité et de la fausseté en ligne.
											Nous ne pouvons pas
refuser cette responsabilité
											car nous, êtres humains,
sommes responsables de cette diffusion.
									","
											Aynı zamanda ABD Kongre ve Senatosu'nda
											yanlış bilgilerin yayılmasında
botların rolüne dair
											ifadeler verildi.
											Biz de buna da baktık.
											Gelişmiş bot tespit 
algoritmaları kullanarak
											verilerimizdeki botları bulup çıkardık.
											Onları çıkardık, geri koyduk
											ve ölçümlerimize ne olduğuna baktık.
											Şunu bulduk, evet, gerçekten de botlar
											internette yalan haberlerin 
yayılmasını hızlandırıyordu
											ama doğruların yayılmasını da
											aynı ölçüde hızlandırıyorlardı.
											Yani gerçeklerin ve yalanların
											yayılışındaki farklılıkların
sorumlusu botlar değil.
											Bu sorumluluğu başkasına atamayız
											çünkü o yayılmanın sorumlusu 
biz insanlarız.
									","
											Ao mesmo tempo,
houve testemunhos
											em ambas as câmaras
do Congresso dos EUA,
											sobre o papel dos robôs
na propagação da desinformação.
											Também estudámos isso
											— utilizámos vários algoritmos 
sofisticados para detetar robôs
											para os encontrar nos nossos dados
e retirá-los de lá.
											Retirámo-los e voltámos a colocá-los
											e comparámos o que acontece
à nossa medição.
											O que encontrámos foi que, de facto,
											os robôs aceleravam a propagação
das notícias falsas ""online"",
											mas aceleravam a propagação
de notícias verdadeiras
											aproximadamente da mesma forma.
											O que significa que os robôs
não são responsáveis
											pelas diferenças entre a difusão
da verdade e da mentira ""online"".
											Não podemos abdicar
dessa responsabilidade,
											porque nós, seres humanos,
somos responsáveis por essa divulgação.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											Now, everything
that I have told you so far,
											unfortunately for all of us,
											is the good news.
									","
											Tout ce que je vous ai dit jusqu'ici,
											malheureusement pour nous tous,
											ce sont les bonnes nouvelles.
									","
											Şimdiye kadar anlattıklarım
											ne yazık ki
											işin iyi yanıydı.
									","
											Infelizmente para todos nós,
											tudo que vos disse até agora
											é a melhor parte.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											The reason is because
it's about to get a whole lot worse.
											And two specific technologies
are going to make it worse.
											We are going to see the rise
of a tremendous wave of synthetic media.
											Fake video, fake audio
that is very convincing to the human eye.
											And this will powered by two technologies.
									","
											La raison en est que cela
va bientôt devenir bien pire.
											Deux technologies en particulier
vont rendre cela bien pire.
											Nous allons voir la montée
d'une énorme vague de média synthétiques :
											de fausses vidéos, de faux enregistrements
très convaincants pour l’œil humain.
											Cela sera propulsé par deux technologies.
									","
											Bunun sebebi daha da kötüye
gidecek olması.
											Bunu kötüleştirecek
iki belli başlı teknoloji var.
											Sentetik medya dalgasında
ciddi bir artış göreceğiz.
											Dışarıdan bakıldığında ikna edici görünen
sahte video, sahte seslendirme.
											Ve iki teknoloji bunu besleyecek.
									","
											As coisas vão piorar bastante.
											Duas tecnologias específicas 
vão piorar tudo.
											Veremos a ascensão de uma enorme
onda de conteúdos sintéticos.
											Vídeos e áudios falsos muito convincentes
para o olhar humano.
											Isso será alimentado por duas tecnologias.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											The first of these is known
as ""generative adversarial networks.""
											This is a machine-learning model
with two networks:
											a discriminator,
											whose job it is to determine
whether something is true or false,
											and a generator,
											whose job it is to generate
synthetic media.
											So the synthetic generator
generates synthetic video or audio,
											and the discriminator tries to tell,
""Is this real or is this fake?""
											And in fact, it is the job
of the generator
											to maximize the likelihood
that it will fool the discriminator
											into thinking the synthetic
video and audio that it is creating
											is actually true.
											Imagine a machine in a hyperloop,
											trying to get better
and better at fooling us.
									","
											La première est connue sous le nom
de « réseaux adverses génératifs ».
											C'est un modèle d'apprentissage
automatique avec deux réseaux :
											un discriminateur,
											dont le rôle est de déterminer
si quelque chose est vrai ou faux,
											et un générateur,
											dont le rôle est de générer
des médias synthétiques.
											Le générateur synthétique génère une vidéo
ou un enregistrement audio synthétique
											et le discriminateur essaye de dire
s'il est réel ou falsifié.
											La tâche du générateur
											consiste à maximiser la probabilité
de faire croire au discriminateur
											que la vidéo et l'enregistrement audio
qu'il crée sont réels.
											Imaginez une machine
dans une boucle infinie
											et essayant d'améliorer
sa capacité à nous tromper.
									","
											İlki ""üretken çekişmeli ağlar"" 
olarak biliniyor.
											Bu, iki ağlı bir makine öğrenimi modeli:
											Bir şeyin gerçek mi sahte mi
											olduğunu belirlemekle görevli
bir ayrıştırıcı
											ve sentetik medya
											üretmekle yükümlü üretici.
											Sentetik üretici, 
sentetik video veya sesi üretir
											ve ayrıştırıcı şunu belirlemeyi dener:
""Bu sahte mi, gerçek mi?""
											Aslında üreticinin işi
											yarattığı sentetik video ve sesin 
ayrıştıcı tarafından
											gerçek sanılması ihtimalini
											artırmaktır.
											Bizi kandırmakta ustalaşmaya çalışan,
											döngüye takılmış bir makine hayal edin.
									","
											A primeira é conhecida por
""rede generativa antagónica.""
											Trata-se de um modelo de aprendizagem
de máquina com duas redes:
											um discriminador,
											cuja função é determinar
se algo é verdadeiro ou falso,
											e um gerador,
											cuja função é gerar
conteúdos sintéticos.
											O gerador sintético produz áudios
e vídeos sintéticos,
											e o discriminador tenta dizer-nos: 
''Isto é real ou é falso?""
											A função do gerador
											é maximizar a probabilidade 
de enganar o discriminador
											para que este julgue que os áudios
e vídeos sintéticos que está a criar
											são, de facto, verdadeiros.
											Imaginem uma máquina num ciclo
											a tentar ser cada vez melhor
no ato de nos enganar.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											This, combined with the second technology,
											which is essentially the democratization
of artificial intelligence to the people,
											the ability for anyone,
											without any background
in artificial intelligence
											or machine learning,
											to deploy these kinds of algorithms
to generate synthetic media
											makes it ultimately so much easier
to create videos.
									","
											Cela, en combinaison
avec la deuxième technologie,
											qui est essentiellement la démocratisation
de l'intelligence artificielle,
											la capacité offerte à tous,
											sans aucune formation
en intelligence artificielle
											ou en apprentissage automatique,
											de déployer ce genre d'algorithmes
pour générer des médias synthétiques
											rendant cela tellement plus simple
de créer des vidéos.
									","
											Bu, ikinci teknolojiyle,
											yapay zekânın demokratikleştirilmesiyle,
yani makine öğrenimi
											veya yapay zekâ konusunda
											herhangi bir eğitimi olmayan 
kişilerin bile
											sentetik medya üretmek için
											bu tür algoritmaları
kullanabilmesiyle birleşince
											videoların yaratılması
fazlasıyla kolaylaşıyor.
									","
											Isto, combinado com a segunda tecnologia,
											que é basicamente a democratização
da inteligência artificial para as pessoas,
											a capacidade de qualquer pessoa,
											sem nenhuma compreensão
sobre inteligência artificial,
											ou aprendizagem de máquina,
											para utilizar este tipo de algoritmos
para gerar conteúdos sintéticos
											faz com que seja
muito mais fácil criar vídeos.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											The White House issued
a false, doctored video
											of a journalist interacting with an intern
who was trying to take his microphone.
											They removed frames from this video
											in order to make his actions
seem more punchy.
											And when videographers
and stuntmen and women
											were interviewed
about this type of technique,
											they said, ""Yes, we use this
in the movies all the time
											to make our punches and kicks
look more choppy and more aggressive.""
											They then put out this video
											and partly used it as justification
											to revoke Jim Acosta,
the reporter's, press pass
											from the White House.
											And CNN had to sue
to have that press pass reinstated.
									","
											La Maison-Blanche a publié
une vidéo falsifiée, truquée
											d'un journaliste interagissant
avec une stagiaire
											et essayant de prendre son micro.
											Ils ont enlevé des images de cette vidéo
											afin que ces actes
paraissent plus percutants.
											Quand des vidéastes,
des cascadeurs et des cascadeuses
											ont été interrogés
sur ce genre de technique,
											ils ont dit : « Oui, nous utilisons
constamment cela dans les films
											pour que nos coups de poing et de pied
paraissent plus musclés et agressifs. »
											Ils ont ensuite publié cette vidéo
											l'ont utilisée
comme justification partielle
											pour révoquer la carte de presse
de Jim Acosta, le journaliste,
											pour la Maison-Blanche.
											CNN a dû aller en justice pour faire
rétablir cette carte de presse.
									","
											Beyaz Saray bir gazetecinin
mikrofonunu almaya çalışan stajyerle
											etkileşimini gösteren sahte,
üstünde oynanmış bir video yayınladı.
											Eylemlerini daha dramatik kılmak için
											bu videodan bazı kareleri çıkardılar.
											Bu teknik konusunda
											videograflar ve dublörlerle görüşüldüğünde
											""Evet, yumruklarımız ve tekmelerimiz
daha etkileyici ve saldırgan görünsün diye
											filmlerde bunu hep kullanırız."" dediler.
											Sonra bu videoyu yayınladılar
											ve bahsi geçen gazeteci olan
Jim Acosta'nın,
											Beyaz Saray basın kartını
											iptal etmekte kullandılar.
											Basın kartının yeniden çıkarılması için
CNN dava açmak zorunda kaldı.
									","
											A Casa Branca partilhou
um vídeo falso, adulterado
											de um jornalista a interagir
com uma estagiária
											que tentava tirar-lhe o microfone.
											Eles removeram partes desse vídeo
											para fazer a ação do jornalista
parecer mais agressiva.
											Quando videógrafos e duplos
											foram entrevistados
sobre este tipo de técnica,
											disseram: ""Sim, usamo-la
com frequência em filmes
											""para fazer com que os nossos socos
e pontapés pareçam mais agressivos.""
											Eles partilharam este vídeo
											e usaram-no em parte como justificação
											para cancelar a credencial
do repórter Jim Acosta,
											da Casa Branca.
											A CNN teve de processar judicialmente
para revalidar a credencial.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											There are about five different paths
that I can think of that we can follow
											to try and address some
of these very difficult problems today.
											Each one of them has promise,
											but each one of them
has its own challenges.
											The first one is labeling.
											Think about it this way:
											when you go to the grocery store
to buy food to consume,
											it's extensively labeled.
											You know how many calories it has,
											how much fat it contains —
											and yet when we consume information,
we have no labels whatsoever.
											What is contained in this information?
											Is the source credible?
											Where is this information gathered from?
											We have none of that information
											when we are consuming information.
											That is a potential avenue,
but it comes with its challenges.
											For instance, who gets to decide,
in society, what's true and what's false?
											Is it the governments?
											Is it Facebook?
											Is it an independent
consortium of fact-checkers?
											And who's checking the fact-checkers?
									","
											Il y a environ cinq chemins différents
											que je peux imaginer
et que nous pourrions suivre
											pour essayer de remédier
à ces problèmes très difficiles.
											Chacun est prometteur
											mais chacun a des défis
qui lui sont propres.
											Le premier est l'étiquetage.
											Réfléchissez-y :
											quand vous allez au supermarché
pour acheter de la nourriture,
											elle est amplement étiquetée.
											Vous savez combien
de calories elle contient,
											combien de graisses —
											et pourtant, quand
nous consommons des informations,
											nous n'avons pas d'étiquettes.
											Que contient cette information ?
											La source est-elle crédible ?
											Où cette information
a-t-elle été recueillie ?
											Nous n'avons aucune de ces informations
											quand nous consommons des informations.
											C'est une solution potentielle,
mais elle a ses défis.
											Par exemple, qui décide, dans la société,
ce qui est vrai et ce qui est faux ?
											Est-ce que ce sont les gouvernements ?
											Est-ce Facebook ?
											Est-ce un consortium indépendant
de vérificateurs d'informations ?
											Et qui contrôle ceux
qui vérifient les informations ?
									","
											Bugün bu son derece zor 
sorunları çözmek için
											izleyebileceğimiz beş yol aklıma geliyor.
											Hepsinin potansiyeli var
											ama kendilerine göre zorlukları da var.
											İlki etiketleme.
											Bunu şöyle düşünün:
											Yiyecek almak için markete gittiğinizde
											hepsi detaylı şekilde etiketlenmiş.
											Kaç kalorisi olduğunu,
											ne kadar yağ içerdiğini biliyorsunuz
											ama tükettiğimiz bilgilerin
hiçbir etiketi yok.
											Bu bilgi neleri kapsıyor?
											Kaynağı güvenilir mi?
											Bilgi nereden toplanmış?
											Bilgileri tüketirken
											bu bilgiler bize verilmiyor.
											Bu izlenebilecek bir yol
ama kendine özgü sorunları var.
											Mesela bir toplumda neyin doğru
neyin yanlış olduğuna kim karar verir?
											Hükûmet mi?
											Facebook mu?
											Bilgileri kontrol eden 
bağımsız bir kurul mu?
											Peki onları kim kontrol edecek?
									","
											Ocorrem-me cinco caminhos
que podemos seguir
											para tentar resolver alguns
destes problemas difíceis.
											Cada um deles inclui uma promessa,
											mas cada um tem os seus próprios desafios.
											O primeiro é a rotulagem.
											Pensemos da seguinte forma:
											quando vamos ao supermercado
comprar a comida que consumimos,
											esta está extensivamente rotulada.
											Sabemos quantas calorias tem,
											a gordura que contém
											— no entanto, ao consumirmos informações
não temos nenhum tipo de rótulo.
											Qual o conteúdo dessas informações?
											A fonte é credível?
											Qual a proveniência dessas informações?
											Não temos esse tipo de informação
											quando consumimos informações.
											É uma possibilidade,
mas coloca alguns desafios.
											Por exemplo, na sociedade, quem decide
o que é verdadeiro ou falso?
											É o governo?
											É o Facebook?
											É um consórcio independente
de verificadores de factos?
											Quem verifica os verificadores de factos?
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											Another potential avenue is incentives.
											We know that during
the US presidential election
											there was a wave of misinformation
that came from Macedonia
											that didn't have any political motive
											but instead had an economic motive.
											And this economic motive existed,
											because false news travels
so much farther, faster
											and more deeply than the truth,
											and you can earn advertising dollars
as you garner eyeballs and attention
											with this type of information.
											But if we can depress the spread
of this information,
											perhaps it would reduce
the economic incentive
											to produce it at all in the first place.
									","
											Une autre option possible,
ce sont les incitations.
											Nous savons que durant les élections
présidentielles américaines,
											il y a eu une vague de désinformation
venue de Macédoine du Nord
											qui n'avait aucun mobile politique
											mais avait un mobile économique.
											Ce mobile économique existait
											car l'infox circule
tellement plus loin, plus vite
											et plus profondément que la vérité
											et vous pouvez gagner de l'argent
dans la publicité
											alors que vous recueillez
les regards et l'attention
											avec ce genre d'informations.
											Mais si nous pouvons réduire
la diffusion de ces informations,
											peut-être cela réduirait-il
l'incitation économique à les produire.
									","
											Bir diğer yol, teşvik.
											ABD başkanlık seçimi sırasında
											Makedonya'dan bir yanlış bilgi dalgası
geldiğini biliyoruz.
											Amaçları siyasi değil,
											ekonomikti.
											Bu ekonomik amaç, var olabilmesini
											yalan haberin, 
doğrulardan çok daha hızlı,
											çok daha derinlere yayılmasına borçlu
											ve bu tür bilgilerle 
insanların ilgisini çekerek
											reklam geliri elde edebilirsiniz.
											Ama bu bilginin yayılmasını baskılarsak
											belki de daha baştan
yaratılmasına sebep olan
											ekonomik teşvikleri de azaltırız.
									","
											Outra possibilidade são os incentivos.
											Sabemos que, durante
as eleições presidenciais nos EUA,
											houve uma onda de desinformação
proveniente da Macedónia
											sem qualquer motivação política
											mas com motivação económica.
											Esta motivação económica existiu
											porque as notícias falsas chegam
muito mais longe, mais depressa
											e mais profundamente do que a verdade,
											porque podemos ganhar dinheiro
em publicidade, atraindo as atenções
											com esse tipo de informações.
											Mas se pudermos diminuir a propagação
deste tipo de informações,
											talvez isso reduza o incentivo económico
											de produzir este tipo de informações.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											Third, we can think about regulation,
											and certainly, we should think
about this option.
											In the United States, currently,
											we are exploring what might happen
if Facebook and others are regulated.
											While we should consider things
like regulating political speech,
											labeling the fact
that it's political speech,
											making sure foreign actors
can't fund political speech,
											it also has its own dangers.
											For instance, Malaysia just instituted
a six-year prison sentence
											for anyone found spreading misinformation.
											And in authoritarian regimes,
											these kinds of policies can be used
to suppress minority opinions
											and to continue to extend repression.
									","
											Troisièmement, nous pouvons
réfléchir à une réglementation
											et nous devrions réfléchir à cette option.
											Actuellement aux États-Unis,
											nous explorons ce qu'il pourrait se passer
											si Facebook et les autres
étaient réglementés.
											Si nous devrions considérer des choses
comme réglementer le discours politique,
											l'étiqueter comme étant
du discours politique,
											nous assurer que les acteurs étrangers
											ne puissent pas financer
un discours politique,
											cela a aussi ses dangers.
											Par exemple, la Malaisie vient d'instituer
une peine de prison de six ans
											pour quiconque diffusant
de la désinformation.
											Dans les régimes autoritaires,
											ce genre de politiques
peuvent être utilisées
											pour étouffer les opinions minoritaires
											et continuer à accroître la répression.
									","
											Üçüncüsü, denetim.
											Bu seçeneği düşünmemiz gerektiği kesin.
											Şu anda ABD'de
											Facebook ve benzerleri denetim altına 
alınsa ne olacağını araştırıyoruz.
											Siyasi söylemleri denetlemeyi,
onları siyasi söylem olarak etiketlemeyi,
											dış mihrakların siyasi söylemleri 
finanse etmesini
											engellemeyi göz önünde
bulundurmamız gerekse de
											bunların da kendince tehlikeleri var.
											Mesela Malezya yalan bilgi yaydığı
tespit edilenlere
											altı yıl hapis cezası getirdi.
											Otoriter rejimlerde
											bu tür düzenlemeler 
azınlık görüşlerini bastırmak
											ve baskının kapsamını genişletmek
amacıyla kullanılabilir.
									","
											Em terceiro lugar,
podemos pensar em regulamentação,
											e certamente, devíamos
considerar esta opção.
											Atualmente, nos EUA,
											estamos a estudar o que aconteceria
se o Facebook e outros fossem regulados.
											Embora devêssemos considerar coisas
como regular o discurso político,
											rotular o facto de se tratar
de discurso político,
											garantir que elementos estrangeiros
não possam financiar o discurso político
											isso também acarreta os seus perigos.
											Por exemplo, recentemente a Malásia
instituiu uma sentença de 6 anos de prisão
											para qualquer pessoa
que propague desinformações.
											Em regimes autoritários,
											esta política pode ser usada
para reprimir opiniões de minorias
											e manter a repressão.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											The fourth possible option
is transparency.
											We want to know
how do Facebook's algorithms work.
											How does the data
combine with the algorithms
											to produce the outcomes that we see?
											We want them to open the kimono
											and show us exactly the inner workings
of how Facebook is working.
											And if we want to know
social media's effect on society,
											we need scientists, researchers
											and others to have access
to this kind of information.
											But at the same time,
											we are asking Facebook
to lock everything down,
											to keep all of the data secure.
									","
											La quatrième option possible
est la transparence.
											Nous voulons savoir comment fonctionnent
les algorithmes de Facebook.
											Comment les données
se combinent-elles aux algorithmes
											pour générer les résultats
que nous observons ?
											Nous voulons qu'ils ouvrent le kimono
											et nous montrent les rouages internes
du fonctionnement de Facebook.
											Pour connaître les effets
des réseaux sociaux sur la société,
											il faut que les scientifiques,
les chercheurs
											et les autres aient accès
à ce genre d'informations.
											Mais en même temps,
											nous demandons à Facebook
de tout verrouiller
											pour assurer la sécurité des données.
									","
											Dördüncü olasılık, şeffaflık.
											Facebook'un algoritmalarının
nasıl çalıştığını bilmek istiyoruz.
											Algoritmalarla birleşen veriler
											nasıl oluyor da
gördüğümüz sonuçları doğuruyor?
											Kapıyı açmalarını
											ve Facebook'un nasıl işlediğini
göstermelerini istiyoruz.
											Sosyal medyanın toplumdaki
etkilerini öğrenmek istiyorsak
											bilim insanları, araştırmacılar
											ve benzerlerinin bu tür bilgilere
erişmesine ihtiyacımız var.
											Ama aynı zamanda
											Facebook'tan her şeyi kilitlemesini,
											tüm verileri güvende tutmasını istiyoruz.
									","
											A quarta opção possível é a transparência.
											Queremos saber como funcionam
os algoritmos do Facebook.
											Como é que os dados
se combinam com os algoritmos
											para produzir os resultados que vemos?
											Queremos que eles ""abram o quimono""
											e nos mostrem o funcionamento
interno do Facebook.
											E se quisermos saber o impacto
das redes sociais na sociedade
											precisamos de cientistas e investigadores
											e outros meios de acesso
a este tipo de informações.
											Mas, simultaneamente,
											estamos a pedir ao Facebook
para trancar tudo,
											para guardar todas as informações
de forma segura.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											So, Facebook and the other
social media platforms
											are facing what I call
a transparency paradox.
											We are asking them, at the same time,
											to be open and transparent
and, simultaneously secure.
											This is a very difficult needle to thread,
											but they will need to thread this needle
											if we are to achieve the promise
of social technologies
											while avoiding their peril.
									","
											Facebook et les autres plateformes
de réseaux sociaux
											font face à ce que j'appelle
un paradoxe de la transparence.
											Nous leur demandons à la fois
											d'être ouverts et transparents
et, simultanément, d'être sécurisés.
											Cela est difficile à accomplir,
											mais ils devront le faire
											si nous voulons
											que les technologies sociales
tiennent leurs promesses
											tout en évitant les risques.
									","
											Bu yüzden Facebook 
ve diğer sosyal medya platformları
											şeffaflık paradoksu dediğim şeyle
karşı karşıya.
											Onlardan hem açık ve şeffaf olmalarını
											hem de güvenli olmalarını istiyoruz.
											Bu, zor bir görev
											ama sosyal teknolojilerin 
potansiyelini değerlendirip
											tehlikelerinden kaçınacaksak
											bu görevi başarmalılar.
									","
											O Facebook e outras plataformas
de redes sociais
											estão a enfrentar o que chamamos
de paradoxo da transparência.
											Pedimos-lhes para serem, simultaneamente
											abertos, transparentes e seguros.
											É uma linha muito difícil de traçar,
											mas deverão traçá-la
											se o objetivo for cumprir a promessa
das tecnologias sociais
											enquanto evitamos os seus perigos.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											The final thing that we could think about
is algorithms and machine learning.
											Technology devised to root out
and understand fake news, how it spreads,
											and to try and dampen its flow.
											Humans have to be in the loop
of this technology,
											because we can never escape
											that underlying any technological
solution or approach
											is a fundamental ethical
and philosophical question
											about how do we define truth and falsity,
											to whom do we give the power
to define truth and falsity
											and which opinions are legitimate,
											which type of speech
should be allowed and so on.
											Technology is not a solution for that.
											Ethics and philosophy
is a solution for that.
									","
											Pour finir, nous pourrions réfléchir
											aux algorithmes
et à l'apprentissage automatique.
											Une technologie conçue pour éradiquer
et comprendre l'infox, sa diffusion,
											et essayer d'atténuer sa circulation.
											Les êtres humains doivent
jouer un rôle dans cette technologie
											car nous ne pourrons jamais
échapper au fait
											que pour toute solution
ou approche technologie,
											il y a une question éthique
et philosophique fondamentale
											quant à notre définition
du vrai et du faux,
											à qui nous donnons le pouvoir
de définir le vrai et le faux
											et quelles opinions sont légitimes,
											une rapidité de quel ordre de grandeur
devrait être autorisée et ainsi de suite.
											La technologie n'est pas la solution.
											L'éthique et la philosophie le sont.
									","
											Düşünmemiz gereken son konu,
algoritmalar ve makine öğrenimi.
											Yalan haberlerin köküne inip
onları, nasıl yayıldıklarını anlamamızı,
											akışı yavaşlatmamızı
sağlayacak teknolojiler.
											İnsanlar bu teknolojiden haberdar olmalı
											çünkü her teknolojik çözümün
											veya yaklaşımın temelinde,
doğruyu ve yalanı nasıl tanımlıyoruz,
											doğrunun ve yalanın ne olduğunu
											tanımlama gücünü kime veriyoruz,
											hangi görüş doğru, 
hangi söylemlere izin verilmeli gibi
											ahlaki ve felsefi soruların
											yattığı gerçeğinden asla kaçamayız.
											Bunun çözümü teknoloji değil.
											Bunun çözümü ahlak ve felsefe.
									","
											O último aspeto são os algoritmos
e a aprendizagem de máquina
											Tecnologia criada para retirar
notícias falsas, compreendê-las,
											como se propagam
e tentar diminuir o seu fluxo.
											Precisamos de compreender
esta tecnologia,
											porque nunca vamos escapar
ao facto de que
											subjacentes a qualquer solução
ou abordagem tecnológica
											estão as questões éticas
e filosóficas fundamentais
											sobre como definimos 
a verdade e a falsidade,
											a quem atribuímos o poder
para definir a verdade e a falsidade,
											que opiniões são legítimas,
											e que tipo de discurso
deve ser permitido, etc.
											A tecnologia não é uma solução para isso.
											A solução é a ética e a filosofia.
											Quase todas as teorias
sobre a tomada de decisões humanas,
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											Nearly every theory
of human decision making,
											human cooperation and human coordination
											has some sense of the truth at its core.
											But with the rise of fake news,
											the rise of fake video,
											the rise of fake audio,
											we are teetering on the brink
of the end of reality,
											where we cannot tell
what is real from what is fake.
											And that's potentially
incredibly dangerous.
									","
											Presque toutes les théories
sur la prise de décision humaine,
											la coopération humaine
et la coordination humaine
											ont une part de vérité en elles.
											Mais avec l'essor des infox,
											l'essor des vidéos truquées,
											l'essor des enregistrements
audios truqués,
											nous vacillons au bord
de la fin de la réalité,
											où nous ne pouvons pas discerner
ce qui est réel et ce qui est faux.
											Cela est potentiellement
incroyablement dangereux.
									","
											İnsanların karar vermesi, iş birliği
											ve koordinasyonu hakkındaki 
tüm teorilerin özünde
											bir tür gerçek anlayışı yatar.
											Ama yalan haberlerin,
											sahte videoların,
											sahte seslendirmelerin artışıyla
											gerçeğin kıyısındaki bir noktaya geldik,
											neyin gerçek neyin yalan olduğunu
ayırt edemiyoruz
											ve bu, çok tehlikeli olabilir.
									","
											a cooperação e coordenação humanas,
											têm, no seu cerne,
um sentido do que é a verdade.
											Mas, com o aumento das notícias falsas,
											com o aumento dos vídeos falsos,
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											We have to be vigilant
in defending the truth
											against misinformation.
											With our technologies, with our policies
											and, perhaps most importantly,
											with our own individual responsibilities,
											decisions, behaviors and actions.
									","
											Nous devons être vigilants
dans la défense de la vérité
											face à la désinformation.
											Avec nos technologies, avec nos politiques
											et, peut-être surtout, individuellement,
											avec nos responsabilités, nos décisions,
											nos comportements
et nos actions.
									","
											Yanlış bilgilendirmeye karşı
gerçekleri savunmak adına
											tetikte olmalıyız.
											Teknolojilerimiz, politikalarımız
											ve belki de en önemlisi
											bireysel sorumluluklarımızla,
											kararlarımız, davranışlarımız
ve eylemlerimizle.
									","
											o aumento dos áudios falsos,
											estamos no limiar do fim da realidade
											em que não sabemos o que é a verdade
e o que é a mentira.
											E isso é potencialmente 
incrivelmente perigoso.
											Temos de ser vigilantes
em defender a verdade
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											Thank you very much.
									","
											Merci beaucoup.
									","
											Çok teşekkürler.
									","
											contra a desinformação.
											Com as nossas tecnologias,
com as nossas políticas
											e, talvez, o mais importante,
											com as nossas 
responsabilidades individuais,
											as decisões, os comportamentos e as ações.
											Muito obrigado.
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
											(Applause)
									","
											(Applaudissements)
									","
											(Alkışlar)
									","
											(Aplausos)
									",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
"
","
","
","
",How we can protect truth in the age of misinformation,Sinan Aral,15:03,"news,Internet,social media,global issues,data,society,TEDx"
