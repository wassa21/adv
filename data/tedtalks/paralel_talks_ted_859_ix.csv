en,es,pt,tr,fr,de,title,speaker,duration,tags
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Power.
											That is the word that comes to mind.
											We're the new technologists.
											We have a lot of data, so we have a lot of power.
											How much power do we have?
											Scene from a movie: ""Apocalypse Now"" — great movie.
											We've got to get our hero, Captain Willard, to the mouth of the Nung River
											so he can go pursue Colonel Kurtz.
											The way we're going to do this is fly him in and drop him off.
											So the scene:
											the sky is filled with this fleet of helicopters carrying him in.
											And there's this loud, thrilling music in the background,
											this wild music.
											♫ Dum da ta da dum ♫
											♫ Dum da ta da dum ♫
											♫ Da ta da da ♫
											That's a lot of power.
											That's the kind of power I feel in this room.
											That's the kind of power we have
											because of all of the data that we have.
									","
											Poder.
											Esa es la palabra que viene a la mente.
											Somos los nuevos tecnólogos.
											Tenemos gran cantidad de información, así que tenemos mucho poder.
											¿Cuánto poder tenemos?
											Escena de la película: ""Apocalipsis Now"" — excelente película.
											Tenemos que llevar a nuestro héroe, el capitán Willard, a la desembocadura del río Nung
											para que pueda perseguir al coronel Kurtz.
											Para esto, lo vamos a transportar volando y lo dejamos en el lugar.
											En esta escena
											el cielo está repleto de helicópteros que lo llevan.
											Hay de fondo una música fuerte y emocionante,
											una música desenfrenada.
											♫ Dum da ta da dum ♫
											♫ Dum da ta da dum ♫
											♫ Da ta da da ♫
											Hay mucha potencia.
											La clase de potencia que siento en esta sala.
											Es el poder que nos da
											toda la información que tenemos.
									","
											Poder.
											Esta é a palavra que nos vem à mente.
											Somos os novos tecnólogos.
											Temos muita informação,
por isso temos muito poder.
											Quanto poder temos?
											Cena de um filme: ""Apocalypse Now""
— um grande filme.
											Temos que levar o herói, 
Capitão Willard, até à foz do Rio Nung
											para que ele persiga o Coronel Kurtz
											— transportá-lo por via aérea
e largá-lo no local.
											Eis a cena:
											o céu está coberto pela esquadrilha
de helicópteros que o transportam.
											No fundo, uma música
alta e arrebatadora,
											uma música selvagem.
											♫Dum da ta da dum ♫
											♫ Dum da ta da dum ♫
											♫ Da ta da da ♫
											É um enorme poder.
											É o tipo de poder que sinto nesta sala.
											É o tipo de poder que nós temos
											devido a toda a informação que temos.
									","
											Güç
											Akla gelen kelime bu.
											Biz yeni teknoloji uzmanlarıyız.
											Çok fazla verimiz var, bu yüzden de çok fazla güce sahibiz.
											Peki, ne kadar gücümüz var?
											Bir filmden sahne, ""Apocalypse Now (Kıyamet)"" — harika bir film.
											Kahramanımızı yani Kaptan Willard'ı Nung Nehri'nin ağzına götürmemiz gerek
											o da böylece Albay Kurtz'u takip edebilecek.
											Bunu yapmak için de, onu oraya uçurup iniş yaptıracağız.
											Ve sahne:
											gökyüzü onu oraya taşıyan helikopter filosuyla doludur.
											Ve arkada şu yüksek sesli, heyecanlı müzik çalar.
											Şu çılgınca parça.
											♫ Dum da ta da dum ♫
											♫ Dum da ta da dum ♫
											♫ Da ta da da ♫
											İşte bu büyük bir güç.
											Benim bu salonda hissettiğim türden güç.
											Bu, elimizdeki tüm o veriler sayesinde
											bizde olan türden bir güç.
									","
											Le pouvoir.
											C'est le mot qui vient à l'esprit.
											Nous sommes les nouveaux technologues.
											Nous avons beaucoup de données, donc nous avons beaucoup de pouvoir.
											Quelle quantité de pouvoir avons-nous ?
											Une scène du film ""Apocalypse Now"" — un grand film.
											Nous devons amener notre héros, le capitaine Willard, à l'embouchure de la rivière Nung,
											pour qu'il puisse poursuivre le colonel Kurtz.
											Pour cela, nous allons le transporter en hélico et le déposer.
											Dans cette scène :
											le ciel est rempli de cette flotte d'hélicoptères qui le transportent.
											Il y a cette musique bruyante et palpitante en fond,
											cette musique effrénée.
											♫ Dum da ta da dum ♫
											♫ Dum da ta da dum ♫
											♫ Da ta da da ♫
											C'est un grand pouvoir.
											C'est le genre de pouvoir que je ressens dans cette pièce.
											C'est le genre de pouvoir que nous avons
											grâce à toutes les données que nous possédons.
									","
											Macht.
											Das ist das Wort, das einem in den Sinn kommt.
											Wir sind die neuen Technologen.
											Wir haben viele Daten, also haben wir viel Macht.
											Wieviel Macht haben wir?
											Eine Szene aus dem Film ""Apocalypse Now"" – toller Film.
											Wir müssen unseren Helden, Captain Willard, zur Mündung des Nung River kriegen,
											damit er Colonel Kurtz verfolgen kann.
											Wir werden das tun, indem wir ihn hinfliegen und abwerfen.
											Also, die Szene:
											am Himmel die Helikopterflotte, die ihn hinbringt.
											Und da ist diese laute, mitreissende Musik im Hintergrund,
											diese wilde Musik.
											♫ Dum da ta da dum ♫
											♫ Dum da ta da dum ♫
											♫ Da ta da da ♫
											Das ist viel Macht.
											Das ist die Art von Macht, die ich in diesem Raum spüre.
											Es ist die Art von Macht, die wir haben
											infolge all der Daten, die wir haben.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Let's take an example.
											What can we do
											with just one person's data?
											What can we do
											with that guy's data?
											I can look at your financial records.
											I can tell if you pay your bills on time.
											I know if you're good to give a loan to.
											I can look at your medical records; I can see if your pump is still pumping —
											see if you're good to offer insurance to.
											I can look at your clicking patterns.
											When you come to my website, I actually know what you're going to do already
											because I've seen you visit millions of websites before.
											And I'm sorry to tell you,
											you're like a poker player, you have a tell.
											I can tell with data analysis what you're going to do
											before you even do it.
											I know what you like. I know who you are,
											and that's even before I look at your mail
											or your phone.
									","
											Pongamos un ejemplo:
											¿Qué podemos hacer
											con la información de una sola persona?
											¿Qué podemos hacer
											con la información de ese señor?
											Puedo mirar sus registros financieros.
											Puedo decir si paga sus cuentas puntualmente.
											Sé si reúne las condiciones para que le den un préstamo.
											Puedo ver su historia clínica, puedo ver si aún late su corazón;
											ver si está bien para que le ofrezcan un seguro.
											Puedo observar sus hábitos en Internet.
											Cuando viene a mi sitio web, en realidad ya sé lo que va a hacer,
											porque lo he visto visitar millones de sitios web antes.
											Y lamento decirlo,
											eres como un jugador de póquer, tienes esa manía.
											Analizando datos puedo decir lo que vas a hacer
											aún antes que lo hagas.
											Sé lo que te gusta. Sé quién eres.
											Incluso antes de mirar tu correo
											o tu teléfono.
									","
											Tomemos um exemplo.
											O que é que podemos fazer
											com os dados de apenas uma pessoa?
											O que é que podemos fazer
											com os dados daquele indivíduo?
											Posso ver os seus registos financeiros.
											Posso dizer se paga as contas a horas,
											se tem condições para pedir um empréstimo.
											Posso ver os registos clínicos,
ver se o coração ainda bate,
											ver se está bem,
para lhe oferecer um seguro.
											Posso observar
os seus hábitos na Internet.
											Quando visita o meu sitio na Internet,
já sei o que vai fazer,
											porque o vi visitar milhões
de sítios anteriormente.
											E, lamento dizer-lhe,
											parece um jogador de póquer, descai-se.
											Analisando os dados, sei o que vai fazer
											antes mesmo de você o fazer.
											Eu sei do que você gosta.
Sei quem você é.
											E isso, antes mesmo de ver
o seu correio ou o seu telemóvel.
									","
											Bir örnek ele alalım.
											Sadece bir kişinin verileriyle
											ne yapabiliriz?
											Mesela şuradaki adamın
											verileriyle ne yapabiliriz?
											Finansal kayıtlarına bakabilirim.
											Faturalarını zamanında ödeyip ödemediğini söyleyebilirim.
											Borç vermeye uygun olup olmadığını öğrenebilirim.
											Tıbbi kayıtlarına bakıp, kalbinin sağlam olup olmadığını görebilir —
											böylece sigorta teklif etmeye uygun mu görebilirim.
											İnternet eğilimlerine bakabilirim.
											İnternet sayfama geldiğinde, aslında ne yapacağını önceden biliyorum.
											çünkü milyonlarca internet sayfasını ziyaret edişini gördüm
											Ve üzgünüm ama,
											tıpkı bir poker oyuncusu gibisin, bunu söylemek zorundayım.
											Veri analizleri ile ne yapacağını sana
											sen daha yapmadan söyleyebilirim.
											Nelerden hoşlandığını, kim olduğunu biliyorum.
											Hem de daha e-postana bakmadan önce bile
											ya da telefonuna.
									","
											Prenons un exemple.
											Que pouvons-nous faire
											avec les données d'une seule personne ?
											Que pouvons-nous faire
											avec les données de ce type ?
											Je peux regarder vos registres financiers.
											Je peux vous dire si vous payez vos factures à temps.
											Je sais alors si je peux vous faire un prêt.
											Je peux regarder votre dossier médical, je peux voir si votre cœur fonctionne bien —
											voir si je peux vous proposer une assurance.
											Je peux regarder où vous cliquez sur Internet.
											Quand vous visitez mon site, je sais déjà ce que vous allez faire,
											parce que je vous ai vu visiter des millions de sites auparavant.
											Je suis désolé de vous dire,
											vous êtes comme un joueur de poker, vous avez des manies.
											Je peux dire grâce à l'analyse de données ce que vous allez faire
											avant même que vous ne le fassiez.
											Je sais ce que vous aimez. Je sais qui vous êtes.
											Et cela avant même que je regarde votre courrier
											ou votre téléphone.
									","
											Lassen Sie uns ein Beispiel anschauen.
											Was können wir mit
											den Daten einer einzelnen Person machen?
											Was können wir mit den Daten
											dieses Mannes hier tun?
											Ich kann mir Ihre Finanzbelege ansehen.
											Ich kann sagen, ob Sie Ihre Rechnungen pünktlich bezahlen.
											Ich weiss, ob man Ihnen ein Darlehen geben sollte.
											Ich kann Ihre medizinische Akte einsehen, ob Ihre Pumpe noch pumpt –
											sehen, ob wir Sie versichern sollten.
											Ich kann mir Ihre Klickmuster ansehen.
											Wenn Sie meine Website besuchen, dann weiss ich schon, was Sie tun werden,
											weil ich Sie zuvor Millionen von Websites habe besuchen sehen.
											Und es tut mir Leid, Ihnen zu sagen,
											Sie sind wie ein Pokerspieler, Sie haben sich verraten.
											Anhand der Datenanalyse kann ich sagen, was Sie tun werden,
											bevor Sie es überhaupt tun.
											Ich weiss, was Sie mögen. Ich weiss, wer Sie sind.
											Sogar noch bevor ich Ihre Post ansehe
											oder Ihr Telefon.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Those are the kinds of things we can do
											with the data that we have.
											But I'm not actually here to talk about what we can do.
											I'm here to talk about what we should do.
											What's the right thing to do?
									","
											Ese es el tipo de cosas que podemos hacer
											con los datos que tenemos.
											Pero en realidad no estoy aquí para hablar de lo que podemos hacer.
											Estoy aquí para hablar de lo que debemos hacer.
											¿Cuál es la acción correcta?
									","
											Este é o tipo de coisas que podemos fazer
											com as informações que temos.
											Mas eu não estou aqui para falar 
do que podemos fazer.
											Estou aqui para falar
do que devemos fazer.
											Qual é a atuação correta?
									","
											İşte bunlar elimizdeki verilerle
											yapabileceğimiz türden şeyler.
											Ama aslında neler yapabileceğimiz hakkında konuşmak için burada değilim.
											Neler yapmamız gerektiği hakkında konuşmak için buradayım.
											Yapılacak doğru şey ne?
									","
											Ce sont le genre de choses que nous pouvons faire
											avec les données que nous avons.
											Mais je ne suis pas là pour parler de ce que nous pouvons faire.
											Je suis ici pour parler de ce que nous devrions faire.
											Quelle est la bonne chose à faire ?
									","
											All diese Dinge können wir tun
											mit den Daten, die wir haben.
											Aber ich bin nicht wirklich hier, um darüber zu sprechen, was wir tun können.
											Ich bin hier, um darüber zu sprechen, was wir tun sollten.
											Was ist das Richtige?
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Now I see some puzzled looks
											like, ""Why are you asking us what's the right thing to do?
											We're just building this stuff. Somebody else is using it.""
											Fair enough.
											But it brings me back.
											I think about World War II —
											some of our great technologists then,
											some of our great physicists,
											studying nuclear fission and fusion —
											just nuclear stuff.
											We gather together these physicists in Los Alamos
											to see what they'll build.
											We want the people building the technology
											thinking about what we should be doing with the technology.
									","
											Veo algunas miradas desconcertadas
											como diciendo, ""¿Por qué nos preguntas qué es lo correcto?
											Nosotros hacemos. Son otros los que la usan"".
											Es cierto.
											Pero esto me lleva al pasado.
											Pienso en la Segunda Guerra Mundial —
											algunos de nuestros grandes tecnólogos de entonces,
											algunos de los grandes físicos,
											estudiaban la fisión y la fusión nuclear —
											cuestiones nucleares.
											Reunimos a estos físicos en Los Álamos
											para ver que construían.
											Queremos que la gente que desarrolla tecnología
											piense qué deberíamos hacer nosotros con ella.
									","
											Estou a ver alguns olhares confusos, tipo:
											""Porque é que nos está a perguntar
qual é a atuação correta?
											""Nós só estamos a criar isto.
São outras pessoas que o utilizam.""
											É verdade.
											Mas isso leva-me ao passado.
											Penso na II Guerra Mundial.
											Alguns dos nossos grandes
tecnólogos de então,
											alguns dos nossos grandes físicos,
											estudando a fissão e a fusão nuclear,
											apenas estudos nucleares.
											Nós reunimos estes físicos em Los Alamos
											para ver o que criariam.
											Nós queremos que as pessoas
que criam a tecnologia
											pensem no que devemos
fazer com a tecnologia.
									","
											Şaşkın bakışlar görüyorum
											sanki, ""Bize doğru olanın ne olduğunu neden soruyorsun?
											Bu zımbırtıyı biz sadece geliştiriyoruz. Onu başkaları kullanıyor.” dercesine
											Peki, öyle olsun.
											Ama bu beni geçmişe götürüyor.
											II. Dünya Savaşını düşünüyorum da —
											büyük teknoloji uzmanlarımızın bazıları,
											büyük fizikçilerimizin bazıları,
											nükleer fisyon ve füzyon üzerine çalışıyorlar —
											sadece nükleer şeyler üzerine.
											Ne üreteceklerini görmek için tüm bu fizikçileri Los Alamos'ta
											bir araya getiriyoruz.
											Teknolojiyi üreten insanlar
											teknolojiyle ne yapmamız gerektiğini düşünen insanlar olsun istiyoruz.
									","
											Je vois des regards perplexes
											comme « Pourquoi nous demandez-vous quelle est la bonne chose à faire ?
											On ne fait que construire ce truc. Quelqu'un d'autre l'utilise. »
											Très bien.
											Mais ça me ramène en arrière.
											Je pense à la deuxième guerre mondiale —
											certains de nos grands technologues de l'époque,
											certains de nos grands physiciens,
											qui étudiaient la fission et la fusion nucléaires —
											juste des trucs nucléaires.
											Nous rassemblons ces physiciens ensemble à Los Alamos
											pour voir ce qu'ils vont construire.
											Nous voulons que les personnes qui construisent la technologie
											pensent à ce que nous devrions faire avec la technologie.
									","
											Ich sehe einige verwirrte Blicke, wie,
											""Wieso fragen Sie uns, was das Richtige zu tun ist
											Wir bauen diese Dinge ja nur, jemand anders benutzt es.""
											Schön und gut.
											Aber das bringt mich zurück zu vorhin.
											Ich denke an den zweiten Weltkriegt –
											einige unserer grossen Technologen damals,
											einige unserer grossartigen Physiker,
											die Kernspaltung und -fusion untersuchten –
											nukleares Zeug halt.
											Wir versammeln diese Physiker in Los Alamos,
											um zu sehen, was sie bauen.
											Wir wollen, dass die Menschen, welche die Technologie erschaffen,
											darüber nachdenken, was wir mit der Technologie tun sollten.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											So what should we be doing with that guy's data?
											Should we be collecting it, gathering it,
											so we can make his online experience better?
											So we can make money?
											So we can protect ourselves
											if he was up to no good?
											Or should we respect his privacy,
											protect his dignity and leave him alone?
											Which one is it?
											How should we figure it out?
									","
											Entonces, ¿qué deberíamos hacer con los datos de ese señor?
											¿Deberíamos recolectar, reunir los datos,
											para mejorar su experiencia en línea?
											¿Para ganar dinero?
											¿Para protegernos nosotros mismos
											si no se comporta bien?
											¿O deberíamos respetar su privacidad,
											proteger su dignidad y dejarlo en paz?
											¿Qué hacemos?
											¿Cómo debemos decidir?
									","
											Então, o que devemos fazer
com os dados daquele indivíduo?
											Devemos colher estes dados, reuni-los,
											para melhorar a sua experiência online?
											Para ganharmos dinheiro?
											Para podermos proteger-nos
caso ele proceda mal
											Ou devemos respeitar a sua privacidade,
											proteger a sua dignidade
e deixá-lo em paz?
											O que devemos fazer?
											Como devemos decidir?
									","
											Peki şu adamın verileriyle bizim ne yapmamız gerekiyor?
											Onları toplamalı, derlemeli miyiz,
											ki böylece onun internet deneyimini iyileştirebilelim?
											Böylece para kazanabilelim?
											Böylece eğer iyi biri değilse
											kendimizi koruyabilelim?
											Yoksa mahremiyetine saygı duymalı,
											itibarını korumalı ve onu rahat mı bırakmalıyız?
											Hangisi?
											Bunu nasıl anlayabiliriz?
									","
											Que devrions-nous donc faire avec les données de ce type ?
											Devrions-nous les collecter, les rassembler,
											pour optimiser son surf sur Internet ?
											Pour faire de l'argent ?
											Pour que nous puissions nous protéger
											s'il a de mauvaises intentions ?
											Ou devrions-nous respecter son intimité,
											protéger sa dignité et le laisser tranquille ?
											Que fait-on ?
											Comment décidons-nous ?
									","
											Was also sollten wir mit den Daten dieses Mannes tun?
											Sollten wir sie sammeln,
											so dass wir sein Online-Erlebnis besser machen können?
											So dass wir damit Geld verdienen können?
											So dass wir uns vor ihm schützen können,
											wenn er Übles im Schilde führte?
											Oder sollten wir seine Privatsphäre respektieren,
											seine Würde schützen und ihn in Ruhe lassen?
											Was ist das Richtige?
											Wie sollten wir das rausfinden?
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											I know: crowdsource. Let's crowdsource this.
											So to get people warmed up,
											let's start with an easy question —
											something I'm sure everybody here has an opinion about:
											iPhone versus Android.
											Let's do a show of hands — iPhone.
											Uh huh.
											Android.
											You'd think with a bunch of smart people
											we wouldn't be such suckers just for the pretty phones.
											(Laughter)
											Next question,
											a little bit harder.
											Should we be collecting all of that guy's data
											to make his experiences better
											and to protect ourselves in case he's up to no good?
											Or should we leave him alone?
											Collect his data.
											Leave him alone.
											You're safe. It's fine.
											(Laughter)
											Okay, last question —
											harder question —
											when trying to evaluate
											what we should do in this case,
											should we use a Kantian deontological moral framework,
											or should we use a Millian consequentialist one?
											Kant.
											Mill.
											Not as many votes.
											(Laughter)
											Yeah, that's a terrifying result.
											Terrifying, because we have stronger opinions
											about our hand-held devices
											than about the moral framework
											we should use to guide our decisions.
									","
											Ya sé: colaboración pública. Vamos a resolver esto juntos.
											Para entrar en calor,
											comencemos con una pregunta fácil —
											algo sobre lo que estoy seguro que todos aquí tienen una opinión:
											iPhone versus Android.
											Levanten las manos por el iPhone.
											Ajá.
											Android.
											Uno pensaría que un grupo de gente inteligente
											o sucumbiría tan fácil ante unos lindos teléfonos.
											(Risas)
											Siguiente pregunta,
											un poco más difícil.
											¿Deberíamos recolectar toda los datos de ese hombre
											para ofrecerle una mejor experiencia
											y para protegernos en caso de que trame algo malo?
											¿O deberíamos dejarlo en paz?
											Recolectar sus datos.
											Dejarlo en paz.
											Estás a salvo. Está bien.
											(Risas)
											Bien, última pregunta —
											más difícil —
											Al tratar de evaluar
											lo que deberíamos hacer en este caso,
											¿deberíamos usar un sistema moral deontológico kantiano,
											o un sistema consecuencionalista milliano?
											Kant.
											Mill.
											No hay tantos votos.
											(Risas)
											Sí, ese es un resultado aterrador.
											Es aterrador porque tenemos opiniones más firmes
											sobre nuestros aparatos portátiles
											que sobre el sistema moral
											que debería guiar nuestras decisiones.
									","
											Eu sei: colaboração pública.
Vamos resolver isto juntos.
											Para fazermos o aquecimento,
											vamos começar com uma questão simples,
											uma coisa a respeito da qual estou certo
de que todos aqui têm uma opinião:
											iPhone versus Android.
											Levantem as vossas mãos — iPhone!
											Ha-ha!
											Android!
											Esperava que um grupo de gente inteligente
											não seria tão apanhada
pelos telemóveis bonitinhos.
											(Risos)
											Próxima pergunta,
											um pouco mais difícil.
											Devemos recolher todos
os dados daquele indivíduo
											para melhorar as suas experiências
											e para nos protegermos no caso
de ele não se portar bem?
											Ou devemos deixá-lo em paz?
											Recolher os dados!
											Deixá-lo em paz!
											Estão safos. Está certo.
											(Risos)
											Muito bem, última pergunta,
											esta mais difícil.
											Quando tentamos avaliar
											o que devemos fazer neste caso,
											devemos usar o sistema
da moral deontológica de Kant,
											ou devemos usar
a teoria da causalidade de Mill?
											Kant!
											Mill.
											Já não há tantos votos.
											(Risos)
											Sim, é um resultado assustador.
											Assustador porque temos
opiniões mais firmes
											sobre os nossos aparelhos portáteis
											do que sobre os padrões morais
											que devemos usar para orientar
as nossas decisões.
									","
											Ben biliyorum: Kitle kaynak. Bunu kitle kaynakla çözelim.
											Öyleyse biraz ısınmak üzere,
											kolay bir soru ile başlayalım —
											buradaki herkesin bir fikri olduğuna emin olduğum bir şeyle:
											iPhone’a karşı Android.
											Haydi el kaldırarak gösterelim – iPhone diyenler.
											A-ha
											Android.
											Bir grup zeki insan olarak bizim
											o kadar da güzel telefon budalası olmayacağımızı düşünebilirsiniz.
											(Gülüşmeler)
											Sıradaki soru,
											birazcık daha zor
											Oradaki adamın deneyimlerini iyileştirmek için
											ve eğer o iyi biri değilse kendimizi korumak için
											onun tüm verilerini toplamalı mıyız?
											Yoksa onu rahat mı bırakmalıyız?
											Verileri toplayalım diyenler.
											Rahat bırakalım.
											Güvendesiniz. Sorun yok.
											(Gülüşmeler)
											Tamam, son soru —
											daha zor bir soru —
											böyle durumları değerlendirmeye çalışırken
											sizce ne yapmalıyız,
											Kantçı deontolojik bir ahlak çerçevesi mi kullanmalıyız,
											yoksa Mill tarzı bir sonuççuluk mu kullanmalıyız?
											Kant.
											Mill.
											Pek fazla oy yok.
											(Gülüşmeler)
											Evet, bu endişe verici bir sonuç.
											Endişe verici, çünkü taşınabilir cihazlarımız hakkında,
											kararlarımızı yönlendirirken kullanmamız gereken
											ahlaki çerçeve hakkında olduğundan
											daha güçlü fikirlerimiz var.
									","
											Je sais : la participation citoyenne. Faisons du crowdsourcing.
											Pour donner de l'entrain aux gens,
											commençons par une question facile —
											une chose sur laquelle tout le monde ici a une idée, j'en suis sûr :
											iPhone contre Android.
											Levez vos mains pour l'iPhone.
											Uh huh.
											Android.
											Je pensais qu'une assemblée de gens intelligents
											ne succomberait pas si facilement aux jolis téléphones.
											(Rires)
											Question suivante.
											Un peu plus difficile.
											Devrions-nous collecter toutes les données de ce type
											pour optimiser son surf sur Internet
											et pour nous protéger au cas où il aurait de mauvaises intentions ?
											Ou devrions-nous le laisser tranquille ?
											Rassembler ses données.
											Le laisser tranquille.
											Vous êtes hors de danger, c'est bon.
											(Rires)
											Bien, dernière question —
											plus difficile —
											quand on essaye d'estimer
											ce que nous devrions faire dans cette situation,
											devrions-nous utiliser le système moral déontologique de Kant,
											ou bien le système moral conséquentialiste de Mill ?
											Kant.
											Mill.
											Pas autant de voix.
											(Rires)
											Oui, c'est un résultat terrifiant.
											Terrifiant, parce que nous avons des opinions plus fortes
											sur nos appareils téléphones
											que sur les systèmes moraux
											que nous devrions utiliser pour orienter nos décisions.
									","
											Ich weiss: Crowdsourcing. Lassen Sie uns das gemeinsam klären.
											Um uns alle aufzuwärmen,
											fangen wir mit einer einfachen Frage an –
											etwas, wozu sicher jeder hier eine Meinung hat.
											iPhone gegen Android.
											Zeigen Sie mir Ihre Hände – iPhone.
											Uh huh.
											Android.
											Man würde meinen, ein Haufen kluger Leute wie wir
											würde nicht wie die Trottel den hübschen Handys hinterherrennen.
											(Gelächter)
											Nächste Frage,
											ein bisschen schwieriger.
											Sollten wir all die Daten dieses Mannes sammeln,
											um sein Erlebnis besser zu machen
											und uns zu schützen, falls er Schlechtes vor hat?
											Oder sollten wir ihn in Ruhe lassen?
											Seine Daten sammeln.
											Ihn in Ruhe lassen.
											Sie sind sicher, alles ist gut.
											(Gelächter)
											Ok, letzte Frage –
											schwierigere Frage –
											wenn wir versuchen herauszufinden,
											was wir in diesem Fall tun sollten,
											sollten wir einen deontologischen moralischen Massstab nach Kant anlegen
											oder die Konsequentialitätslogik nach Mill?
											Kant.
											Mill.
											Nicht so viele Stimmen.
											(Gelächter)
											Ja, das ist ein erschreckendes Resultat.
											Erschreckend, weil wir eine gefestigtere Meinung
											über unsere Smartphones haben,
											als über unseren moralischen Masstab,
											den wir als Richtlinie für unsere Entscheidungen verwenden sollten.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											How do we know what to do with all the power we have
											if we don't have a moral framework?
											We know more about mobile operating systems,
											but what we really need is a moral operating system.
											What's a moral operating system?
											We all know right and wrong, right?
											You feel good when you do something right,
											you feel bad when you do something wrong.
											Our parents teach us that: praise with the good, scold with the bad.
											But how do we figure out what's right and wrong?
											And from day to day, we have the techniques that we use.
											Maybe we just follow our gut.
											Maybe we take a vote — we crowdsource.
											Or maybe we punt —
											ask the legal department, see what they say.
											In other words, it's kind of random,
											kind of ad hoc,
											how we figure out what we should do.
											And maybe, if we want to be on surer footing,
											what we really want is a moral framework that will help guide us there,
											that will tell us what kinds of things are right and wrong in the first place,
											and how would we know in a given situation what to do.
									","
											¿Cómo sabemos qué hacer con todo el poder que tenemos
											si no tenemos un sistema moral?
											Sabemos más sobre los sistemas operativos móviles,
											pero lo que realmente necesitamos es un sistema operativo moral.
											¿Qué es un sistema operativo moral?
											Todos sabemos lo que es correcto e incorrecto.
											Te sientes bien cuando haces algo correcto,
											te sientes mal cuando haces algo incorrecto.
											Nuestros padres nos enseñan que se alaba lo bueno y se regaña lo malo.
											Pero, ¿cómo podemos averiguar qué es lo correcto y lo incorrecto?
											Y, día a día, tenemos las técnicas que utilizamos.
											Tal vez solo seguimos nuestro instinto.
											Tal vez votamos —consultamos la opinión pública.
											O tal vez apostamos —
											preguntamos al departamento legal, vemos lo que dicen.
											En otras palabras, es un poco aleatorio,
											improvisamos,
											la forma de averiguar lo que debemos hacer.
											Y, tal vez, si queremos sentirnos más seguros,
											lo que realmente queremos es un sistema moral que nos oriente,
											que nos diga en primer lugar que tipo de cosas están bien y mal,
											y cómo sabemos qué hacer en una situación dada.
									","
											Como sabemos o que fazer
com todo o poder que temos
											se não temos um enquadramento moral?
											Sabemos mais
sobre sistemas operativos móveis,
											mas do que realmente necessitamos
é de um sistema operativo moral.
											O que é um sistema operativo moral?
											Todos sabemos o que é certo e errado.
											Sentimo-nos bem quando fazemos
uma coisa boa,
											sentimo-nos mal ao fazer uma coisa errada.
											Os nossos pais ensinam-nos
que se louva o bom, ralha-se ao mau.
											Mas como sabemos
o que é bom e o que é mau?
											No dia a dia, temos
as técnicas que usamos.
											Talvez apenas sigamos o nosso instinto.
											Talvez recorramos à votação
—pedimos a colaboração pública.
											Ou talvez pesquisemos
											— perguntamos ao departamento jurídico,
para ver o que dizem.
											Por outras palavras, é um pouco aleatório,
											um pouco ""ad hoc"",
											como decidimos o que devemos fazer.
											E talvez, se quisermos
sentir-nos mais seguros,
											o que realmente queiramos
seja um sistema moral que nos oriente,
											que nos diga que tipos de coisas
são, à partida, certas e erradas,
											e como sabemos o que fazer
numa determinada situação.
									","
											Elimizdeki tüm bu güç ile ne yapacağımızı,
											eğer bir ahlaki çerçevemiz yoksa nasıl bilebiliriz ki?
											Taşınabilir işletim sistemleri hakkında çok şey bilirken,
											aslında gerçek ihtiyacımız olan şey bir ahlaki işletim sistemi.
											Nedir ahlaki işletim sistemi?
											Doğru ve yanlışın ne olduğunu biliyoruz, değil mi?
											Doğru bir şey yaptığında kendini iyi hissedersin,
											Yanlış bir şey yaptığında kendini kötü hissedersin.
											Ebeveynlerimiz bize şunu öğretir: iyiyi yücelt, kötünün dersini ver.
											Ama neyin doğru neyin yanlış olduğunu nasıl anlayacağız?
											Günbegün kullandığımız tekniklerimiz var.
											Belki sadece kalbimizin sesini dinliyoruz.
											Belki oylama yapıyoruz – kitle kaynak kullanıyoruz
											Belki kumar oynuyoruz —
											Hukukçulara sorup, ne dediklerine bakıyoruz.
											Bir başka deyişle, ne yapmamız gerektiğini nasıl bulduğumuz,
											bir bakıma rastlantısal,
											bir bakıma da “ad hoc” (niyete mahsus)
											Ve belki de, daha güvenilir bir temelde olmak istiyorsak
											gerçekte istediğimiz, bizi orada yönlendirmede yardım edecek,
											ilk etapta bize neyin doğru neyin yanlış olduğunu söyleyecek,
											ve belli bir durumda ne yapacağımızı nasıl bileceğimize yardım edecek ahlaki bir çerçevedir.
									","
											Que faire de tout le pouvoir que nous avons
											si nous n'avons pas de système moral ?
											Nous en savons davantage sur les systèmes d'exploitation de nos téléphones,
											alors que ce dont nous avons vraiment besoin est d'un système d'exploitation moral.
											Qu'est-ce qu'un système d'exploitation moral ?
											Nous connaissons tous le bien et le mal.
											Vous vous sentez bien quand vous faites quelque chose de juste,
											vous vous sentez mal quand vous faites le mal.
											Nos parents nous l'apprennent : louer le bien, réprimander le mal.
											Mais comment savoir ce qui est bien et ce qui est mal ?
											De jour en jour, nous utilisons des techniques.
											Peut-être que nous suivons simplement notre instinct.
											Peut-être que nous procédons à un vote — le crowdsourcing.
											Ou peut-être que nous nous déchargeons —
											nous demandons le service juridique, voir ce qu'ils en pensent.
											En d'autres mots, c'est plutôt aléatoire,
											c'est plutôt ad hoc,
											la façon dont nous décidons de ce que nous devrions faire.
											Peut-être que si nous voulons adopter une position plus sûre,
											ce que nous voulons vraiment est un système moral qui nous aidera à nous y orienter,
											qui nous dira qu'est-ce qui est bien et qu'est-ce qui est mal dès le départ,
											et comment savoir quoi faire dans une situation donnée.
									","
											Woher wissen wir, was wir mit unserer Macht anfangen sollen,
											wenn wir keinen moralischen Masstab haben?
											Wir wissen mehr über mobile Betriebssysteme,
											aber was wir wirklich brauchen, ist ein moralisches Betriebssystem.
											Was ist ein moralisches Betriebssystem?
											Wir alle kennen richtig und falsch, nicht wahr.
											Man fühlt sich gut, wenn man das Richtige tut,
											man fühlt sich schlecht, wenn man das Falsche tut.
											Unsere Eltern lehren uns: das Gute loben, das Böse schelten.
											Aber wie finden wir heraus, was richtig und was falsch ist?
											Jeden Tag folgen wir bestimmten Techniken, die wir verwenden.
											Vielleicht folgen wir einfach unserem Bauch.
											Vielleicht machen wir eine Abstimmung – lassen die Menge entscheiden.
											Oder wir weichen aus –
											fragen die Rechtsabteilung und sehen, was die sagen.
											In anderen Worten, es ist ziemlich zufällig,
											sozusagen fallweise,
											wie wir herausfinden, was wir tun sollten.
											Und vielleicht, wenn wir einen sichereren Stand haben wollen,
											möchten wir wirklich einen moralischen Massstab haben, der uns dahin führt,
											der uns erst einmal sagt, welche Dinge richtig oder falsch sind
											und der uns wissen lässt, was in einer bestimmten Situation zu tun ist.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											So let's get a moral framework.
											We're numbers people, living by numbers.
											How can we use numbers
											as the basis for a moral framework?
											I know a guy who did exactly that.
											A brilliant guy —
											he's been dead 2,500 years.
											Plato, that's right.
											Remember him — old philosopher?
											You were sleeping during that class.
											And Plato, he had a lot of the same concerns that we did.
											He was worried about right and wrong.
											He wanted to know what is just.
											But he was worried that all we seem to be doing
											is trading opinions about this.
											He says something's just. She says something else is just.
											It's kind of convincing when he talks and when she talks too.
											I'm just going back and forth; I'm not getting anywhere.
											I don't want opinions; I want knowledge.
											I want to know the truth about justice —
											like we have truths in math.
											In math, we know the objective facts.
											Take a number, any number — two.
											Favorite number. I love that number.
											There are truths about two.
											If you've got two of something,
											you add two more, you get four.
											That's true no matter what thing you're talking about.
											It's an objective truth about the form of two,
											the abstract form.
											When you have two of anything — two eyes, two ears, two noses,
											just two protrusions —
											those all partake of the form of two.
											They all participate in the truths that two has.
											They all have two-ness in them.
											And therefore, it's not a matter of opinion.
									","
											Entonces tengamos un sistema moral.
											Somos seres que trabajamos con números, vivimos por los números.
											¿Cómo podemos usar los números
											como base para un sistema moral?
											Conozco a un hombre que hizo exactamente eso,
											Un hombre brillante —
											murió hace 2500 años.
											Platón, exacto.
											¿Lo recuerdan? ¿un viejo filósofo?
											Se durmieron durante esa clase.
											Y Platón se planteó muchas de estas preocupaciones que tenemos.
											Se preocupaba por lo correcto y lo incorrecto.
											Quería saber qué era lo justo.
											Pero le preocupaba que todo lo que parecíamos hacer
											era intercambiar opiniones sobre el tema.
											Él dice que algo es lo justo. Ella dice que otra cosa es lo justo.
											Ambos suenan convincentes.
											Vamos y volvemos sin llegar a ningún lado.
											No quiero opiniones, quiero conocimiento.
											Quiero saber la verdad sobre la justicia —
											tal como tenemos verdades en matemáticas.
											En matemáticas conocemos los hechos objetivos.
											Tomen un número, cualquier número — el 2.
											Mi número favorito. Me encanta ese número.
											Hay verdades sobre el 2.
											Si tienen 2 de algo,
											y agregan 2 más, tienen 4.
											Eso es verdad sin importar qué estén hablando.
											Es una verdad objetiva sobre la forma del 2,
											la forma abstracta.
											Cuando se tiene 2 de cualquier cosa - 2 ojos, 2 oídos, 2 narices,
											2 protuberancias —
											todos ellos participan de la forma del 2.
											Todos participan de las verdades del 2.
											Todos tienen la dualidad.
											Y por lo tanto, no es una cuestión de opinión.
									","
											Então, vamos arranjar um sistema moral.
											Somos pessoas que lidam com números,
vivemos através de números.
											Como podemos usar números
											como base de um sistema moral?
											Conheço um indivíduo
que fez exatamente isso.
											Era um indivíduo brilhante,
											morreu há 2500 anos.
											Platão, isso mesmo.
											Lembram-se dele, do velho filósofo?
											Vocês estavam a dormir nessa aula?
											Platão tinha grande parte
das nossas preocupações.
											Estava preocupado com o certo e o errado.
											Queria saber o que é justo.
											Mas preocupava-o o facto de que
tudo o que parecemos fazer
											é trocar opiniões sobre o assunto.
											Ele diz que isto é justo.
Ela diz que aquilo é justo.
											Ele parece convincente e ela também.
											Ando para trás e para a frente,
não chego a lugar nenhum.
											Não quero opiniões, quero conhecimento.
											Quero saber a verdade sobre a justiça,
											tal como temos verdades na matemática.
											Em matemática, conhecemos
factos objetivos.
											Escolham um número,
qualquer número — dois.
											O meu número favorito. Adoro-o.
											Há verdades sobre o dois.
											Se vocês tiverem dois de alguma coisa,
											adicionam dois e obtêm quatro.
											Isto é verdade, seja do que for
que estão a falar.
											É uma verdade objetiva
sobre a forma dois,
											a forma abstrata.
											Quando temos dois de alguma coisa
— dois olhos, duas orelhas,
											dois narizes, apenas duas saliências —
											todas elas participam da forma de dois.
											Todas elas participam
nas verdades que o dois tem.
											Todas têm em si o ser ""dois"".
											E, consequentemente, isto não é
uma questão de opinião.
									","
											Öyleyse bir ahlaki çerçeve edinelim.
											Biz sayılarla yaşayan, çok sayıda kişiyiz.
											Ahlaki bir çerçeveye temel olacak şekilde,
											sayıları nasıl kullanabiliriz?
											Ben tam olarak bunu yapan birini tanıyorum,
											Parlak zekâlı bir adam —
											2.500 yıl önce öldü.
											Platon, evet doğru.
											Hatırladınız mı – hani şu eski filozof?
											O sırada derste uyuyordunuz.
											Ve Platon, bizim sahip olduğumuz aynı kaygılara çokça sahipti.
											Doğru ve yanlış hakkında meraklıydı.
											Neyin adil olduğunu bilmek istiyordu.
											Ama bu konuda tüm yaptığımızın bu konuda fikir alışverişi
											yapıyormuşuz gibi göründüğünden endişeliydi.
											Birine göre bir şey adilken, diğerine göre başka bir şey adil.
											Onun anlattığı da bunun anlattığı da bir bakıma ikna edici.
											Bir ileri bir geri gidiyorum bu şekilde, bir yere vardığım yok.
											Artık fikir istemiyorum, bilgi birikimi istiyorum.
											Adalet hakkındaki gerçeği bilmek istiyorum —
											tıpkı matematikte gerçekliklerimizin olduğu gibi.
											Matematikte tarafsız olguları bilebiliriz.
											Bir sayı al, herhangi bir sayı — iki
											En sevdiğim sayıdır. Bayılırım bu sayıya.
											İki hakkında gerçekler vardır.
											Herhangi bir şeyden iki tanesine sahipseniz,
											buna iki tane daha eklediğinizde, dört elde edersiniz.
											Neden bahsettiğiniz fark etmez, her şey için doğrudur.
											Bu iki olma biçimi hakkında, bu soyut biçim hakkında
											tarafsız bir olgudur.
											Herhangi bir şeyden iki tanesine sahipsen – iki göz, iki kulak, burun delikleri
											sadece iki çıkıntı —
											tüm bunlar iki biçiminde yerini alır.
											İkinin sahip olduğu tüm gerçeklere ortak olur.
											Hepsinde sahip oldukları bir ""ikilik"" vardır.
											Ve dolayısıyla, bu bir kanaat meselesi değildir.
									","
											Prenons donc un cadre moral.
											Nous vivons dans un monde de chiffres.
											Comment pouvons-nous utiliser les chiffres
											comme base d'un système moral ?
											Je connais quelqu'un qui a fait exactement cela,
											quelqu'un de brillant —
											il est mort il y a 2 500 ans.
											Platon, c'est exact.
											Vous vous rappelez de lui — le vieux philosophe ?
											Vous dormiez pendant les cours.
											Platon partageait beaucoup de nos préoccupations.
											Il se préoccupait du bien et du mal.
											Il voulait savoir ce qui était juste.
											Mais il s'inquiétait que tout ce que nous semblons faire,
											c'est échanger des opinions sur le sujet.
											Il me dit que quelque chose est juste. Elle me dit qu'autre chose est juste.
											Les deux sont plutôt convaincants quand ils parlent.
											Je fais des allers retours ; je n'avance pas.
											Je ne veux pas d'opinions, je veux de la connaissance.
											Je veux connaître la vérité sur la justice —
											comme on connait les vérités mathématiques.
											En maths, on connait les faits concrets.
											Prenez un chiffre, n'importe lequel — deux.
											Mon chiffre préféré. J'adore ce chiffre.
											Il y a des vérités sur le chiffre deux.
											Si vous avez une chose en deux exemplaires,
											vous en ajoutez deux, vous en obtenez quatre.
											C'est vrai pour n'importe quelle chose.
											c'est une vérité objective sur la forme du chiffre deux,
											la forme abstraite.
											Quand vous avez une chose en deux exemplaires — deux yeux, deux oreilles, deux nez,
											juste deux éléments —
											ils participent tous à la forme du chiffre deux.
											Ils participent aux vérités intrinsèques du chiffre deux.
											Il y a du chiffre deux en chacun d'eux.
											Par conséquent, ça ne dépend pas de l'opinion.
									","
											Also lassen Sie uns einen moralischen Massstab finden.
											Wir sind Zahlenleute, wir leben nach Zahlen.
											Wie können wir Zahlen als Basis
											für unseren moralischen Masstab verwenden?
											Ich kenne jemanden, der genau das getan hat.
											Ein brillianter Typ –
											er ist schon seit 2500 Jahren tot.
											Plato, genau.
											Erinnern Sie sich – alter Philosoph?
											Sie haben in dieser Schulstunde geschlafen.
											Und Plato hatte oft dieselben Sorgen wie wir.
											Er sorgte sich um richtig und falsch.
											Er wollte wissen, was gerecht ist.
											Aber er war beunruhigt darüber, dass wir darüber
											nur Meinungen auszutauschen scheinen.
											Er sagt, etwas ist gerecht. Sie sagt, etwas anderes ist gerecht.
											Beide sind ziemlich überzeugend.
											Ich gehe hin und her, ich komme nirgends an.
											Ich will keine Meinungen, ich will Wissen.
											Ich will die Wahrheit über Gerechtigkeit wissen –
											so wie wir Wahrheiten in der Mathematik haben.
											In der Mathematik kennen wir die objektiven Fakten.
											Nehmen Sie irgendeine Zahl – zwei.
											Lieblingszahl. Ich liebe diese Zahl.
											Es gibt Wahrheiten über die Zwei.
											Wenn man zwei von etwas hat,
											und man zwei dazu gibt, bekommt man vier.
											Das ist wahr, egal worüber man spricht.
											Es ist eine objektive Wahrheit über die Form der Zwei,
											die abstrakte Form.
											Wenn man zwei von irgendwas hat – zwei Augen, Ohren, Nasen,
											zwei Bandscheibenleiden –
											all diese Dinge nehmen an der Form der Zwei teil.
											Sie sind ein Teil der Wahrheiten, die die Zwei hat.
											Sie haben alle Zwei-heit in sich.
											Und deshalb ist das keine Meinungsfrage.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											What if, Plato thought,
											ethics was like math?
											What if there were a pure form of justice?
											What if there are truths about justice,
											and you could just look around in this world
											and see which things participated,
											partook of that form of justice?
											Then you would know what was really just and what wasn't.
											It wouldn't be a matter
											of just opinion or just appearances.
											That's a stunning vision.
											I mean, think about that. How grand. How ambitious.
											That's as ambitious as we are.
											He wants to solve ethics.
											He wants objective truths.
											If you think that way,
											you have a Platonist moral framework.
									","
											Platón pensaba: ¿y si
											la ética fuese como la matemática?
											¿Y si hubiera una forma pura de justicia?
											¿Y si hay verdades acerca de la justicia,
											y si pudiéramos mirar el mundo
											y ver las cosas que la componen,
											que forman parte de la justicia?
											Entonces podría saberse lo que realmente es justo y lo que no.
											No sería una cuestión
											de simple opinión o apariencias.
											Esa es una visión asombrosa.
											Quiero decir, piénsenlo. Es magnífico y ambicioso.
											Tan ambicioso como nosotros.
											Él quiere resolver la ética.
											Quiere verdades objetivas.
											Si piensas de esa forma,
											tienes un sistema moral platónico.
									","
											Platão pensou:
											""E se a ética fosse como a matemática?
											E se houvesse uma forma pura de justiça?
											E se houvesse verdades sobre a justiça
											e pudéssemos olhar
à nossa volta, neste mundo
											e ver quais as coisas
que participam dessa forma de justiça?
											Assim saberíamos o que é justo
e o que o não é.
											Não seria uma questão
de mera opinião ou aparência.
											É uma visão assombrosa.
											Pensem nisto.
Que grandioso! Que ambicioso!
											Tão ambicioso como nós somos.
											Ele quer resolver a ética.
											Quer verdades objetivas.
											Se pensarmos assim,
											têm um sistema moral platónico.
									","
											Peki ya Platon, etiğin
											matematik gibi olduğunu düşünseydi?
											Ya adaletin saf bir biçimi varsa?
											Ya adalet hakkında gerçeklikler varsa,
											ve yalnızca dünyaya şöyle bir bakınarak
											nelerin bu gerçeğe ortak olup,
											bu adalet biçiminde yerini aldığını görebilseydik?
											Böylece gerçekte neyin adil olup neyin olmadığını bilebilirdik.
											Sadece kanaat veya sadece
											kalıplardan ibaret olmazdı.
											Bu çarpıcı bir görüş.
											Yani, bir düşünsenize. Ne kadar muazzam. Ne kadar hırslı.
											Tıpkı bizim kadar hırslı.
											Etiği çözmek istiyor.
											Tarafsız gerçeklikler istiyor.
											Eğer bu şekilde düşünüyorsanız,
											Platonist bir ahlaki çerçeveniz var demektir.
									","
											Et si, Platon se disait,
											l'étique était comme les maths ?
											Et s'il y avait une forme pure de justice ?
											Et s'il y avait des vérités sur la justice,
											et que vous pouviez simplement regarder le monde
											et voir les choses qui y participent,
											qui prennent part à cette forme de justice ?
											Vous sauriez alors ce qui est vraiment juste et ce qui ne l'est pas.
											Ça ne dépendrait pas
											d'un simple jugement ou d'un simple aspect.
											C'est une vision stupéfiante.
											Je veux dire, pensez-y. C'est magnifique. C'est ambitieux.
											C'est aussi ambitieux que nous.
											Nous voulons résoudre les problèmes d'éthique.
											Nous voulons des vérités objectives.
											Si vous pensez de cette façon,
											vous avez un système moral platonicien.
									","
											Plato dachte also, was wäre,
											wenn Ethik wie Mathematik wäre?
											Was, wenn es eine reine Form von Gerechtigkeit gäbe?
											Was, wenn es Wahrheiten über Gerechtigkeit gibt
											und man sich einfach in der Welt umsehen könnte
											und sehen, welche Dinge an dieser Form
											von Gerechtigkeit teilhalben?
											Dann wüsste man, was wirklich gerecht wäre und was nicht.
											Es wäre dann keine Frage
											von Meinung oder gerechter Erscheinung.
											Das ist eine umwerfende Vision.
											Ich meine, denken Sie darüber nach. Wie grossartig, wie ehrgeizig.
											So ehrgeizig, wie wir sind.
											Er will die Ethik lösen.
											Er will objektive Wahrheiten.
											Wenn man so darüber nachdenkt,
											hat man einen moralischen Massstab nach Plato.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											If you don't think that way,
											well, you have a lot of company in the history of Western philosophy,
											because the tidy idea, you know, people criticized it.
											Aristotle, in particular, he was not amused.
											He thought it was impractical.
											Aristotle said, ""We should seek only so much precision in each subject
											as that subject allows.""
											Aristotle thought ethics wasn't a lot like math.
											He thought ethics was a matter of making decisions in the here-and-now
											using our best judgment
											to find the right path.
											If you think that, Plato's not your guy.
											But don't give up.
											Maybe there's another way
											that we can use numbers as the basis of our moral framework.
									","
											Si no piensas de esa forma,
											bien, tienes mucha compañía en la historia de la filosofía occidental,
											porque, ya saben, esta linda idea fue criticada.
											Aristóteles, en particular, no la compartía.
											Le resultaba poco práctico.
											Aristóteles dijo: ""En cada asunto solo debemos buscar el nivel de precisión
											que ese asunto permite"".
											Aristóteles pensaba que la ética no era como la matemática.
											Él pensaba que la ética es una cuestión de tomar decisiones aquí y ahora
											usando nuestro mejor juicio
											para encontrar el camino correcto.
											Si piensan eso, Platón no es la persona a seguir.
											Pero no se rindan.
											Tal vez hay otra manera
											de usar los números como base de nuestro sistema moral.
									","
											Se não pensarem assim,
											terão muita companhia
na história da filosofia ocidental,
											porque as pessoas criticaram a ideia pura
											Aristóteles, em particular,
não a apreciou muito.
											Achou-a impraticável.
											Aristóteles disse: 
""Só devemos procurar em cada assunto
											""o nível de precisão
que esse assunto permita.""
											Aristóteles pensou que a ética
não era como a matemática.
											Pensou que a ética tinha a ver
com tomar decisões aqui e agora
											usando o nosso melhor julgamento
											para encontrar o caminho certo.
											Se pensarem assim,
Platão não é o vosso tipo.
											Mas não desistam.
											Talvez haja outra maneira
											de podermos usar números
como base do nosso sistema moral.
									","
											Eğer böyle düşünmüyorsanız,
											öyleyse, batı felsefesinde pek çok fikir ortağınız var demektir,
											çünkü bu hatrı sayılır fikri – bilirsiniz, insanlar bunu eleştirdi.
											Aristo, bundan özellikle memnun kalmadı.
											O bunun kullanışsız olduğunu düşünüyordu.
											Aristo şöyle dedi, “Bizler herhangi bir konuda, ancak o konunun bize izin verdiği miktarda
											kesinlik arayabiliriz”
											Aristo etiğin matematiğe pek benzemediğini düşünüyordu.
											Etiğin, anlık bir karar verirken doğru yolu bulmak üzere, en iyi şekilde
											hüküm verme yetimizi kullanma meselesi
											olduğunu düşünüyordu.
											Eğer, Platon sizin adamınız değilse,
											yine de pes etmeyin.
											Belki, ahlaki çerçevemizde
											sayıları temel alarak kullanabileceğimiz başka bir yol vardır.
									","
											Si vous ne pensez pas de cette façon,
											eh bien, vous n'êtes pas seul dans l'histoire de la philosophie occidentale,
											parce que cette jolie idée — vous savez, les gens l'ont critiquée.
											Aristote, en particulier, n'a pas apprécié.
											Il pensait que c'était infaisable en pratique.
											Aristote disait : « Nous ne devrions chercher qu'autant d'exactitude dans un sujet
											que celui-ci nous le permet. »
											Aristote pensait que l'éthique n'était pas vraiment comme les maths.
											Il pensait que l'éthique consistait à prendre des décision ici et maintenant
											en utilisant notre meilleur jugement
											pour trouver le droit chemin.
											Si vous pensez cela, Platon n'est pas votre homme.
											Mais n'abandonnez pas.
											Peut-être y a-t-il un autre moyen
											pour utiliser les nombres comme base de notre système moral.
									","
											Wenn man nicht so denkt,
											nun, dann hat man viel Gesellschaft in der Geschichte der westlichen Philosophie,
											denn diese ordentliche Idee – wissen Sie, sie wurde kritisiert.
											Besonders Aristoteles war nicht erfreut.
											Er fand das sehr unpraktisch.
											Aristoteles sagte, ""Wir sollten nur soviel Präzision in jedem Thema suchen,
											wie es dieses Thema erlaubt.""
											Aristoteles fand, Ethik sei überhaupt nicht wie Mathematik.
											Er dachte, Ethik sei eine Frage von Entscheidungen im Hier und Jetzt,
											unter Verwendung unseres besten Urteilsvermögens
											um den richtigen Weg zu finden.
											Wenn Sie das denken, ist Plato nicht Ihr Mann.
											Aber geben Sie nicht auf.
											Vielleicht gibt es einen anderen Weg,
											wie wir Zahlen als Grundlage für unseren moralischen Massstab verwenden können.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											How about this:
											What if in any situation you could just calculate,
											look at the choices,
											measure out which one's better and know what to do?
											That sound familiar?
											That's a utilitarian moral framework.
											John Stuart Mill was a great advocate of this —
											nice guy besides —
											and only been dead 200 years.
											So basis of utilitarianism —
											I'm sure you're familiar at least.
											The three people who voted for Mill before are familiar with this.
											But here's the way it works.
											What if morals, what if what makes something moral
											is just a matter of if it maximizes pleasure
											and minimizes pain?
											It does something intrinsic to the act.
											It's not like its relation to some abstract form.
											It's just a matter of the consequences.
											You just look at the consequences
											and see if, overall, it's for the good or for the worse.
											That would be simple. Then we know what to do.
									","
											¿Qué tal si
											ante cada situación simplemente pudieran calcular,
											mirar las opciones,
											medir cuál es mejor y saber qué hacer?
											¿Les suena familiar?
											Ese es un sistema moral utilitarista.
											John Stuart Mill fue un gran defensor de esto —
											además de un tipo genial —
											y murió hace solo 200 años.
											Así, la base del utilitarismo —
											Seguro que al menos están familiarizados.
											Las 3 personas que votaron por Mill antes están familiarizados con esto.
											Esto es así:
											¿Qué pasa si la moral, lo que hace que algo sea moral,
											es solo una cuestión de maximizar el placer
											y minimizar el dolor?
											Se trata de algo intrínseco al acto.
											No se trata de una relación con alguna forma abstracta.
											Es sólo una cuestión de consecuencias.
											Buscamos sólo en las consecuencias
											y vemos si en el todo, son positivas o negativas.
											Eso sería simple. Entonces sabríamos que hacer.
									","
											Que tal isto:
											E se em cada situação,
pudéssemos calcular,
											olhar para as opções,
											medir qual delas é a melhor
e saber o que fazer?
											Soa familiar?
											É um sistema moral utilitarista.
											John Stuart Mill foi seu grande defensor
											— um tipo fixe, aliás —
											e só morreu há 200 anos.
											Portanto, as bases do utilitarismo
											— de certeza que vos são familiares,
											pelo menos às três pessoas
que votaram em Mill.
											Mas eis a forma como isto funciona.
											Que tal se o que torna uma coisa moral,
											é só uma questão
de essa coisa maximizar o prazer
											e minimizar a dor?
											Trata-se de uma coisa intrínseca ao ato.
											Não tem que ver com a sua relação
com uma forma abstrata.
											É apenas uma questão de consequências.
											Olhamos apenas para as consequências
											e vemos se, no conjunto,
são para o bem ou para o mal.
											Isso seria simples. 
Assim saberíamos o que fazer.
									","
											Şuna ne dersiniz:
											Ya herhangi bir durumda hesaplamalar yapıp,
											seçeneklere bakıp,
											hangisinin daha iyi olduğunu ölçerek ne yapacağınızı bilebilirseniz?
											Bu tanıdık geliyor mu?
											İşte bu faydacı ahlak çerçevesi.
											John Stuart Mill bunun en büyük savunucusuydu —
											ayrıca iyi bir adamdı —
											ve sadece 200 yıl önce öldü.
											Dolayısıyla faydacılığın temeli —
											En azından aşina olduğunuza eminim.
											Başlarda Mill için el kaldırmış üç kişi için bunlar tanıdıktır.
											Ama işte bu şekilde çalışır.
											Ya ahlak kuralları, yani bir şeyin ahlaklı olmasını sağlayanlar,
											onların sadece hazzı çoğaltması ve acıyı azaltması
											ile ilgiliyse?
											Eyleme içkin bir şey.
											Soyut bir biçim ile olan ilişkisi gibi değil.
											Ortaya çıkan sonuçlarla ilgili bir şey.
											Sadece sonuçlara bakıyorsunuz
											ve eylemin iyi veya kötü olduğunu görüyorsunuz.
											Böylesi basit olurdu. Böylece ne yapacağımızı bilebiliriz.
									","
											Que diriez-vous de ceci :
											et si dans n'importe quelle situation, vous pouviez simplement calculer,
											examiner les possibilités,
											évaluer laquelle est la meilleure et savoir quoi faire ?
											Cela vous dit quelque chose ?
											C'est un système moral utilitariste.
											John Stuart Mill en était un grand partisan —
											un type bien par ailleurs —
											et il n'est mort que depuis 200 ans.
											Donc les fondements de l'utilitarisme —
											je suis sûr que vous les connaissez.
											Les trois personnes qui ont voté pour Mill tout à l'heure savent ce que c'est.
											Mais voilà comment ça fonctionne.
											Et si la morale, si ce qui rend quelque chose moral,
											n'était qu'un calcul de plaisir maximum
											et de douleur minimum ?
											C'est intrinsèque au fait.
											Ça n'a pas de rapport avec sa forme abstraite.
											C'est juste fonction des conséquences.
											Vous regardez simplement les conséquences,
											et vous voyez si, globalement, c'est pour le meilleur ou pour le pire.
											Ce serait simple. Nous saurions ensuite quoi faire.
									","
											Wie wäre es damit:
											Was, wenn man in jeder Situation einfach rechnen könnte,
											sich die Wahlmöglichkeiten ansehen,
											messen, welche die bessere ist und wissen, was tun?
											Klingt das vertraut?
											Das ist ein utilitaristischer moralischer Massstab.
											John Stuart Mill war ein grosser Verfechter davon –
											ein guter Mann übrigens –
											und erst seit 200 Jahren tot.
											Die Grundlage des Utilitarianismus –
											ich bin sicher, damit sind Sie zumindest vertraut.
											Die drei Leute, die vorhin für Mill gestimmt haben, sind damit vertraut.
											Aber so funktioniert es.
											Was, wenn die Moral, das was etwas moralisch macht,
											nur eine Frage davon ist, ob es Vergnügen maximiert
											und Schmerz minimiert?
											Es fügt der Tat etwas intrinsisches hinzu.
											Es ist nicht wie ihre Beziehung zu einer abstrakten Form.
											Es ist eine Frage der Konsequenzen.
											Man sieht sich die Konsequenzen an
											und ob es, über alles gesehen, zum Guten oder zum Schlechten ist.
											Das wäre einfach. Dann wüssten wir, was zu tun ist.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Let's take an example.
											Suppose I go up
											and I say, ""I'm going to take your phone.""
											Not just because it rang earlier,
											but I'm going to take it because I made a little calculation.
											I thought, that guy looks suspicious.
											And what if he's been sending little messages to Bin Laden's hideout —
											or whoever took over after Bin Laden —
											and he's actually like a terrorist, a sleeper cell.
											I'm going to find that out, and when I find that out,
											I'm going to prevent a huge amount of damage that he could cause.
											That has a very high utility to prevent that damage.
											And compared to the little pain that it's going to cause —
											because it's going to be embarrassing when I'm looking on his phone
											and seeing that he has a Farmville problem and that whole bit —
											that's overwhelmed
											by the value of looking at the phone.
											If you feel that way,
											that's a utilitarian choice.
									","
											Pongamos un ejemplo.
											Supongamos que voy
											y digo, ""Voy a tomar tu teléfono"".
											No sólo porque sonó antes,
											sino que lo voy a tomar porque hice un pequeño cálculo.
											Pensé, ese tipo parece sospechoso.
											Y qué tal si ha estado enviando mensajes a la guarida de Bin Laden —
											o quien haya reemplazado a Bin Laden -
											Y en realidad es un terrorista, una célula latente.
											Voy a averiguarlo, y cuando lo descubra,
											voy a evitar el enorme daño que podría causar.
											Eso va a ser muy útil para evitar ese daño.
											Y comparado con el pequeño dolor que va a causar —
											porque va a ser vergonzoso cuando vea su teléfono móvil
											y vea que tiene un problema con Farmville y todo lo demás -
											eso es minimizado
											por el valor de mirar su teléfono.
											Si consideran ese camino,
											esa es una opción utilitarista.
									","
											Tomemos um exemplo.
											Suponham que eu digo:
											""Vou-lhe tirar o seu telemóvel.""
											Não só porque, há bocado, ele tocou,
											mas porque fiz um pequeno cálculo.
											Aquele indivíduo pareceu-me suspeito.
											E se ele tiver estado a enviar mensagens
para o esconderijo do Bin Laden,
											ou para quem quer
que tenha sucedido a Bin Laden?
											Parece mesmo um terrorista,
uma célula de espionagem.
											Vou descobrir isso e, quando descobrir,
											vou impedir os enormes prejuízos
que ele podia causar.
											Será muito útil
para evitar esses prejuízos.
											Em comparação com a pequena dor
que vai causar,
											— porque será embaraçoso
eu estar a ver o telemóvel,
											a ver que ele tem problemas
na Farmville, etc. —
											isso é minimizado
											pela vantagem de ver o telemóvel.
											Se vocês pensarem assim,
											trata-se de uma escolha utilitária.
									","
											Bir örnek ele alalım.
											İyice ileri gittiğimi varsayalım
											diyorum ki, “Telefonunu alacağım”
											Zamansız çaldığı için değil ama,
											onu alacağım çünkü küçük bir hesaplama yaptım.
											Bu adamın şüpheli göründüğünü düşündüm.
											Ya Bin Ladin’in saklandığı yere küçük mesajlar gönderip duruyorsa —
											veya Bin Ladin’den sonra yerine geçen her kimse —
											ve bu adam aslında bir terörist, emir bekleyen bir saldırgan.
											Ben bunu ortaya çıkartacağım, ve bunu yaptığımda,
											sebep olabileceği muazzam boyuttaki zararı önlemiş olacağım.
											Hasar önleme konusunda çok büyük faydası var bunun.
											Ve sebep olacağı azıcık ıstırabı, kıyasladığımda —
											çünkü telefonuna bakıp aslında Farmville’de küçük bir problemi olduğunu
											gördüğümde bu biraz utanç verici olacak —
											bu benim telefona
											bakmamın değeri karşısında hiçbir şey olmayacak.
											Eğer bu şekilde düşünüyorsanız,
											bu faydacı bir seçimdir.
									","
											Prenons un exemple.
											Imaginez que je vienne
											et je dise : « Je vais vous prendre votre téléphone. »
											Pas parce qu'il a sonné tout à l'heure,
											mais parce que j'ai fait un petit calcul.
											Je pensais que ce type avait l'air suspect.
											Et s'il était en train d'envoyer des messages à la planque de Ben Laden —
											ou de n'importe qui ayant pris la relève de Ben Laden —
											c'est en fait un terroriste, une cellule dormante.
											Je vais m'en rendre compte, et quand ce sera fait,
											je vais éviter d'énormes dégâts qu'il pourrait causer.
											L'intérêt est très grand d'éviter les dégâts,
											comparé au moindre mal qu'il y aurait
											si je le gêne en regardant dans son téléphone
											pour découvrir qu'il ne faisait que jouer à Farmville —
											c'est écrasé
											par l'utilité d'examiner son téléphone.
											Si vous pensez comme cela,
											c'est un choix utilitariste.
									","
											Lassen Sie uns ein Beispiel machen.
											Nehmen wir an, ich gehe hier hoch
											und ich sage, ""Ich nehme jetzt Ihr Telefon.""
											Nicht, weil es vorhin geklingelt hat,
											ich nehme es, weil ich eine kleine Berechnung gemacht habe.
											Ich dachte mir, dieser Typ sieht verdächtig aus.
											Und was, wenn er Nachrichten an Bin Ladens Versteck geschickt hat –
											oder an wen auch immer, der nach Bin Laden übernommen hat –
											und er ist tatsächlich sowas wie ein Terrorist, eine Schläferzelle.
											Ich werde das herausfinden, und wenn ich es herausfinde,
											werde ich eine grosse Menge Schaden verhindern, den er anrichten könnte.
											Es hat einen sehr hohen Nutzen, diesen Schaden zu verhindern.
											Und verglichen mit dem kleinen Schmerz, den es verursachen wird –
											denn es wird unangenehm sein, wenn ich mir sein Telefon ansehe
											und sehe dass er ein Farmville-Problem und all das hat –
											das wird überstrahlt
											vom Wert, sich das Telefon anzusehen.
											Wenn Sie so fühlen,
											ist das eine utiliaristische Wahl.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											But maybe you don't feel that way either.
											Maybe you think, it's his phone.
											It's wrong to take his phone
											because he's a person
											and he has rights and he has dignity,
											and we can't just interfere with that.
											He has autonomy.
											It doesn't matter what the calculations are.
											There are things that are intrinsically wrong —
											like lying is wrong,
											like torturing innocent children is wrong.
											Kant was very good on this point,
											and he said it a little better than I'll say it.
											He said we should use our reason
											to figure out the rules by which we should guide our conduct,
											and then it is our duty to follow those rules.
											It's not a matter of calculation.
									","
											Pero tal vez tampoco consideren esa opción.
											Tal vez piensen, es su teléfono.
											No está bien tomar su teléfono,
											porque él es una persona
											y tiene derechos y dignidad,
											y simplemente no podemos interferir en eso.
											Él tiene autonomía.
											No importa cuáles sean los cálculos.
											Hay cosas que intrínsecamente están mal —
											como mentir está mal.
											torturar a niños inocentes está mal.
											Kant era muy bueno en este punto,
											y planteaba esto un poco mejor de lo que yo lo haré.
											Decía que deberíamos usar nuestro razonamiento
											para decidir las reglas que deberían guiar nuestra conducta.
											Y luego es nuestro deber seguir esas reglas.
											No es una cuestión de cálculos.
									","
											Mas talvez também 
não pensem dessa maneira.
											Talvez pensem, o telemóvel é dele.
											É errado tirar-lhe o telemóvel,
											porque é uma pessoa,
tem direitos, e tem dignidade,
											e não podemos simplesmente
interferir neles.
											Ele tem autonomia.
											Não interessam os cálculos.
											Há coisas que são
intrinsecamente erradas
											— mentir é errado,
											como é errado torturar crianças inocentes.
											Kant era muito bom neste ponto,
											e disse isto um pouco melhor
do que eu direi.
											Ele disse que devíamos usar a nossa razão
											para decidir as regras que
deviam orientar a nossa conduta.
											E depois é nosso dever
seguir essas regras.
											Não é uma questão de cálculos.
									","
											Ama belki, bu şekilde de düşünmüyorsunuz.
											Belki de sizce, bu onun telefonu.
											Bu adamın telefonunu almamız yanlış bir şey,
											çünkü o bir birey,
											onun kişisel hakları ve bir itibarı var,
											ve biz bunlara öylece müdahale edemeyiz.
											Onun bir özyönetimi var.
											Hesaplamaların ne olduğu mühim değil.
											İçkin olarak yanlış olan şeyler vardır —
											mesela yalan söylemek yanlıştır,
											mesela masum çocuklara işkence etmek yanlıştır.
											Kant bu noktada çok iyidi,
											ve benim ifade edeceğimden biraz daha iyisini söyledi.
											O, davranışlarımızı yönlendirmemiz gereken kuralları belirlemek için
											idrakımızı kullanmamız gerektiğini söyledi.
											Sonrasında bu kuralları takip etmek bizim görevimiz.
											Bu hesaplanacak bir şey değil.
									","
											Mais peut-être que vous ne pensez pas non plus comme ça.
											Peut-être que vous vous dites : c'est son téléphone.
											C'est mal de prendre son téléphone,
											parce que c'est un individu
											et il a des droits et il a une dignité,
											et nous ne pouvons pas interférer avec ça.
											Il est autonome.
											Peut importe les calculs.
											Ces choses sont intrinsèquement mauvaises —
											comme mentir est mal,
											de même que torturer des enfants innocents est mal.
											Kant était vraiment bon sur ce sujet,
											et il le disait un peu mieux que je vais le dire.
											Il disait que nous devrions utiliser notre raison
											pour décider des règles selon lesquelles nous devrions orienter notre conduite.
											Il est ensuite de notre devoir de suivre ces règles.
											Ça n'a rien à voir avec des calculs.
									","
											Aber vielleicht fühlen Sie auch nicht so.
											Vielleicht denken Sie, es ist sein Telefon.
											Es ist falsch, sein Telefon zu nehmen,
											denn er ist eine Person
											und er hat Rechte und seine Würde,
											und wir können das nicht einfach beeinträchtigen.
											Er ist autonom.
											Es spielt keine Rolle, wie die Berechnungen sind.
											Es gibt Dinge, die intrinsisch falsch sind –
											wie es falsch ist, zu lügen
											oder unschuldige Kinder zu quälen.
											Kant war in diesem Punkt sehr gut,
											und er sagte es ein bisschen besser, als ich es sagen werde.
											Er sagte, wir sollten unsere Vernunft benutzen,
											um die Regeln herauszufinden, die unser Verhalten bestimmen.
											Und dann ist es unsere Pflicht, diesen Regeln zu folgen.
											Es ist keine Frage von Berechnung.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											So let's stop.
											We're right in the thick of it, this philosophical thicket.
											And this goes on for thousands of years,
											because these are hard questions,
											and I've only got 15 minutes.
											So let's cut to the chase.
											How should we be making our decisions?
											Is it Plato, is it Aristotle, is it Kant, is it Mill?
											What should we be doing? What's the answer?
											What's the formula that we can use in any situation
											to determine what we should do,
											whether we should use that guy's data or not?
											What's the formula?
											There's not a formula.
											There's not a simple answer.
									","
											Así que detengámonos.
											Estamos justo en el centro de esta maraña filosófica.
											Esto continuó durante miles de años,
											porque son preguntas difíciles,
											y solo tengo 15 minutos.
											Por lo tanto, vamos directo al grano.
											¿Cómo debemos tomar nuestras decisiones?
											¿De acuerdo a Platón, a Aristóteles, a Kant, a Mill?
											¿Qué debemos hacer? ¿Cuál es la respuesta?
											¿Cuál es la fórmula que podemos usar en cualquier situación
											para determinar qué debemos hacer,
											sea que debamos o no usar la información de ese hombre?
											¿Cuál es la fórmula?
											No hay fórmula.
											No hay una respuesta simple.
									","
											Por isso vamos parar.
											Estamos mesmo no cerne
deste emaranhado filosófico.
											E isto continua durante milhares de anos,
											porque estas questões são difíceis,
											e só dispomos de 15 minutos.
											Por isso, vamos diretos ao que interessa.
											Como devemos tomar as nossas decisões?
											De acordo com Platão,
Aristóteles, Kant, Mill?
											O que devemos fazer? Qual é a resposta?
											Qual é a fórmula que podemos usar
em qualquer situação
											para determinar o que devemos fazer,
											se devemos ou não usar as informações
daquele individuo?
											Qual é a fórmula?
											Não há nenhuma fórmula.
											Não há uma resposta simples.
									","
											Öyleyse şimdi duralım.
											Bu meselenin felsefi çalılıklarında dolaşmakta haklıyız.
											Ve bu binlerce yıldır sürüyor,
											çünkü bunlar zor sorular,
											ve benim yalnızca 15 dakikam var.
											Öyleyse sadede gelelim.
											Kararlarımızı nasıl vermeliyiz?
											Platon mu, Aristo mu, Kant mı, yoksa Mill mi?
											Ne yapmalıyız? Cevap ne?
											O adamın verilerini kullanıp kullanmama konusunda
											ne yapmamız gerektiğini belirlemek için,
											Her durumda kullanabileceğimiz türden formül ne?
											Nedir bunun formülü?
											Böyle bir formül yok.
											Basit bir cevap yok.
									","
											Arrêtons-nous.
											Nous sommes au cœur de cet enchevêtrement philosophique.
											Et le débat perdure depuis des milliers d'années,
											parce que ce sont des questions difficiles,
											et je n'ai que 15 minutes.
											Alors allons droit au but.
											Comment devrions-nous prendre nos décisions ?
											Selon Platon, en accord avec Aristote, ou bien Kant, ou Mill ?
											Que devrions-nous faire ? Quelle est la réponse ?
											Quelle est la formule que nous pouvons utiliser dans n'importe quelle situation
											pour déterminer ce que nous devrions faire ?
											Si nous devrions utiliser les données de ce type ou pas ?
											Quelle est la formule ?
											Il n'y a pas de formule.
											Il n'y a pas de réponse simple.
									","
											Also lassen Sie uns aufhören.
											Wir sind mitten drin in diesem philosophischen Gewühl.
											Und das geht schon seit Tausenden von Jahren so,
											denn das sind schwierige Fragen
											und ich habe nur 15 Minuten.
											Also lassen Sie uns auf den Punkt kommen.
											Wie sollten wir unsere Entscheidungen treffen?
											ist es Plato, Aristoteles, Kant oder Mill?
											Was sollten wir tun? Was ist die Antwort?
											Was ist die Formel, die wir in jeder Situation benutzen können,
											um festzulegen, was wir tun sollten,
											ob wir die Daten dieses Mannes verwenden sollten oder nicht?
											Was ist die Formel'
											Es gibt keine Formel.
											Es gibt keine einfache Antwort.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Ethics is hard.
											Ethics requires thinking.
											And that's uncomfortable.
											I know; I spent a lot of my career
											in artificial intelligence,
											trying to build machines that could do some of this thinking for us,
											that could give us answers.
											But they can't.
											You can't just take human thinking
											and put it into a machine.
											We're the ones who have to do it.
											Happily, we're not machines, and we can do it.
											Not only can we think,
											we must.
											Hannah Arendt said,
											""The sad truth
											is that most evil done in this world
											is not done by people
											who choose to be evil.
											It arises from not thinking.""
											That's what she called the ""banality of evil.""
											And the response to that
											is that we demand the exercise of thinking
											from every sane person.
									","
											La ética es algo difícil.
											Requiere reflexión.
											Y eso es incómodo.
											Lo sé; pasé gran parte de mi carrera
											en inteligencia artificial,
											tratando de construir máquinas que pudiesen pensar algunas de estas cuestiones por nosotros,
											que pudiesen darnos respuestas.
											Pero ellas no pueden.
											No se puede tomar el pensamiento humano
											y ponerlo dentro de una máquina.
											Somos nosotros quienes debemos hacerlo.
											Felizmente, no somos máquinas y podemos hacerlo.
											Y no sólo podemos pensar,
											debemos hacerlo.
											Hannah Arendt dijo:
											""La triste verdad
											es que el mayor daño hecho en este mundo
											no lo causan las personas
											que eligen ser malas.
											Surge de la falta de pensamiento"".
											Es lo que ella llamaba la ""banalidad del mal"".
											Y la respuesta a eso
											es que demandamos el ejercicio del pensamiento
											de cada persona sana.
									","
											A ética é difícil.
											A ética requer pensamento.
											E é desconfortável.
											Eu sei, passei grande parte
da minha carreira
											na inteligência artificial,
tentando construir máquinas
											que pudessem pensar
nalgumas destas questões por nós,
											dar-nos respostas.
											Mas não podem.
											Não se consegue pegar no pensamento humano
											e colocá-lo numa máquina.
											Somos nós que temos de pensar.
											Felizmente, não somos máquinas,
podemos pensar.
											Não só podemos pensar,
mas devemos fazê-lo.
											Hannah Arendt disse:
											""A triste verdade
											""é que o maior mal feito neste mundo
											""não é feito por pessoas
que escolhem ser más.
											""Ele surge da falta do pensamento.""
											É o que ela denomina
a ""banalidade do mal.""
											E a resposta a isso
											é que exigimos o exercício do pensamento
											a todas as pessoas sãs.
									","
											Etik zordur.
											Etik düşünmeyi gerektirir.
											Ve bu tatsız bir durum.
											Biliyorum, kariyerimin çoğunu
											yapay zeka için kullandım,
											bizim için düşünme işinin bir kısmını yapabilecek, bize cevaplar verebilecek
											makineler üretmeye çalışmakta.
											Ama yapamıyorlar.
											Gidip insan düşüncesini alıp
											aynen bir makineye yerleştiremiyorsunuz.
											Bu işi yapması gereken bizleriz.
											Şükür ki biz makine değiliz ve biz bunu yapabiliyoruz.
											Sadece düşünmeyi becermekle kalmıyoruz,
											buna mecburuz.
											Hannah Arendt şöyle söylüyor,
											“Acı gerçek şu ki
											dünyadaki kötülüklerin çoğu
											kötü olmayı seçen kişiler
											tarafından yapılmıyor.
											Düşünmemekten kaynaklanıyor.”
											Bu, onun “kötülüğün bayağılığı” dediği şey.
											Ve buna verilecek karşılık,
											aklı başında her insan tarafından düşünme tatbikine
											gereksinim duymamız.
									","
											L'éthique, c'est difficile.
											L'éthique exige une réflexion.
											C'est inconfortable.
											Je sais ; j'ai passé une grande partie de ma carrière
											dans l'intelligence artificielle,
											à essayer de construire des machines qui puissent réfléchir là-dessus pour nous,
											qui puissent nous donner des réponses.
											Mais elles ne le peuvent pas.
											Vous ne pouvez pas simplement prendre la pensée humaine
											et la mettre dans une machine.
											Nous devons le faire par nous-mêmes.
											Heureusement, nous ne sommes pas des machines, et nous pouvons le faire.
											Nous pouvons non seulement penser,
											mais nous le devons.
											Hannah Arendt disait :
											« La triste vérité
											est que la plupart du mal fait en ce monde
											n'est pas fait par des gens
											qui ont choisi de faire le mal.
											Il surgit de l'inexistence d'une réflexion. »
											C'est ce qu'elle appelait « la banalité du mal. »
											La réponse à cela
											est que nous réclamons l'exercice de pensée
											à toute personne sensée.
									","
											Ethik ist schwierig.
											Ethik verlangt Denkarbeit.
											Und das ist unbequem.
											Ich weiss, ich habe einen grossen Teil meiner Karriere damit verbracht,
											mich mit künstlicher Intelligenz zu beschäftigen,
											zu versuchen, Maschinen zu bauen, die etwas von dieser Arbeit für uns tun könnten,
											die uns Antworten geben könnten.
											Aber sie können es nicht.
											Man kann nicht einfach menschliches Denken nehmen,
											und es in eine Maschine stecken.
											Wir sind diejenigen, die es tun müssen.
											Glücklicherweise sind wir keine Maschinen.
											Wir können nicht nur denken,
											wir müssen.
											Hannah Arendt sagte,
											""Die traurige Wahrheit ist,
											dass das meiste Böse, was auf dieser Welt getan wird,
											nicht von Menschen getan wird,
											die sich dazu entscheiden, schlecht zu sein.
											Es kommt dadurch, dass sie nicht nachdenken.""
											Das ist es, was wir die ""Banalität des Bösen"" nennen.
											Und die Antwort darauf ist,
											dass wir Übung im Denken verlangen
											von jeder normalen Person.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											So let's do that. Let's think.
											In fact, let's start right now.
											Every person in this room do this:
											think of the last time you had a decision to make
											where you were worried to do the right thing,
											where you wondered, ""What should I be doing?""
											Bring that to mind,
											and now reflect on that
											and say, ""How did I come up that decision?
											What did I do? Did I follow my gut?
											Did I have somebody vote on it? Or did I punt to legal?""
											Or now we have a few more choices.
											""Did I evaluate what would be the highest pleasure
											like Mill would?
											Or like Kant, did I use reason to figure out what was intrinsically right?""
											Think about it. Really bring it to mind. This is important.
											It is so important
											we are going to spend 30 seconds of valuable TEDTalk time
											doing nothing but thinking about this.
											Are you ready? Go.
									","
											Así que hagámoslo. Pensemos.
											De hecho, empecemos ahora mismo.
											Cada persona de esta sala haga esto:
											piensen en la última vez que tuvieron que tomar una decisión
											donde estuvieron preocupados por hacer lo correcto,
											donde se preguntaron, ""¿Qué debo hacer?""
											Recuerden ese momento.
											Y ahora reflexionen en eso
											y digan: ""¿Cómo llegué a esa decisión?
											¿Qué hice? ¿Seguí mi intuición?
											¿Pedí la votación de alguien? ¿Pedí opinión legal?""
											O, ahora, tenemos algunas opciones más.
											""¿Evalué cuál sería el mayor de los placeres
											como lo haría Mill?
											O al igual que Kant, ¿usé la razón para decidir qué era intrínsecamente correcto?""
											Piensen en esto. Recuerden. Esto es importante.
											Es tan importante
											que vamos a usar 30 segundos del valioso tiempo de TED
											nada más que para pensar en esto.
											¿Están listos? Vamos.
									","
											Vamos, então, fazer isso. Vamos pensar.
											De facto, vamos começar agora mesmo.
											Cada pessoa, nesta sala, faça o seguinte:
											Pensem na última vez que tiveram 
que tomar uma decisão
											em que se preocuparam
em fazer o que era certo,
											em que se perguntaram:
""O que devo fazer?""
											Recordem esse momento.
											E agora reflitam sobre ele e digam:
											""Como é que cheguei àquela decisão?
											""O que é que eu fiz? 
Segui a minha intuição?
											""Pedi a alguém para votar sobre o assunto?
Ou pedi um parecer jurídico?""
											— agora temos mais algumas opções.
											""Avaliei qual seria o prazer máximo
											como faria Mill?
											Ou, como Kant, usei a razão para decidir
o que era intrinsecamente correto?""
											Pensem nisso. Recordem-se.
Isto é importante.
											É tão importante
que vamos passar 30 segundos
											do valioso tempo do TED Talk
											a não fazer mais nada senão pensar nisto.
											Estão prontos? Comecem!
									","
											Öyleyse yapalım. Haydi düşünelim.
											Gerçekten, şimdi başlayalım.
											Bu salondaki herkes şunu yapsın:
											karar vermenizi gerektiren son zamanı düşünün
											doğru olanı yapmak için kaygılandığınız,
											Ne yapmalıyım acaba?” diye merak ettiğiniz.
											Aklınıza getirin.
											Ve şimdi üzerine kafa yorun
											deyin ki, “Bu karara nasıl vardım?”
											Ne yaptım? Kalbimin sesini mi dinledim?
											Birilerinin kanaatine mi sundum? Bir hukukçuya mı danıştım?
											Veya artık birkaç tercihimiz daha var.
											“En çok hazzı verecek şeye göre mi değerlendirme yaptım,
											Mill’in yapacağı gibi?”
											Yoksa Kant gibi, içkin doğruyu bulmak için sağduyumu mu kullandım?
											Bunu bir düşünün. Gerçekten aklınızda canlandırın. Bu önemli.
											Bu öylesine önemli ki
											değerli TEDTalk zamanımızın 30 saniyesini buna harcayacağız
											hiçbir şey yapmayıp, sadece bunun hakkında düşüneceğiz.
											Hazır mısınız? Başla.
									","
											Faisons-donc cela. Pensons.
											En fait, commençons dès maintenant.
											Tout le monde dans la salle :
											pensez à la dernière fois que vous avez dû prendre une décision
											où vous étiez préoccupés de faire ce qui est juste,
											où vous vous êtes demandés : « Que devrais-je faire ? »
											Pensez à cela.
											Réfléchissez maintenant à cela
											et demandez-vous : « Comment ais-je pris cette décision ?
											Qu'est-ce que j'ai fait ? Est-ce que j'ai suivi mon instinct ?
											Est-ce que j'ai fait procéder à un vote ? Ou est-ce que j'ai fait appel au service juridique ? »
											Ou bien nous avons d'autres choix maintenant.
											« Est-ce que j'ai estimé ce qui procurerait le plus de plaisir,
											comme Mill l'aurait fait ?
											Ou comme Kant, ai-je utilisé ma raison pour décider de ce qui était intrinsèquement juste ?
											Pensez-y. Vraiment. C'est important.
											C'est si important
											que nous allons passer 30 précieuses secondes de mon intervention à TED
											à ne rien faire d'autre que d'y penser.
											Vous êtes prêts ? Allez-y.
									","
											Also lassen Sie uns das tun. Lassen Sie uns nachdenken.
											Lassen Sie uns jetzt gleich damit anfange.
											Jede Person in diesem Raum tut das folgende:
											denken Sie an das letzte Mal, als Sie eine Entscheidung treffen mussten
											und sich darum sorgten, das Richtige zu tun,
											wo Sie sich gefragt haben, ""Was sollte ich tun?""
											Rufen Sie sich das in Erinnerung.
											Und jetzt reflektieren Sie das
											und sagen sich, ""Wie kam ich zu meiner Entscheidung?""
											Was habe ich getan? Habe ich auf meinen Bauch gehört?
											Habe ich jemanden abstimmen lassen? Oder habe ich es auf den Rechtsdienst abgeschoben?
											Jetzt haben wir noch einige Möglichkeiten mehr.
											""Habe ich untersucht, was das meiste Vergnügen zur Folge hat,
											wie Mill es tun würde?
											Oder habe ich wie Kant meine Vernunft benutzt, um herauszufinden, was intrinsisch richtig ist?""
											Denken Sie darüber nach. Rufen Sie es sich richtig in Erinnerung. Das ist wichtig.
											Es ist so wichtig,
											dass wir 30 Sekunden wertvoller TEDTalk-Zeit darauf verwenden werden,
											nichts anderes zu tun, als darüber nachzudenken.
											Sind Sie bereit? Los.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Stop. Good work.
											What you just did,
											that's the first step towards taking responsibility
											for what we should do with all of our power.
									","
											Paren. Buen trabajo.
											Lo que acaban de hacer,
											es el primer paso en el sentido de asumir responsabilidad
											por lo que debemos hacer con todo nuestro poder.
									","
											Parem. Bom trabalho.
											O que acabaram de fazer
											é o primeiro passo no sentido
de assumir a responsabilidade
											sobre o que devemos fazer
com todo o nosso poder.
									","
											Tamam dur. Güzel.
											Az önce yaptığınız,
											gücümüzle ne yapmamız gerektiği konusunda
											sorumluluk alma yolunda ilk adımdı.
									","
											Arrêtez. Bon travail.
											Ce que vous venez de faire,
											c'est le premier pas vers la prise de responsabilité
											concernant ce que nous devrions faire avec tout ce pouvoir.
									","
											Stopp. Gute Arbeit.
											Was Sie gerade getan haben,
											ist der erste Schritt dazu, Verantwortung dafür zu übernehmen,
											was wir mit all unserer Macht tun sollten.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Now the next step — try this.
											Go find a friend and explain to them
											how you made that decision.
											Not right now. Wait till I finish talking.
											Do it over lunch.
											And don't just find another technologist friend;
											find somebody different than you.
											Find an artist or a writer —
											or, heaven forbid, find a philosopher and talk to them.
											In fact, find somebody from the humanities.
											Why? Because they think about problems
											differently than we do as technologists.
											Just a few days ago, right across the street from here,
											there was hundreds of people gathered together.
											It was technologists and humanists
											at that big BiblioTech Conference.
											And they gathered together
											because the technologists wanted to learn
											what it would be like to think from a humanities perspective.
											You have someone from Google
											talking to someone who does comparative literature.
											You're thinking about the relevance of 17th century French theater —
											how does that bear upon venture capital?
											Well that's interesting. That's a different way of thinking.
											And when you think in that way,
											you become more sensitive to the human considerations,
											which are crucial to making ethical decisions.
									","
											Ahora el siguiente paso — prueben esto.
											Busquen un amigo y explíquenle
											cómo tomaron esa decisión.
											Ahora no. Esperen el final de la charla.
											Durante el almuerzo.
											Y no lo hagan con otro amigo tecnólogo;
											encuentren alguien diferente a ustedes.
											Encuentren un artista o un escritor —
											o, Dios nos libre, encuentren un filósofo y hablen con ellos.
											De hecho, encuentren alguien de las humanidades.
											¿Por qué? Porque ellos piensan en los problemas
											de forma diferente a como lo hacemos los tecnólogos.
											Hace unos días, aquí en frente, al otro lado de la calle,
											había cientos de personas reunidas.
											Eran tecnólogos y humanistas
											en una conferencias sobre Bibliotecas Tecnológicas.
											Y ellos se reunieron
											porque los tecnólogos querían aprender
											cómo era pensar desde una perspectiva humanista.
											Hay alguien de Google
											hablando con alguien que hace literatura comparada.
											Están pensando sobre la relevancia del teatro francés del siglo XVII —
											¿cómo se relaciona eso con el capital de riesgo?
											Bien eso es interesante. Es una forma de pensar diferente.
											Y cuando piensan de esa forma,
											se vuelven más sensibles a las cuestionas humanas,
											lo cual es crucial para tomar decisiones éticas.
									","
											Agora, o passo seguinte — tentem isto.
											Procurem um amigo e expliquem-lhe
											como tomaram aquela decisão.
											Não neste preciso momento.
Esperem que eu acabe de falar.
											Façam-no ao almoço.
											E não se limitem a fazê-lo com outro amigo
da área da tecnologia.
											Encontrem alguém diferente de vocês,
											um artista ou um escritor
											ou, o céu vos proteja,
encontrem um filósofo e falem com ele.
											De facto, encontrem alguém
da área de humanidades.
											Porquê? Porque eles pensam nos problemas
											de uma forma diferente
dos da área tecnológica.
											Há poucos dias, aqui em frente,
mesmo do outro lado da rua,
											reuniram-se centenas de pessoas,
											das áreas humanística e tecnológica
											naquela conferência
sobre Bibliotecas Tecnológicas.
											Juntaram-se todos, porque
os de tecnologia queriam aprender
											como seria pensar a partir
de uma perspetiva humanista.
											Havia pessoas do Google
											a falar com pessoas
que fazem literatura comparativa.
											Estão a pensar na relevância
do teatro francês do séc. XVII
											como é que ele influenciou
o capital de risco?
											Isso é interessante.
É uma forma diferente de pensar.
											E quando pensamos dessa maneira,
											tornamo-nos mais sensíveis
às considerações humanas,
											que são fundamentais
para a tomada de decisões éticas.
									","
											Şimdi bir sonraki adım – şunu deneyin.
											Gidip bir arkadaşınızı bulun ve ona
											bu kararı nasıl aldığınızı anlatın.
											Şimdi değil. Konuşmamızı bitirene kadar bekleyin.
											Öğle yemeğinden sonra yapın.
											Ve gidip yine bir teknoloji uzmanı bulmayın;
											sizden farklı olan birini bulun.
											Bir sanatçı veya yazar bulun —
											veya tanrı göstermesin, bir felsefeci bulup onunla konuşun.
											Hakikaten, beşeri bilimlerden birini bulun.
											Niye? Çünkü onlar sorunlar hakkında
											biz teknoloji uzmanlarından farklı düşünür.
											Birkaç gün önce, buranın karşı sokağında,
											yüzlerce insan toplanmıştı.
											Teknoloji uzmanları ve hümanistler,
											şu büyük BiblioTech konferansındaydı.
											Bir araya geldiler
											çünkü teknoloji uzmanları, beşeri bilimler perspektifiyle
											düşünmenin nasıl bir şey olduğunu öğrenmek istiyordu.
											Google'da çalışan birini
											karşılaştırmalı edebiyat üzerine çalışan biri ile konuşurken buluyordunuz.
											Şimdi 17inci yüzyıl Fransız tiyatrosunu düşünüyorsunuz —
											bunun risk sermayesi ile nasıl bir ilgisi olabilir?
											Evet ilginç. Bu farklı bir düşünme şekli.
											Ve bu şekilde düşündüğünüzde,
											insani hususlara karşı daha duyarlı hale geliyorsunuz,
											ki bunlar etik kararlar alırken oldukça can alıcı.
									","
											La prochaine étape : essayez ceci.
											Allez trouver un ami et expliquez-lui
											comment vous avez pris cette décision.
											Pas tout de suite. Attendez que j'ai terminé de parler.
											Faites-le au déjeuner.
											N'allez pas simplement trouver un autre ami technologue ;
											trouvez quelqu'un de différent.
											Trouvez un artiste ou un écrivain —
											ou, Dieu vous en préserve, trouvez un philosophe et parlez leur.
											En fait, trouvez quelqu'un dans les sciences humaines.
											Pourquoi ? Parce qu'ils pensent aux problèmes
											d'une manière différente à nous les technologues.
											Il y a juste quelques jours, de l'autre côté de la rue ici,
											il y avait un rassemblement de centaines de personnes.
											C'était des technologues et des humanistes
											à la grande BiblioTech Conférence.
											Ils étaient rassemblés
											parce que les technologues voulaient apprendre
											ce que cela faisait de penser du point de vue des sciences sociales.
											Vous avez quelqu'un de chez Google
											qui parle à quelqu'un qui fait de la littérature comparée.
											Vous vous demandez quel est l'intérêt du théâtre français du 17ème siècle —
											quel est le lien avec le capital-risque ?
											Eh bien, c'est intéressant. C'est une manière de penser différente.
											Quand vous pensez de cette façon,
											vous devenez plus sensible aux considérations humaines,
											ce qui est crucial pour prendre des décisions éthiques.
									","
											Jetzt der nächste Schritt – versuchen Sie das.
											Gehen Sie zu einem Freund und erklären Sie ihm,
											wie Sie diese Entscheidung gefällt haben.
											Nicht jetzt. Warten Sie, bis ich fertig gesprochen habe.
											Tun Sie es in der Mittagspause.
											Und finden Sie nicht einfach einen anderen Freund aus der Technologie,
											finden Sie jemanden, der anders ist als Sie.
											Finden Sie einen Künstler oder einen Autoren –
											oder, Gott bewahre, finden Sie einen Philosophen und sprechen Sie mit ihm.
											Tatsächlich sollten Sie einen Geisteswissenschaftler finden.
											Warum? Weil sie anders über Probleme nachdenken,
											als wir das als Technologen tun.
											Vor einigen Tagen waren hier auf der anderen Strassenseite
											Hunderte von Menschen versammelt.
											Es gab Technologen und Geisteswissenschaftler
											an dieser grossen BiblioTech Konferenz.
											Sie kamen zusammen,
											weil die Technologen lernen wollten,
											wie es wäre, aus einer geisteswissenschaftlichen Perspektive zu denken.
											Da hat man dann jemanden von Google,
											im Gespräch mit jemandem der Literaturvergleiche macht.
											Man denkt über die Relevant des Französischen Theaters im 17. Jahrhundert nach –
											wie kommt das gegen Venture Kapital an?
											Das ist interessant. Das ist eine andere Art zu denken.
											Wenn man auf diese Weise nachdenkt,
											wird man sensibler für menschliche Überlegungen,
											die entscheidend für ethische Entscheidungen sind.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											So imagine that right now
											you went and you found your musician friend.
											And you're telling him what we're talking about,
											about our whole data revolution and all this —
											maybe even hum a few bars of our theme music.
											♫ Dum ta da da dum dum ta da da dum ♫
											Well, your musician friend will stop you and say,
											""You know, the theme music
											for your data revolution,
											that's an opera, that's Wagner.
											It's based on Norse legend.
											It's Gods and mythical creatures
											fighting over magical jewelry.""
											That's interesting.
											Now it's also a beautiful opera,
											and we're moved by that opera.
											We're moved because it's about the battle
											between good and evil,
											about right and wrong.
											And we care about right and wrong.
											We care what happens in that opera.
											We care what happens in ""Apocalypse Now.""
											And we certainly care
											what happens with our technologies.
									","
											Entonces, imaginen que ahora mismo
											van y encuentran a su amigo músico.
											Y le cuentan lo que estuvimos hablando,
											sobre la revolución de la información y todo eso —
											incluso tarareando algunas partes de nuestro tema:
											♫ Dum ta da da dum dum ta da da dum ♫
											Bueno, su amigo músico los detendrá y dirá:
											""Sabes, la música de fondo
											para tu revolución de la información,
											es una ópera, es Wagner.
											Se basa en la mitología nórdica.
											Son dioses y criaturas míticas
											luchando por joyas mágicas"".
											Eso es interesante.
											También es una ópera hermosa.
											Y esa ópera nos emociona.
											Nos emociona porque es sobre la lucha
											entre el bien y el mal,
											sobre lo correcto y lo incorrecto.
											Y nos importa lo que lo correcto y lo incorrecto.
											Nos importa lo que pasa en la ópera.
											Nos importa lo que pasa en ""Apocalipsis Now"".
											Y sin duda que nos importa
											lo que pasa con nuestras tecnologías.
									","
											Então, imaginem que agora mesmo
											encontravam o vosso amigo músico.
											E contavam-lhe aquilo
de que estamos a falar,
											sobre a revolução na informação,
											talvez até trauteassem partes
do nosso tema musical:
											♫ Dum ta da da dum dum ta da da dum ♫
											Aí, o vosso amigo músico
interrompe-vos e diz:
											""Sabes, a música de fundo
											""da vossa revolução da informação
											""é uma ópera, é Wagner.
											""É baseada na mitologia nórdica.
											""São deuses e criaturas míticas
											""a lutar por joias mágicas.""
											É interessante.
											Mas também é uma ópera maravilhosa.
											Emocionamo-nos com aquela ópera.
											Ficamos emocionados
porque se trata de uma batalha
											entre o bem e o mal,
											sobre o certo e o errado.
											E nós preocupamo-nos
com o certo e o errado.
											Preocupamo-nos com
o que acontece naquela ópera.
											Preocupamo-nos com o que acontece
no ""Apocalypse Now.""
											E preocupamo-nos certamente
											com o que acontece
com as nossas tecnologias.
									","
											Öylese şimdi şunu hayal edin
											gittiniz ve müzisyen bir arkadaşınızı buldunuz.
											Ona hakkında konuştuğumuz şeyi anlatıyorsunuz,
											tüm bu veri devrimini ve tüm bunları —
											hatta belki şu parçamızdan birkaç ölçü mırıldanıyorsunuz.
											♫ Dum ta da da dum dum ta da da dum ♫
											Müzisyen arkadaşınız sizi durdurup şunu söyleyecek,
											“Hani şu müzik parçası var ya
											şu veri devrimi için,
											işte o bir opera, bir Wagner eseri.
											İskandinav efsaneleri üzerine.
											Tanrılar ve mitsel yaratıklar
											sihirli mücevherler için savaşıyorlar.”
											Bu enteresan.
											Ayrıca güzel de bir opera.
											Biz bu opera ile duygulanıyoruz.
											Duygulanıyoruz, çünkü bu opera iyi ile kötü arasında
											doğru ile yanlış arasında
											geçen bir savaş hakkında yazılmış.
											Ve biz doğru ile yanlışı önemsiyoruz.
											Biz o operada ne olduğunu önemsiyoruz.
											Biz “Kıyamet” filminde ne olduğunu önemsiyoruz.
											Ve biz kesinlikle teknolojimizle
											neler olduğunu önemsiyoruz.
									","
											Imaginez maintenant
											que vous avez trouvé votre ami musicien.
											Vous lui racontez ce dont on parle,
											sur notre révolution des données et tout ça —
											vous fredonnez peut-être quelques notes de notre thème musical.
											♫ Dum ta da da dum dum ta da da dum ♫
											Votre ami musicien va vous interrompre et vous dire :
											« Tu sais, le thème musical
											pour ta révolution des données,
											c'est un opéra, c'est Wagner.
											C'est basé sur une légende nordique.
											Ce sont des dieux et des créatures mythologiques
											qui se battent pour des bijoux magiques. »
											C'est intéressant.
											C'est aussi un magnifique opéra.
											Nous sommes émus par cet opéra.
											Nous sommes émus parce que c'est sur la bataille
											entre le bien et le mal,
											le juste et l'injuste.
											Et nous nous préoccupons du juste et de l'injuste.
											Nous nous soucions de ce qui se passe dans cet opéra.
											Nous nous soucions de ce qui se passe dans ""Apocalypse Now"".
											Et nous nous préoccupons certainement
											de ce qui se passe avec nos technologies.
									","
											Stellen Sie sich vor, dass Sie genau jetzt
											losgegangen sind und Ihren Musikerfreund getroffen haben.
											Sie erzählen ihm, worüber wir hier sprechen,
											über unsere ganze Datenrevolution und all das –
											vielleicht summen Sie sogar ein paar Takte unserer Titelmusik.
											♫ Dum ta da da dum dum ta da da dum ♫
											Ihr Musikerfreund wird Sie stoppen und sagen,
											""Weisst Du, diese Titelmusik
											für Eure Datenrevolution,
											das ist eine Oper, das ist Wagner.
											Sie basiert auf einer nordischen Legende.
											Es geht um Götter und mystische Kreaturen,
											die um magische Juwelen kämpfen.""
											Das ist interessant.
											Es ist auch eine wunderschöne Oper.
											Und die Oper bewegt uns.
											Wir sind bewegt, weil es um die Schlacht geht
											zwischen Gut und Böse,
											zwischen Richtig und Falsch.
											Richtig und Falsch sind wichtig für uns.
											Was in dieser Oper geschieht, ist wichtig für uns.
											Was in ""Apocalypse Now"" geschieht, ist wichtig für uns.
											Und auf jeden Fall ist es wichtig für uns,
											was mit unseren Technologien geschieht.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											We have so much power today,
											it is up to us to figure out what to do,
											and that's the good news.
											We're the ones writing this opera.
											This is our movie.
											We figure out what will happen with this technology.
											We determine how this will all end.
									","
											Hoy tenemos mucho poder,
											depende de nosotros decidir qué hacer.
											Y esa es la buena noticia.
											Somos nosotros los que escribimos esta ópera.
											Es nuestra película.
											Nosotros decidimos lo que pasará con esta tecnología.
											Nosotros determinamos cómo terminará todo esto.
									","
											Hoje temos muito poder,
											cabe-nos a nós decidir o que fazer.
											Essa é a boa notícia.
											Somos os únicos a escrever esta ópera.
											É o nosso filme.
											Nós decidimos o que vai acontecer
com esta tecnologia.
											Determinamos como tudo isto acabará.
									","
											Bugün çok fazla gücümüz var,
											ne yapacağımızı belirlemek bizim elimizde.
											Ve işte iyi haber de bu.
											Burada bu operayı yazanlar bizleriz.
											Bu bizim filmimiz.
											Bu teknoloji ile neler olacağını biz belirliyoruz.
											Nasıl biteceğini biz belirliyoruz.
									","
											Nous avons tant de pouvoir aujourd'hui,
											ça ne dépend que de nous de savoir ce qu'on en fait.
											C'est la bonne nouvelle.
											Nous sommes ceux qui écrivent cet opéra.
											C'est notre film.
											Nous décidons ce qui va arriver avec cette technologie.
											Nous déterminons comment tout cela va finir.
									","
											Wir haben heute soviel Macht,
											es liegt an uns, herauszufinden, was zu tun ist.
											Und das sind gute Neuigkeiten.
											Wir sind diejenigen, die die Oper schreiben.
											Das ist unser Film.
											WIr finden heraus, was mit dieser Technologie geschieht.
											Wir legen fest, wie das alles enden wird.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											Thank you.
									","
											Gracias.
									","
											Obrigado.
									","
											Teşekkür ederim.
									","
											Merci.
									","
											Dankeschön.
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
											(Applause)
									","
											(Aplausos)
									","
											(Aplausos)
									","
											(Alkışlar)
									","
											(Applaudissements)
									","
											(Applaus)
									","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
"
","
","
","
","
","
","We need a ""moral operating system""",Damon Horowitz,16:18,"TEDx,culture,philosophy,technology"
