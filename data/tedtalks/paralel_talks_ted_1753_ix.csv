en,pt,de,fr,tr,es,title,speaker,duration,tags
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											Today I'm going to talk
about technology and society.
											The Department of Transport
estimated that last year
											35,000 people died
from traffic crashes in the US alone.
											Worldwide, 1.2 million people
die every year in traffic accidents.
											If there was a way we could eliminate
90 percent of those accidents,
											would you support it?
											Of course you would.
											This is what driverless car technology
promises to achieve
											by eliminating the main
source of accidents —
											human error.
									","
											Hoje, vou falar
sobre tecnologia e sociedade.
											O Departamento de Transportes
estimou que, no ano passado,
											morreram 35 mil pessoas devido
a acidentes rodoviários, somente nos EUA.
											A nível mundial, 1,2 milhões de pessoas 
morrem por ano em acidentes rodoviários.
											Se existisse uma forma de eliminar 
90% desses acidentes,
											vocês iriam apoiá-la?
											Claro que sim.
											É isto que a tecnologia de
carros autónomos pretende alcançar
											ao eliminar a causa principal 
dos acidentes
											— o erro humano.
									","
											Ich werde heute über 
Technologie und Gesellschaft sprechen.
											Das Verkehrsministerium schätzt,
dass im letzten Jahr
											35.000 Menschen bei Verkehrsunfällen
allein in den USA gestorben sind.
											Weltweit sterben jährlich 1,2 Millionen
Menschen bei Verkehrsunfällen.
											Wenn es eine Möglichkeit gäbe,
90 % dieser Unfälle zu vermeiden,
											wären Sie dafür?
											Natürlich wären Sie das.
											Genau das ist es, was die Technologie
fahrerloser Autos erreichen möchte,
											indem sie die Hauptursache
für Autounfälle eliminiert –
											menschliches Versagen.
									","
											Aujourd'hui, je vais parler 
de technologie et de société.
											Le Département du Transport a estimé
que, l'année dernière,
											le nombre de morts dû aux accidents de la
circulation à 35 000, seulement aux USA.
											Au niveau mondial, c'est 1,2 million de
gens qui meurent chaque année.
											S'il y avait une possibilité d'éliminer
90% de ces accidents,
											la soutiendriez-vous ?
											Bien sûr que oui.
											La technologie des voitures sans 
conducteur promet d'y arriver
											en éliminant la principale source 
d'accidents—
											l'erreur humaine.
									","
											Bugün, teknoloji ve toplum
hakkında konuşacağım.
											Ulaştırma Bakanlığı verilere göre 
geçen sene yalnızca ABD'de
											35.000 insanın trafik kazalarında 
yaşamını yitirdiğini bildirdi.
											Dünya çapında, her yıl 1.2 milyon insan
trafik kazalarında hayatını kaybediyor.
											Bu kazaların yüzde 90'ını ortadan 
kaldırabileceğimiz bir yöntem olsaydı,
											bunu destekler miydiniz?
											Elbette desteklerdiniz.
											Sürücüsüz araba teknolojisi
işte bunu vadediyor;
											kazaların ana sebebini,
yani insan hatasını
											ortadan kaldırmayı.
									","
											Hoy voy a hablar de tecnología 
y de la sociedad.
											El Departamento de Transporte
estimó que, el año pasado,
											hubo 35 000 muertos
en accidentes de auto, tan solo en EE.UU.
											A nivel mundial, mueren 1,2 millones
de personas por año en accidentes de auto.
											Si hubiera una manera de eliminar
el 90 % de esos accidentes,
											¿apoyarían la causa?
											Por supuesto que lo harían.
											Esto es lo que promete
la tecnología de vehículos autónomos,
											al eliminar la principal causa
de accidentes:
											el error humano.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											Now picture yourself
in a driverless car in the year 2030,
											sitting back and watching
this vintage TEDxCambridge video.
									","
											Imaginem-se num carro autónomo
no ano de 2030,
											descontraídos e a ver este vídeo
""vintage"" do TEDxCambridge.
									","
											Stellen Sie sich vor, Sie sitzen
im Jahr 2030 in einem fahrerlosen Auto.
											Sie sind entspannt und schauen
dieses alte TEDxCambridge-Video.
									","
											Imaginez vous, en 2030, dans une voiture 
sans conducteur,
											regardant cette ancienne vidéo TED.
									","
											Şimdi kendinizi 2030 yılında
sürücüsüz bir araba içerisinde hayal edin,
											arkada oturuyor ve bu nostaljik
TEDxCambridge videosunu izliyorsunuz.
									","
											Imagínense en el año 2030,
viajando en un vehículo autónomo,
											sentados, mirando este video vintage
de un evento TEDxCambridge.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											All of a sudden,
											the car experiences mechanical failure
and is unable to stop.
											If the car continues,
											it will crash into a bunch
of pedestrians crossing the street,
											but the car may swerve,
											hitting one bystander,
											killing them to save the pedestrians.
											What should the car do,
and who should decide?
											What if instead the car
could swerve into a wall,
											crashing and killing you, the passenger,
											in order to save those pedestrians?
											This scenario is inspired
by the trolley problem,
											which was invented
by philosophers a few decades ago
											to think about ethics.
									","
											De repente,
											o carro sofre uma falha mecânica
e é incapaz de parar.
											Se o carro continuar em frente,
											irá colidir com um monte de peões
que atravessam a rua,
											mas o carro poderá desviar-se,
											atingindo um peão no passeio,
											matando-o para salvar os restantes peões.
											O que deverá o carro fazer, 
e quem deverá decidir?
											E se o carro pudesse desviar-se 
contra uma parede,
											chocando e matando o passageiro,
											de forma a salvar aqueles peões?
											Este cenário é inspirado 
pelo dilema do elétrico,
											inventado por filósofos 
há algumas décadas,
											para pensar sobre a ética.
									","
											Plötzlich tritt ein mechanischer Fehler
auf und das Auto kann nicht anhalten.
											Wenn das Auto weiterfährt,
											wird es in in ein paar Fußgänger fahren,
die gerade die Straße überqueren.
											Das Auto könnte jedoch auch ausweichen,
											einen Beobachter treffen und töten,
											um die Fußgänger zu schützen.
											Was sollte das Auto machen
und wer sollte entscheiden?
											Was wäre, wenn das Auto stattdessen
ausweichen und eine Wand treffen könnte
											und dabei Sie, den Insassen, töten würde,
											um die Fußgänger zu retten?
											Dieses Szenario ist vom
Trolley-Problem inspiriert,
											das vor einigen Jahrzehnten
von Philosophen erfunden wurde,
											um Ethik zu erforschen.
									","
											Quand tout à coup,
											une panne mécanique l'empêche
de s'arrêter.
											Si la voiture roule toujours,
											elle peut écraser les piétons qui sont
en train de traverser;
											mais elle peut aussi faire une embardée,
											touchant un passant en le tuant
											pour sauver les piétons.
											Que devrait faire la voiture
et qui devrait décider ?
											Et si la voiture fonçait dans un mur,
											vous tuant vous, le passager
											pour sauver ces piétons ?
											Ce scénario est inspiré du problème 
venant des trolleybus,
											inventé par des philosophes il y a 
quelques décennies
											pour penser à l'éthique.
									","
											Aniden,
											arabada mekanik bir arıza oluyor
ve duramıyor.
											Araba sürüşe devam ederse,
											yoldan geçen bir grup insana çarpacak,
											fakat araç direksiyon kırabilir,
											görgü tanıklarından birine çarpar
											ve böylece daha çok yaya kurtulmuş olur.
											Araba ne yapmalı
ve buna kim karar vermeli?
											Farz edelim ki,
araba direksiyonu bir duvara kırıyor,
											diğer yayaları kurtarmak adına,
											duvara çarparak arabadaki 
yolcuyu yani sizi öldürüyor.
											Bu senaryo,
bundan 30-40 yıl önce
											ahlak kuramını irdelemek adına
filozoflarca yaratılan tren ikileminden
											esinlenerek ortaya konmuş.
									","
											De pronto,
											el auto tiene una falla mecánica
y no puede detenerse.
											Si el auto continúa,
											va a atropellar a un grupo
de peatones que cruza la calle.
											Pero el auto puede cambiar de dirección,
											atropellar a un solo transeúnte,
											matarlo, y así salvar a los peatones.
											¿Qué debería hacer el auto,
y quién debería decidir?
											¿Y si en cambio el auto
pudiera irse contra una pared,
											chocar y matarte a ti, el pasajero,
											para salvar a los peatones?
											Este caso hipotético está inspirado
en el dilema del tranvía,
											que fue inventado por unos filósofos
hace unas décadas
											para reflexionar sobre la ética.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											Now, the way we think
about this problem matters.
											We may for example
not think about it at all.
											We may say this scenario is unrealistic,
											incredibly unlikely, or just silly.
											But I think this criticism
misses the point
											because it takes
the scenario too literally.
											Of course no accident
is going to look like this;
											no accident has two or three options
											where everybody dies somehow.
											Instead, the car is going
to calculate something
											like the probability of hitting
a certain group of people,
											if you swerve one direction
versus another direction,
											you might slightly increase the risk
to passengers or other drivers
											versus pedestrians.
											It's going to be
a more complex calculation,
											but it's still going
to involve trade-offs,
											and trade-offs often require ethics.
									","
											A forma como pensamos
neste problema é importante.
											Por exemplo, nós podemos
nem sequer pensar nele.
											Podemos dizer que 
este cenário é irrealista,
											extremamente improvável
ou simplesmente absurdo.
											Mas eu acho que esta crítica
perde de vista o objetivo
											porque leva o cenário demasiado à letra.
											É óbvio que nenhum acidente 
se parecerá com este;
											nenhum acidente tem duas ou três opções
											em que alguém acaba morto inevitavelmente.
											Em vez disso, o carro irá calcular algo
											como a probabilidade de embater 
num certo grupo de pessoas
											e, caso se desvie para 
uma direção ou para outra,
											poderá aumentar o risco dos passageiros
ou de outros condutores
											em vez dos peões.
											Irá ser um cálculo mais complexo,
											mas irá envolver na mesma
tomar decisões
											e muitas das vezes, 
tomar essas decisões requer ética.
									","
											Die Art, wie wir über 
das Problem denken, zählt.
											So könnten wir etwa
gar nicht darüber nachdenken.
											Wir könnten sagen, 
dass das Szenario unrealistisch,
											extrem unwahrscheinlich oder albern ist.
											Aber ich denke, dass diese Kritik
am Thema vorbeigeht,
											da sie das Szenario zu wörtlich nimmt.
											Natürlich wird kein Unfall
genauso aussehen.
											Bei keinem Unfall gibt es
zwei oder drei Optionen,
											bei denen immer jemand stirbt.
											Stattdessen wird das Auto
eine Zahl ausrechnen,
											wie die Wahrscheinlichkeit,
eine bestimmte Menschengruppe zu treffen.
											Wenn es in die eine oder
die andere Richtung ausweicht.
											könnte das Risiko für Passagiere
geringfügig höher sein,
											als das Risiko für Fußgänger.
											Die Berechnung wäre komplexer,
											würde aber immer noch
Abwägungen beinhalten
											und Abwägungen beinhalten oft Ethik.
									","
											Il est important de savoir ce que nous
en pensons.
											Peut être que nous n'y pensons
pas du tout.
											On peut trouver ce scénario irréel,
											extrêmement peu probable ou juste stupide.
											Je pense que cette critique manque
d'un point important
											car elle suit ce scénario à la lettre.
											Il est évident qu'aucun accident
ne ressemblera à ça,
											aucun accident n'a deux ou trois options
											où tout le monde finit par mourir.
											Pour contrer tout cela, la voiture
pourrait calculer
											la probabilité d'heurter
un groupe de personnes,
											si on dévie d'un côté ou d'un autre,
											on augmenterait le risque des passagers
ou des conducteurs
											versus les piétons.
											Il s'agit d'un calcul un peu plus 
complexe,
											mais cela impliquerait quand même
des compromis,
											et les compromis demandent souvent 
de l'éthique.
									","
											Bu probleme bakış açımız önem taşıyor.
											Mesela, hiç üzerine kafa yormayabiliriz.
											Bu senaryonun gerçekçi olmadığını,
son derece olağan dışı olduğunu
											veya aptalca olduğunu düşünebiliriz.
											Fakat bu eleştirinin,
işin özünü kaçırdığını düşünüyorum,
											çünkü senaryoyu
fazla direkt yorumluyorlar.
											Elbette hiçbir kaza bu şekilde olmaz,
											herkesin o veya bu şekilde öldüğü
											iki üç olasılığa indirgenemez.
											Buna karşın araba,
											vuracağı kişi sayısı gibi
kendi içinde hesaplamalara gidecek,
											direksiyonu çevireceği
yönleri kıyaslayarak
											yolcu veya diğer sürücülere 
vereceği hasarı, yayalara oranla
											nispeten arttırabilir.
											Çok daha karmaşık bir hesaplama olacaktır,
											ama yine de risk oranını
hesaba katmış olacaktır
											ve risk oranları,
sıklıkla ahlak kuramı içindedir.
									","
											Es importante saber
cómo pensamos en este problema.
											Podríamos, por ejemplo,
no pensar en esto en absoluto.
											Podríamos decir que la situación 
es poco realista,
											remotamente probable,
o simplemente absurda.
											Pero para mí esta crítica
pierde de vista el problema,
											porque se toma la situación
muy al pie de la letra.
											Por supuesto que ningún accidente
es exactamente así;
											ningún accidente tiene dos o tres opciones
											donde de una forma u otra muere alguien.
											Lo que va a ocurrir,
es que el auto va a calcular algo,
											como la probabilidad de atropellar
a un determinado grupo de personas
											si toma una dirección u otra.
											Se podría aumentar levemente el riesgo
de los pasajeros y conductores,
											en favor de los peatones.
											Va a ser un cálculo más complejo,
											pero aun así va a implicar
hacer concesiones,
											y las concesiones normalmente
requieren una ética.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											We might say then,
""Well, let's not worry about this.
											Let's wait until technology
is fully ready and 100 percent safe.""
											Suppose that we can indeed
eliminate 90 percent of those accidents,
											or even 99 percent in the next 10 years.
											What if eliminating
the last one percent of accidents
											requires 50 more years of research?
											Should we not adopt the technology?
											That's 60 million people
dead in car accidents
											if we maintain the current rate.
											So the point is,
											waiting for full safety is also a choice,
											and it also involves trade-offs.
									","
											Podemos dizer:
""Não nos vamos preocupar com isso.
											""Vamos esperar até que a tecnologia esteja
totalmente desenvolvida e 100% segura.""
											Suponhamos que, de facto, se possam
eliminar 90% desses acidentes,
											ou mesmo 99% nos próximos 10 anos.
											E se eliminar esse 1% dos acidentes
											exigir mais 50 anos de pesquisa?
											Não deveremos adotar a tecnologia?
											Trata-se de 60 milhões de pessoas
mortas em acidentes,
											se mantivermos o ritmo atual.
											Isto significa que
esperar por segurança total
											também é uma escolha
											e também envolve tomar decisões.
									","
											Jetzt könnten wir sagen:
„Lasst uns keine Sorgen machen.
											Lasst uns warten, bis die Technologie
bereit und zu 100 % sicher ist.“
											Nehmen wir an, wir können tatsächlich
90 % dieser Unfälle vermeiden
											oder sogar 99 % in den nächsten 10 Jahren.
											Was wäre, wenn die Eliminierung 
der letzen 1 % der Unfälle
											50 weitere Jahre der Forschung
bedeuten würde?
											Sollten wir die Technologie ablehnen?
											Dann würden 60 Millionen Menschen
bei Autounfällen sterben,
											wenn wir die Rate so beibehalten.
											Der Punkt ist also,
											dass das Warten auf vollkommene Sicherheit
eine Möglichkeit wäre,
											diese aber auch
Abwägungen beinhalten würde.
									","
											On pourrait donc dire :
« Ne nous en préoccupons pas.
											Attendons à ce que la technologie soit 
prête et sûre à 100%. »
											Imaginez qu'on puisse éliminer 90%
de ces accidents,
											ou même 99% dans les dix prochaines 
années.
											Et si l'élimination du dernier 1%
des accidents
											demandait plus de 50 ans de recherches ?
											Ne devrions-nous pas
adopter cette technologie ?
											Ce sont 60 millions de morts à cause 
des accidents de voiture
											si nous maintenons les taux actuels.
											Le fait est que,
											attendre pour une sécurité optimale 
est aussi un choix
											mais cela implique aussi des compromis.
									","
											Şu şekilde düşünebiliriz,
''Peki, o hâlde daha fazla uzatmayalım.
											Teknolojinin tamamen hazır olmasını,
%100 güvenli hâle gelmesini bekleyelim.''
											Gelecek 10 yılda, bu kazaların %90'ını
											ve hatta %99'unu
önleyebildiğimizi farz edelim.
											Peki ya diğer %10'luk
kaza dilimini önleyebilmek,
											50 yıllık bir çalışma daha
gerektiriyor olsaydı?
											Teknolojiyi uyarlamamız gerekmez mi?
											Mevcut oranı korursak,
bu 60 milyon insanın araba kazalarında
											canlarını yitirdiği anlamına geliyor.
											Demek istediğim şu ki,
											tamamen güvenliği sağlamak için
beklemek bir seçenek,
											fakat aynı zamanda,
kendi içinde risk taşıyor.
									","
											Podríamos decir: ""Bueno,
no nos preocupemos por esto.
											Esperemos a que la tecnología esté
totalmente preparada y sea 100 % segura"".
											Supongamos que efectivamente podemos 
eliminar el 90 % de esos accidentes,
											o incluso el 99 % en los próximos 10 años.
											¿Qué pasaría si eliminar el 1 % 
de los accidentes restante
											llevara 50 años más de investigación?
											¿No deberíamos adoptar la tecnología?
											Estaríamos hablando de 60 millones
de muertos en accidentes de auto
											si seguimos al ritmo al que vamos.
											Quiere decir que,
											esperar a tener seguridad total
también es una elección
											y también implica hacer concesiones.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											People online on social media
have been coming up with all sorts of ways
											to not think about this problem.
											One person suggested
the car should just swerve somehow
											in between the passengers —
									","
											Nas redes sociais, as pessoas
têm arranjado inúmeras formas
											para não ter de pensar neste problema.
											Uma pessoa sugeriu que o carro 
devia, de alguma forma,
											passar entre os peões...
									","
											In den sozialen Medien haben die Nutzer
unzählige Möglichkeiten entwickelt,
											um diesem Problem aus dem Weg zu gehen.
											Eine Person schlug vor, das sich das Auto
											zwischen den Fußgängern
durchschlängeln soll,
									","
											Les gens ont trouvé plusieurs manières,
sur les réseaux sociaux,
											pour éviter de penser à ce problème.
											Une personne a suggéré que la voiture 
devrait pouvoir dévier
											entre les piétons—
									","
											Sosyal medyada insanlar,
bu problemi düşünmemek için
											türlü fikirler öne sürüyorlar.
											Bir kişi arabanın bir şekilde,
yaya ile tanık arasından
											geçmesi fikrini
									","
											En línea, en las redes sociales, la gente
ha estado proponiendo todo tipo de ideas
											para no pensar en este problema.
											Una persona sugirió que el auto
debería zigzaguear de alguna forma
											entre los peatones...
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											and the bystander.
											Of course if that's what the car can do,
that's what the car should do.
											We're interested in scenarios
in which this is not possible.
											And my personal favorite
was a suggestion by a blogger
											to have an eject button in the car
that you press —
									","
											e o peão no passeio.
											Claro que, se isso for possível, 
é o que o carro deve fazer.
											Estamos interessados em cenários 
em que isso não é possível.
											O meu cenário favorito foi 
uma sugestão feita por um ""blogger"",
											de o carro ter um botão de ejeção 
que se pressiona...
									","
											und dem Beobachter.
											Natürlich könnte und sollte
das Auto dies machen,
											aber wir beleuchten Szenarien,
in denen das unmöglich ist.
											Mein Lieblingsvorschlag
kam von einem Blogger,
											der vorschlug eine Schleudersitz-Taste
im Auto zu haben, die gedrückt wird,
									","
											et les passants.
											Si la voiture avait les capacités 
de le faire, elle le ferait sûrement.
											Nous sommes intéressés
par d'autres scénarios.
											Mon préféré est une suggestion 
de la part d'un blogueur,
											qui est d'avoir un bouton pour
siège éjectable—
									","
											öne sürdü.
											Elbette araba eğer bunu yapabiliyorsa,
bunu yapması gerekir.
											Böyle bir çözümün mümkün
olmadığı senaryolardan bahsediyoruz.
											Bir blog yazarınca öne sürülen,
şahsen benim en sevdiğim öneride,
											arabada basılabilen fırlatma tuşu ile
									","
											y el transeúnte.
											Por supuesto que, si el auto fuera capaz
de hacer eso, debería hacerlo.
											Pero nos interesan las situaciones
donde esto no es posible.
											Mi favorita fue la idea de un bloguero
											que propuso un botón de ""eyectarse""
que se presiona justo antes...
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											just before the car self-destructs.
									","
											antes de o carro se autodestruir.
									","
											bevor sich das Auto zerstört.
									","
											juste avant l'autodestruction.
									","
											arabanın devamında
kendini imha etmesi çözümüydü.
									","
											de que el auto se autodestruya.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											So if we acknowledge that cars
will have to make trade-offs on the road,
											how do we think about those trade-offs,
											and how do we decide?
											Well, maybe we should run a survey
to find out what society wants,
											because ultimately,
											regulations and the law
are a reflection of societal values.
									","
											Se nós reconhecermos que os carros 
terão que tomar decisões na estrada,
											como devemos ponderar essas decisões
											e como é que decidimos?
											Talvez devêssemos fazer um inquérito 
para saber o que a sociedade quer
											porque, em última análise,
											as normas e as leis são o espelho
dos valores da sociedade.
									","
											Wenn wir also anerkennen, dass Autos
auf der Straße abwägen müssen,
											wie denken wir über diese Abwägungen
											und wie entscheiden wir uns?
											Vielleicht sollten wir eine Umfrage
in der Gesellschaft machen.
											Denn letztendlich
											sind Vorschriften und das Gesetz
ein Spiegel der gesellschaftlichen Werte.
									","
											Si nous considérons que les voitures
devront aussi faire des compromis,
											comment y penser,
											mais surtout comment se décider ?
											Peut être devrions-nous faire un sondage
auprès de la société,
											car finalement,
											les règlements et la loi sont les reflets
des valeurs sociétales.
									","
											Arabaların trafikte risk oranı tahlili
yapacağını kabul edecek olursak,
											bu risk oranı tahlilleri hakkında
nasıl düşüneceğiz
											ve nasıl karar vereceğiz?
											Belki de toplumun ne istediğini
anlamak için bir anket düzenlemeliyiz,
											çünkü nihayetinde,
											düzenlemeler ve yasalar
toplumsal değerlerin bir yansımasıdır.
									","
											Entonces, si aceptamos que los autos
van a tener que hacer concesiones,
											¿cómo pensamos en esas concesiones,
											y cómo decidimos cuáles son?
											Tal vez deberíamos hacer una encuesta
y ver qué quiere la sociedad,
											porque en última instancia,
											las regulaciones y las leyes
son el reflejo de los valores sociales.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											So this is what we did.
											With my collaborators,
											Jean-François Bonnefon and Azim Shariff,
											we ran a survey
											in which we presented people
with these types of scenarios.
											We gave them two options
inspired by two philosophers:
											Jeremy Bentham and Immanuel Kant.
											Bentham says the car
should follow utilitarian ethics:
											it should take the action
that will minimize total harm —
											even if that action will kill a bystander
											and even if that action
will kill the passenger.
											Immanuel Kant says the car
should follow duty-bound principles,
											like ""Thou shalt not kill.""
											So you should not take an action
that explicitly harms a human being,
											and you should let the car take its course
											even if that's going to harm more people.
									","
											Então foi o que fizemos.
											Com os meus colaboradores,
											Jean-François Bonnefon e Azim Shariff,
											realizámos um inquérito
											no qual apresentámos às pessoas 
estes tipos de cenários.
											Demos-lhes duas opções, 
inspiradas por dois filósofos:
											Jeremy Bentham e Immanuel Kant.
											Bentham diz que o carro 
deve seguir a ética utilitarista:
											fazer aquilo que irá 
minimizar os danos totais
											— mesmo que isso implique 
matar um peão no passeio
											e, mesmo que isso 
acabe por matar o passageiro.
											Immanul Kant diz que o carro 
deve seguir princípios morais,
											como ""Não matarás.""
											Então, não se deve agir, caso isso 
implique magoar um ser humano,
											e deverá deixar-se que o carro 
siga o seu percurso
											mesmo que se magoem mais pessoas.
									","
											Genau das haben wir getan.
											Mit meinen Mitarbeitern,
											Jean-François Bonnefon und Azim Shariff,
											haben wir eine Umfrage gemacht,
											in der wir Menschen
diese Art von Szenarien zeigten.
											Wir haben ihnen zwei Optionen gegeben,
von zwei Philosophen inspiriert:
											Jeremy Bentham und Immanuel Kant.
											Bentham sagt, dass das Auto
utilitaristischer Ethik folgen sollte:
											Es soll die Handlung ausführen,
die den Gesamtschaden minimiert,
											sogar, wenn dies einen Beobachter tötet
											und sogar, wenn diese Handlung
den Passagier tötet.
											Immanuel Kant sagt, dass das Auto
pflichtgemäßen Prinzipien folgen sollte,
											wie „Du sollst nicht töten.“
											Man sollte also nicht so handeln,
dass es einen Menschen explizit verletzt,
											sondern das Auto seinen Weg nehmen lassen,
											sogar, wenn dies mehr Menschen verletzt.
									","
											Nous avons donc fait ceci.
											En compagnie de mes collaborateurs,
											Jean-François Bonnefon et Azim Shariff,
											nous avons mené une enquête
											où nous avons présenté ces scénarios
aux gens.
											Nous leur avons donné deux options, 
inspirées par deux philosophes :
											Jeremy Bentham et Emmanuel Kant.
											Selon Bentham, la voiture devrait suivre
l'éthique utilitariste :
											son action devrait être celle qui réduit
tous les dommages —
											même si cette action finira par tuer 
un passant
											ou même si elle finira par tuer 
le passager.
											Selon Kant, la voiture devrait agir selon
certains commandements,
											comme  « Tu ne tueras point. »
											Ton action ne devrait donc pas nuire à
un être humain de manière explicite,
											et tu devrais laisser la voiture faire
sa route
											même si plus de gens finiront blessés.
									","
											Böyle yaptık.
											Ekip arkadaşlarım ile birlikte,
											Jean-François Bonnefon ve Azim Shariff,

											bir anket yaptık
											ve bu ankette insanlara
bu tarz senaryolar sunduk.
											Onlara, iki filozoftan ilham aldığımız
iki seçenek sunduk:
											Jeremy Bentham ve Immanuel Kant.

											Bentham'a göre, araba faydacı
bir etiğe göre hareket etmeli:
											büyük çaptaki hasarı en aza
indirgeyecek şekilde hareket etmeli,
											bu eylem bir tanığı öldürecek olsa da,
											bu eylem bir yolcuyu öldürecek olsa da.
											Immanuel Kant'a göre araba,
vazifesinin icabına göre hareket etmeli,
											''Öldürmeyeceksin'' gibi.
											Bariz bir şekilde, bir insana
zarar verecek şekilde hareket etmemeli
											ve araba kendi hâline bırakılmalı,
											daha fazla insana zarar verecek olsa bile.
									","
											Y fue lo que hicimos.
											Con mis colaboradores,
											Jean-François Bonnefon y Azim Shariff,
											hicimos una encuesta
											en la que le propusimos a la gente
este tipo de situaciones.
											Les dimos dos opciones
inspiradas en dos filósofos:
											Jeremy Bentham e Immanuel Kant.
											Bentham dice que el auto
debería seguir la ética del utilitarismo:
											debería tomar la acción
que minimice el daño total,
											aun si esto implica matar a un transeúnte,
											y aun si esto implica matar al pasajero.
											Immanuel Kant dice que el auto
debería seguir la ética del deber,
											tal como ""No matarás"".
											O sea que no deberías tomar ninguna acción
que implique hacerle daño a un ser humano,
											y deberías dejar que el auto siga su curso
											aun si eso resulta en más heridos.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											What do you think?
											Bentham or Kant?
											Here's what we found.
											Most people sided with Bentham.
											So it seems that people
want cars to be utilitarian,
											minimize total harm,
											and that's what we should all do.
											Problem solved.
											But there is a little catch.
											When we asked people
whether they would purchase such cars,
											they said, ""Absolutely not.""
									","
											O que acham?
											Bentham ou Kant?
											Estes são os resultados.
											A maioria concordou com Bentham.
											Parece que as pessoas preferem 
que os carros sejam utilitários,
											minimizem os danos totais,
e é isso que todos nós devemos fazer.
											Problema resolvido.
											Mas há um pequeno senão.
											Quando perguntámos às pessoas 
se elas comprariam esses carros,
											elas responderam: ""Claro que não.""
									","
											Was denken Sie?
											Bentham oder Kant?
											Hier ist unser Ergebnis.
											Die Meisten sind auf Benthams Seite.
											Die Menschen scheinen also zu wollen,
dass Autos utilitaristisch sind
											und den Gesamtschaden minimieren
											und das sollten wir alle tun.
											Problem gelöst.
											Da gibt es aber einen Haken.
											Als wir die Leute fragten,
ob sie solche Autos kaufen würden
											antworteten sie: „Niemals.“
									","
											Qu'en pensez-vous ?
											Bentham ou bien Kant ?
											Voici notre solution.
											La plupart étaient pour Bentham.
											Les gens veulent donc que la voiture
soit utilitariste,
											réduire les dommages,
											ce que nous devrions tous faire.
											Problème résolu.
											Mais il y a un petit piège.
											Lorsque nous leur avons demandé
s'ils achèteraient ces voitures,
											ils ont répondu : « Absolument pas. »
									","
											Siz ne düşünüyorsunuz?
											Bentham mı, Kant mı?
											Bizim bulgumuzu paylaşayım.
											Çoğu insan Bentham'a hak verdi.
											Öyle ki, insanlar arabaların faydacı
olmalarını istiyorlar gibi görünüyor,
											toplam zararı en aza indirgemesini,
											ki bu hepimizin
yapması gereken şey aslında.
											Sorun çözüldü.
											Dikkat etmemiz gereken bir nokta var.
											İnsanlara bu tarz arabaları satın alma
durumlarını sorduğumuzda,
											''Kesinlikle hayır.'' dediler.
									","
											¿Uds. qué piensan?
											¿Bentham o Kant?
											El resultado fue este:
											la mayoría optó por Bentham.
											Así que parece que la gente quiere 
que los autos sean utilitarios,
											minimizar el daño total,
											y eso es lo que deberíamos hacer.
											Problema solucionado.
											Pero hay una pequeña trampa.
											Cuando le preguntamos a la gente
si comprarían estos autos,
											la respuesta fue un ""No"" rotundo.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											They would like to buy cars
that protect them at all costs,
											but they want everybody else
to buy cars that minimize harm.
									","
											Elas gostariam de comprar carros 
que as protegessem a todo o custo,
											mas querem que os restantes 
comprem carros que minimizem os danos.
									","
											Sie möchten Autos kaufen,
die sie um jeden Preis schützen,
											aber alle anderen sollen Autos kaufen,
die Schaden minimieren.
									","
											Ils aimeraient acheter des voitures qui
les protègent à tout prix,
											mais ils veulent que tous les autres les
achètent pour réduire les dommages.
									","
											Kendilerini her an koruyan
arabalar satın almak isterken,
											diğer herkesin zararı en aza indirgeyen
arabalardan almalarını istiyorlar.
									","
											Les gustaría comprar un auto
que los proteja a ellos a toda costa,
											pero quieren que los demás compren autos
que minimicen el daño.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											We've seen this problem before.
											It's called a social dilemma.
											And to understand the social dilemma,
											we have to go a little bit
back in history.
											In the 1800s,
											English economist William Forster Lloyd
published a pamphlet
											which describes the following scenario.
											You have a group of farmers —
											English farmers —
											who are sharing a common land
for their sheep to graze.
											Now, if each farmer
brings a certain number of sheep —
											let's say three sheep —
											the land will be rejuvenated,
											the farmers are happy,
											the sheep are happy,
											everything is good.
											Now, if one farmer brings one extra sheep,
											that farmer will do slightly better,
and no one else will be harmed.
											But if every farmer made
that individually rational decision,
											the land will be overrun,
and it will be depleted
											to the detriment of all the farmers,
											and of course,
to the detriment of the sheep.
									","
											Já vimos este problema.
											Chama-se dilema social.
											Para perceber o dilema social,
											temos que recuar um pouco na história.
											No início do século XIX,
											o economista inglês William Forster Lloyd 
publicou um folheto
											que descrevia o seguinte cenário:
											Temos um grupo de pastores
— pastores ingleses —
											que partilham um terreno
para as ovelhas pastarem.
											Se cada pastor levar
um certo número de ovelhas
											— por exemplo, três ovelhas —
											o terreno recuperará,
os pastores ficam contentes,
											as ovelhas ficam contentes,
											tudo fica bem.
											Se um pastor levar uma ovelha extra,
											terá uma pequena vantagem, 
mas ninguém será prejudicado.
											Mas, se cada pastor tomar
a mesma decisão,
											a terra será sobreutilizada
e ficará empobrecida
											prejudicando todos os pastores
											e, claro, as ovelhas também.
									","
											Das Problem kannten wir.
											Man nennt es soziales Dilemma.
											Um das soziale Dilemma zu verstehen,
											müssen wir in die Vergangenheit schauen.
											Im 19. Jahrhundert veröffentlichte
											der englische Ökonom
William Forster Lloyd ein Merkblatt,
											das das folgende Szenario beschreibt.
											Eine Gruppe von Bauern –
											englische Bauern –
											teilen sich ein Stück Land,
auf dem ihre Schafe grasen.
											Wenn jeder Bauer
eine bestimmte Anzahl Schafe hat,
											sagen wir 3 Schafe,
											wird das Land verjüngt.
											Die Bauern sind glücklich
											und die Schafe sind glücklich.
											Alles ist gut.
											Wenn jetzt aber ein Bauer
ein Schaf mehr hat,
											geht es ihm etwas besser
und niemand kommt zu Schaden.
											Trifft aber jeder Bauer diese
individuelle rationale Entscheidung,
											ist das Stück Land überlaufen
und wird erschöpft,
											zum Nachteil aller Bauern
											und natürlich zum Nachteil der Schafe.
									","
											Nous connaissons ce type de problème.
											C'est un dilemme social.
											Pour comprendre ce dilemme social,
											nous devons remonter un peu dans le temps.
											Dans les années 1800,
											l'économiste anglais William Forster Lloyd
a publié un pamphlet
											décrivant le scénario suivant.
											Vous avez un groupe de fermiers—
											fermiers anglais—
											qui se partagent des terres
pour leurs moutons.
											Si chaque fermier ramène un certain nombre
de moutons—
											disons trois moutons—
											la terre sera régénérée,
											les fermiers heureux,
											les moutons heureux,
											tout est en ordre.
											Maintenant si un fermier en ramène un
de plus,
											il s'en sortira un peu mieux,
au détriment de personne.
											Mais si chaque fermier faisait de même,
											la terre serait surexploitée et appauvrie
											au détriment de tous les fermiers
											et bien sûr à celui des moutons.
									","
											Bu problemle daha önce karşılaşmıştık.
											Buna ''toplumsal ikilem'' deniyor.
											Toplumsal ikilemi anlayabilmek için,
											biraz eskilere gitmemiz gerekir.
											1800'lerde,
											İngiliz iktisatçı William Forster Lloyd,
											şu senaryoyu aktaran bir broşür yayınladı:
											Bir grup çiftçi var,
											İngiliz çiftçiler,
											koyunlarını otlatmak için
umumi bir araziyi paylaşıyorlar.
											Her bir çiftçi,
belirli sayıda koyun getirirse
											- 3 koyun diyelim -
											toprak yenilenmiş olacak,
											çiftçiler mutlu,
											koyunlar mutlu,
											her şey iyi olacak.
											Fakat bir çiftçi,
fazladan bir koyun daha getirirse,
											o çiftçinin işleri için daha iyi olacak
ve bu kimseye zarar vermeyecek.
											Ama her bir çiftçi, bireysel olarak
bu mantıklı kararı verecek olursa,
											alan istilaya uğramış olacak
ve yeşillik tükenecek,
											bu da her çiftçinin zararına olacak
											ve tabii ki koyunların da zararına olacak.
									","
											Ya conocemos este tipo de problema.
											Es un dilema social.
											Y para entender el dilema social,
											hay que retroceder
un poco en la historia.
											En el 1800,
											el economista inglés William Forster Lloyd
publicó un folleto
											que describe la siguiente situación.
											Hay un grupo de pastores,
											pastores ingleses,
											que comparten un prado común
donde pastan sus ovejas.
											Si cada pastor 
trae una cierta cantidad de ovejas,
											digamos tres ovejas,
											el suelo se recupera bien,
											los pastores contentos,
											las ovejas contentas,
											todo va bien.
											Ahora, si uno de los pastores
trae una oveja extra,
											ese pastor va a estar un poquito mejor,
y nadie más va a salir perjudicado.
											Pero si cada pastor tomara esa decisión
individualmente racional,
											el prado se vería sobreexplotado
y el pasto se agotaría,
											en detrimento de todos los pastores,
											y por supuesto,
en detrimento de las ovejas.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											We see this problem in many places:
											in the difficulty of managing overfishing,
											or in reducing carbon emissions
to mitigate climate change.
											When it comes to the regulation
of driverless cars,
											the common land now
is basically public safety —
											that's the common good —
											and the farmers are the passengers
											or the car owners who are choosing
to ride in those cars.
											And by making the individually
rational choice
											of prioritizing their own safety,
											they may collectively be
diminishing the common good,
											which is minimizing total harm.
											It's called the tragedy of the commons,
											traditionally,
											but I think in the case
of driverless cars,
											the problem may be
a little bit more insidious
											because there is not necessarily
an individual human being
											making those decisions.
											So car manufacturers
may simply program cars
											that will maximize safety
for their clients,
											and those cars may learn
automatically on their own
											that doing so requires slightly
increasing risk for pedestrians.
											So to use the sheep metaphor,
											it's like we now have electric sheep
that have a mind of their own.
									","
											Vemos este problema em muitos sítios:
											na dificuldade de controlar 
a pesca excessiva,
											ou em reduzir as emissões de carbono 
para atenuar as mudanças climáticas.
											Quando se trata da regulamentação 
de carros autónomos,
											os terrenos baldios são,
basicamente, a segurança pública
											— ou seja, o bem comum.
											Os pastores são os passageiros
											ou os donos de carros que escolham 
conduzir esse tipo de veículo.
											E ao fazer essa escolha
individual e racional
											de dar prioridade à sua segurança,
											eles podem estar, em conjunto,
a prejudicar o bem comum,
											que é o que está
a minimizar os danos totais.
											É a chamada ""tragédia dos comuns"",
tradicionalmente.
											Mas eu penso que, no caso 
de carros autónomos,
											o problema pode ser 
um pouco mais insidioso
											pois não é necessariamente um ser humano
											a tomar essas decisões.
											Os fabricantes de automóveis
podem programar carros
											que irão maximizar
a segurança dos seus clientes,
											e esses carros poderão aprender sozinhos
											que, ao fazer isso, aumentará
o risco para os peões.
											Na metáfora das ovelhas,
											é como se tivéssemos ovelhas eletrónicas 
que pensam por si mesmas.
									","
											Wir sehen dieses Problem überall:
											beim Versuch Überfischung zu vermeiden
											oder beim Versuch Emission zu reduzieren,
um den Klimawandel einzudämmen.
											Wenn es um Vorschriften
für fahrerlose Autos geht,
											steht das gemeinsame Land
für die öffentliche Sicherheit –
											das Gemeinwohl –
											und die Bauern sind die Passagiere
											oder die Autobesitzer,
die in diesen Autos fahren.
											Beim Treffen der individuellen
rationalen Entscheidung,
											die eigene Sicherheit zu bevorzugen,
											könnten sie das Gemeinwohl
zusammen vermindern,
											was den Gesamtschaden verringert.
											Man nennt dies die Tragik der Allmende,
											herkömmlicherweise,
											aber im Fall fahrerloser Autos,
											könnte das Problem
etwas komplizierter sein,
											weil nicht unbedingt ein Mensch
											diese Entscheidungen trifft.
											Autohersteller könnten also einfach
Autos so programmieren,
											dass sie maximale Sicherheit
für ihre Kunden gewähren
											und diese Autos könnten
automatisch, alleine lernen,
											dass diese Sicherheit mit einem
erhöhten Risiko für Fußgänger einhergeht.
											In der Schaf-Metapher
											würde das elektronische Schafe
mit eigener Meinung bedeuten.
									","
											Nous rencontrons ce problème
à plusieurs endroits :
											dans la difficulté à gérer la surpêche,
											ou à réduire les émissions de carbone pour
atténuer le changement climatique.
											Quand il s'agit du règlement des voitures
sans conducteur,
											la terre commune représente
la sécurité publique —
											c'est le bien commun —
											et les fermiers sont les passagers
											ou les propriétaires de ces voitures qui 
décident de les conduire.
											En faisant ce choix rationnel
											de prioriser leur propre sécurité,
											ils sont peut être en train d'affaiblir
le bien commun,
											de réduire donc les dommages.
											C'est la Tragédie des biens communs,
											typiquement,
											mais je pense que dans le cas des voitures
sans conducteur,
											le problème est peut-être
un peu plus insidieux
											car ce n'est pas forcément
un seul être humain
											qui prend ces décisions.
											Les fabricants de voitures pourraient 
simplement les programmer
											pour maximiser la sécurité des clients,
											et elles pourraient apprendre
par elles-mêmes
											qu'en agissant de cette manière, elles
augmenteraient le risque des piétons.
											Revenons à notre métaphore,
											c'est comme si maintenant nous avions
des moutons électriques conscients.
									","
											Bu sorun ile birçok kez karşılaşıyoruz:
											aşırı balık avlanması hususunda,
											ya da iklim değişikliğini azaltmak adına
karbon salınımını azaltmada.
											Sürücüsüz araba hukukuna baktığımızda,
											umumi alan toplum güvenliği oluyor
											- yani kamu yararı -
											ve çiftçiler yolcular oluyor
											veya o arabaları kullanmayı
tercih eden araç sahipleri oluyor.
											Ve kendi güvenliklerine öncelik tanıyan,
											bireysel mantıklı seçimlerini yaparak
											hep birlikte genelin iyiliğini azaltarak
											toplam zarar riskini aza indirgemeyi
düşürüyor olabilirler.
											Buna bilindiği üzere
ortak malların trajedisi
											deniyor,
											fakat bana kalırsa,
sürücüsüz araba hususunda
											sorun biraz daha derin olabilir,
											çünkü temelde bu kararları veren
											bir insan söz konusu değil.
											Araba imalatçıları, müşterileri için
üst düzey güvenlik önlemleri alan
											araba programlayabilirler
											ve bu arabalar, otomatik olarak
bu seçimleri yapmanın
											yayalar için riskleri bir nebze de olsa
arttırdığını öğrenebilir.
											Koyun benzetmesine dönecek olursak,
											şu anda kendi fikirlerini verebilen
elektrikli koyunlara sahibiz diyebiliriz.
									","
											Es un problema que se ve mucho:
											en la dificultad de
controlar la sobrepesca,
											o al reducir las emisiones de carbono
para contrarrestar el cambio climático.
											Volviendo al tema de la regulación
de vehículos autónomos,
											el prado común vendría a ser
básicamente la seguridad pública;
											ese es el bien común.
											Y los pastores serían los pasajeros
											o los dueños de los autos que 
eligen viajar en esos vehículos.
											Y al tomar la decisión
individualmente racional
											de priorizar su propia seguridad,
											podrían estar disminuyendo
colectivamente el bien común,
											que es minimizar el daño total.
											Esto se llama ""tragedia de los comunes"",
											tradicionalmente,
											pero creo que en el caso
de los vehículos autónomos,
											el problema es tal vez
un poquito más traicionero
											porque no es necesariamente
un ser humano
											el que toma las decisiones.
											Entonces, los fabricantes podrían
simplemente programar los autos
											para maximizar la seguridad
de sus clientes.
											Y esos autos podrían aprender,
automáticamente y por su cuenta,
											que hacer eso requiere aumentar
levemente el riesgo de los peatones.
											O sea que, volviendo a las ovejas:
											es como si ahora tuviéramos
ovejas eléctricas que piensan solas.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											And they may go and graze
even if the farmer doesn't know it.
									","
											Elas podem ir pastar
sem que o pastor saiba disso.
									","
											Und diese könnten grasen,
ohne, dass der Bauer davon weiß.
									","
											Ils peuvent brouter sans que le fermier
le sache.
									","
											Ve kendi başlarına kaçıp
çiftçinin haberi olmadan otlanabilirler.
									","
											Y pueden irse a pastar solas
aunque el pastor no lo sepa.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											So this is what we may call
the tragedy of the algorithmic commons,
											and if offers new types of challenges.
											Typically, traditionally,
											we solve these types
of social dilemmas using regulation,
											so either governments
or communities get together,
											and they decide collectively
what kind of outcome they want
											and what sort of constraints
on individual behavior
											they need to implement.
											And then using monitoring and enforcement,
											they can make sure
that the public good is preserved.
											So why don't we just,
											as regulators,
											require that all cars minimize harm?
											After all, this is
what people say they want.
											And more importantly,
											I can be sure that as an individual,
											if I buy a car that may
sacrifice me in a very rare case,
											I'm not the only sucker doing that
											while everybody else
enjoys unconditional protection.
									","
											É a isso que chamamos
a tragédia dos algoritmos comuns,
											e isso apresenta novos tipos de problemas.
											Tipicamente,
											nós resolvemos este tipo de 
dilemas sociais com regulamentações
											em que os governos
e as comunidades se juntam,
											e decidem coletivamente
que tipo de resultado querem
											e que tipo de restrições é necessário
aplicar no comportamento individual.
											E depois, com o acompanhamento 
e a sua imposição,
											podem certificar-se de que 
o bem público é preservado.
											Então porque é que nós,
enquanto entidades reguladoras,
											não exigimos que todos os carros 
minimizem os danos?
											Afinal, as pessoas dizem 
que é isso que querem.
											E mais importante ainda,
											enquanto indivíduo, tenho a certeza
de que, se comprasse um carro,
											numa situação improvável, 
decidisse sacrificar-me,
											eu não seria o único a fazer isso
											enquanto as demais pessoas
teriam uma proteção ilimitada.
									","
											Der Name dafür könnte also
Tragik der algorithmischen Allmende sein
											und diese stellt uns vor
ganz neue Probleme.
											Normalerweise
											haben wir diese Art von sozialen Dilemmas
mit Vorschriften gelöst.
											Entweder Regierungen
oder Gemeinden kommen zusammen
											und entscheiden gemeinsam,
welches Ergebnis sie möchten
											und welche Einschränkungen 
des individuellen Verhaltens
											sie einführen müssen.
											Dann wird mittels Überwachung
und Vollstreckung sichergestellt,
											dass das Gemeinwohl gewahrt bleibt.
											Warum sagen wir dann nicht,
											als Regulatoren,
											dass alle Autos Schaden minimieren müssen?
											Im Grunde, ist es das,
was Menschen wollen.
											Und was noch wichtiger ist,
											ich, als Individuum, kann sicher sein,
											dass, wenn ich ein Auto kaufe,
dass mich im seltenen Fall opfern würde,
											ich nicht der einzige Dumme bin,

											während alle anderen
bedingungslose Sicherheit genießen.
									","
											C'est ce qu'on pourrait appeler la 
Tragédie des communs algorithmiques,
											qui offre de nouveaux types de défis.
											De manière générale, typiquement,
											nous résolvons ces types de dilemmes 
sociaux grâce aux lois :
											soit les gouvernements soit
les communautés se réunissent
											pour décider ensemble quel est
le résultat voulu
											et quelles sortes de contraintes liées
au comportement
											doivent être appliquées.
											Ensuite grâce à la surveillance
et au contrôle,
											ils peuvent s'assurer que le bien civil
soit préservé.
											Pourquoi ne pourrions-nous pas,
											en tant que régulateurs,
											exiger à ce que toutes les voitures
réduisent les dommages ?
											Après tout, c'est ce que veulent les gens.
											Plus important encore,
											je peux être sûr qu'en tant qu'individu,
											si j'achète une voiture pouvant
me sacrifier dans un cas très rare,
											je ne vais pas être le seul pigeon
											à le faire alors que tous les autres
sont protégés.
									","
											Bunu da şu şekilde ifade edebiliriz:
algoritmik ortak malların trajedisi.
											Beraberinde yeni zorluklar getiriyor.
											Genellikle, çoğunlukla,
											bu tür toplumsal ikilemleri
yasalar nezdinde çözüme kavuştururuz;
											ya hükümet ya da topluluklar
bir araya gelir
											ve hep birlikle ne tür bir sonuç
elde etmek istediklerine karar verirler
											ve bireysel davranışlarda,
ne tür kısıtlamalara gidilmesi gerektiğini
											kararlaştırırlar.
											Gözlem ve yürürlülüğü kullanarak
											kamu yararının korunduğuna emin olurlar.
											Düzenleyiciler olarak,
											neden bütün arabalara
											zararı en aza indirgeme statüsü
kazandırmıyoruz?
											Nihayetinde,
herkes bunu istediğini dile getiriyor.
											Daha da önemlisi,
											bir birey olarak eminim ki
											çok nadir bir durumda beni
gözden çıkarabilecek bir araba alırsam,
											diğer herkes
											koşulsuz korumanın keyfini çıkarırken
bunu yapan tek keriz ben olmam.
									","
											O sea que a esto podríamos llamarlo
""la tragedia de los comunes algorítmicos"",
											y nos presenta nuevos desafíos.
											Típicamente, tradicionalmente,
											este tipo de dilemas sociales
se resuelven implementando regulación.
											Ya sea el gobierno
o la comunidad, se juntan
											y deciden colectivamente
qué resultado quieren obtener,
											y qué tipo de restricciones
a la conducta individual
											necesitan implementar.
											Y luego, a través del control
y la imposición de normas,
											pueden garantizar
la preservación del bien común.
											Entonces ¿por qué no exigimos,
											en nuestro rol de reguladores,
											que todos los autos
tienen que minimizar el daño?
											A fin de cuentas, eso es
lo que la gente dice que quiere.
											Y más importante aún,
											puedo estar seguro de que, como individuo,
											si compro un auto que en un caso
muy extremo podría llegar a sacrificarme,
											no soy el único papanatas haciéndolo
											mientras todos los demás
gozan de protección ilimitada.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											In our survey, we did ask people
whether they would support regulation
											and here's what we found.
											First of all, people
said no to regulation;
											and second, they said,
											""Well if you regulate cars to do this
and to minimize total harm,
											I will not buy those cars.""
											So ironically,
											by regulating cars to minimize harm,
											we may actually end up with more harm
											because people may not
opt into the safer technology
											even if it's much safer
than human drivers.
									","
											No inquérito, perguntámos às pessoas 
se apoiariam a regulamentação
											e obtivemos este resultado:
											Para começar, as pessoas disseram 
que não apoiariam a regulamentação.
											E em segundo, disseram:
											""Se regulamentarem os carros para 
fazer isso e minimizar os danos totais,
											""não irei comprar esses carros.""
											Então, ironicamente,
											ao regulamentar os carros 
para minimizarem os danos,
											pode-se estar a causar mais danos
											pois as pessoas podem não optar 
pela tecnologia mais segura
											mesmo sendo mais segura
do que os condutores humanos.
									","
											In unser Umfrage haben wir gefragt,
ob Vorschriften befürwortet werden
											und hier ist die Antwort.
											Zuerst haben sich die Teilnehmer
gegen Vorschriften ausgesprochen.
											Dann haben sie gesagt:
											„Wenn Autos so reguliert werden
und den Schaden minimieren sollen,
											kaufe ich das Auto nicht. “
											Ironischerweise
											indem wir Autos regulieren,
so dass sie Schaden minimieren
											könnten wir noch mehr Schaden nehmen,
											weil die Menschen sich nicht
für sichere Technologie entscheiden,
											obwohl sie viel sicherer
als der Mensch ist.
									","
											Dans notre enquête, nous avons demandé
s'ils valideraient un telle loi
											et voici le résultat.
											Tout d'abord, les gens ont répondu
non à la loi ;
											ensuite, ils ont dit :
											« Si vous légiférer pour que les voitures
réduisent les dommages,
											je ne les achèterais pas. »
											Donc ironiquement,
											en réglant les voitures pour réduire
les dommages,
											ça pourrait être pire
											car les gens n'opteraient pas pour
la technologie plus sécurisée
											même si c'est plus sûr qu'un conducteur.
									","
											Ankette insanlara, yasal düzenlemeye
destek verip vermeyeceklerini sorduk
											ve sonuç şu şekildeydi.
											İlk önce, insanlar yasaya hayır dediler
											ve sonra dediler ki,
											''Arabaları bunun için ve toplam zararı
en aza indirgemek için düzenlersek,
											bu arabaları satın almam.''
											İşe bakın ki,
											zararı en aza indirgemek için
arabaları düzenleyerek
											daha fazla zarara sebebiyet verebiliriz,
											çünkü insanlar daha güvenli olan bu
teknolojiye dahil olmak istemeyebilirler,
											insan sürücülerden daha güvenli olsa bile.
									","
											En nuestra encuesta indagamos
acerca de la idea de la regulación,
											y el resultado fue este:
											Primero, la gente dijo 
""no"" a la regulación;
											y segundo:
											""Bueno, si van a regular los autos
para actuar así y minimizar el daño total,
											yo no los voy a comprar"".
											Entonces, irónicamente,
											al regular los autos
para minimizar el daño,
											podríamos acabar con más daño
											porque la gente no adoptaría
esta nueva tecnología
											aun cuando es mucho más segura
que los conductores humanos.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											I don't have the final
answer to this riddle,
											but I think as a starting point,
											we need society to come together
											to decide what trade-offs
we are comfortable with
											and to come up with ways
in which we can enforce those trade-offs.
									","
											Eu não possuo a resposta final
para este enigma,
											mas acho que, para começar,
											é necessário que a sociedade
											concorde nas decisões mais adequadas
											e encontre formas de como 
se podem impor essas decisões.
									","
											Ich habe keine ultimative Antwort
für dieses Rätsel,
											aber ich denke,
											zuallererst sollte die Gesellschaft
zusammen kommen
											und die Kompromisse beschließen,
die wir verkraften können
											und Ideen entwickeln,
wie wir diese durchsetzen können.
									","
											Je n'ai pas la réponse finale de
cette énigme,
											mais pour commencer,
											notre société devrait s'unir
											pour décider quels compromis
nous correspondent le plus
											et trouver des moyens pour les appliquer.
									","
											Bu bilmeceye nihai bir cevabım yok,
											ama başlangıç noktası olarak,
											toplumun bir araya gelip
											risk oranı dengesinde ortak bir noktada
karara varması gerekir
											ve bu denge unsurunun uygulamasında
izleyeceğimiz yol belirlenebilir.
									","
											No tengo la respuesta final
a este acertijo,
											pero creo que, para empezar,
											necesitamos que la sociedad
se ponga de acuerdo
											sobre las concesiones
que está dispuesta a aceptar,
											y las posibles maneras
de imponer esas concesiones.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											As a starting point,
my brilliant students,
											Edmond Awad and Sohan Dsouza,
											built the Moral Machine website,
											which generates random scenarios at you —
											basically a bunch
of random dilemmas in a sequence
											where you have to choose what
the car should do in a given scenario.
											And we vary the ages and even
the species of the different victims.
											So far we've collected
over five million decisions
											by over one million people worldwide
											from the website.
											And this is helping us
form an early picture
											of what trade-offs
people are comfortable with
											and what matters to them —
											even across cultures.
											But more importantly,
											doing this exercise
is helping people recognize
											the difficulty of making those choices
											and that the regulators
are tasked with impossible choices.
											And maybe this will help us as a society
understand the kinds of trade-offs
											that will be implemented
ultimately in regulation.
									","
											Como ponto de partida, 
os meus brilhantes alunos,
											Edmond Awad e Sohan Dsouza,
											criaram o site ""Moral Machine"",
											que gera cenários aleatórios
											— basicamente, um monte
de dilemas aleatórios
											em que vocês têm que escolher
											o que um carro deve fazer
num determinado cenário.
											E vamos mudando as idades
e as espécies das diversas vítimas.
											Até agora, recolhemos 
mais de cinco milhões de respostas
											de mais de 1 milhão de pessoas,
a nível mundial,
											através desse site.
											Isto está a ajudar-nos
a formar um quadro inicial
											do tipo de decisões que 
as pessoas acham adequadas
											e o que é importante para elas,
											mesmo noutras culturas.
											Mas mais importante,
											fazer este exercício ajuda as pessoas
											a reconhecer a dificuldade
de fazer aquelas escolhas
											e que a entidade reguladora está
incumbida de fazer escolhas impossíveis.
											Enquanto sociedade, talvez isto nos 
ajude a perceber que tipos de decisões
											deverão ser implementadas 
na regulamentação.
									","
											Als Grundlage haben
meine brillanten Studenten,
											Edmong Awad und Sohan Dsouza,
											die Moral Machine Website gebaut,
											die eine Reihe von Szenarien vorgibt,
											eine Reihe von zufälligen
Dilemmas in Folge,
											bei denen Sie bestimmen müssen,
wie das Auto reagiert.
											Wir verändern das Alter und sogar
die Spezies der verschiedenen Opfer.
											Bisher haben wir 
über fünf Millionen Entscheidungen
											von über einer Million Menschen weltweit
											mit der Webseite erhoben.
											Und das hilft uns dabei,
von Anfang an zu verstehen,
											mit welchen Kompromissen
die Menschen leben können
											und was ihnen wichtig ist –
											sogar kulturübergreifend.
											Das Wichtigste ist jedoch,
											dass diese Übung dabei hilft,
zu verstehen,
											wie schwierig es ist,
diese Entscheidungen zu treffen,
											und dass Regulatoren vor
unmöglichen Entscheidungen stehen.
											Und vielleicht hilft es
der Gesellschaft zu verstehen,
											welche Abwägungen letztendlich
in Vorschriften enthalten sind.
									","
											Pour commencer, mes brillants étudiants,
											Edmond Awad et Sohan De Souza
											ont créé le site Moral Machine;
											celui-ci génère des scénarios aléatoires—
											une série de dilemmes à la chaîne
											où vous devez choisir ce que ferait 
la voiture dans ces cas.
											Nous varions les âges et la nature 
des différentes victimes.
											Jusqu'à présent, nous avons récolté
plus de 5 millions de décisions
											prises par plus d'un million de gens
											depuis le site internet.
											Ceci nous aide à avoir une idée
											de quels compromis les gens sont prêts
à accepter
											et ce qui compte pour eux—
											même à travers les cultures.
											Mais surtout,
											ces exercices aident les gens
à reconnaître
											la difficulté que représente le fait
de faire un choix
											et que les lesgilateurs sont confrontés
à des choix impossibles.
											Peut-être que ceci nous aidera
à comprendre, en tant que société,
											quels compromis seront mis en place
dans la loi.
									","
											Başlangıç noktası olarak,
benim parlak öğrencilerim
											Edmond Awad ve Sohan Dsouza,
											Ahlak Makinesi internet sitesini kurdu.
											Bu site size rastgele senaryolar sunuyor,
											bir dizi ikilemler yöneltiyor
											ve verilen bu senaryoda, arabanın ne
yapması gerektiğine karar veriyorsun.
											Yaşları ve hatta farklı kurbanların
türlerini bile çeşitlendirdik.
											Şu ana kadar, site üzerinden
dünya genelinde
											bir milyonu aşkın insan tarafından
beş milyonun üzerinde
											karar topladık.
											Bu bulgular, kültürler arası bile
											insanların neleri feda edebileceklerini
											ve onlar için
önem arz eden şeyleri anlayıp
											bir temel oluşturmamızda yardımcı oluyor.
											Ama daha önemlisi,
											bu araştırma insanlara,
bu seçimleri yapmanın
											ne kadar zor olduğunu
											ve yasal düzenlemelerin, imkânsız
seçimler ile çevrelendiğini hatırlatıyor.
											Bu belki de toplum olarak,
nihayetinde yasalara işlenecek türde
											risk oranı tahlilini
anlamamıza yardımcı olabilir.
									","
											Como punto de partida,
mis brillantes alumnos,
											Edmond Awad y Sohan Dsouza,
											construyeron el sitio web Moral Machine,
											que genera y presenta
situaciones hipotéticas al azar;
											es básicamente una secuencia
aleatoria de dilemas
											donde tienes que elegir
qué debería hacer el auto en cada caso.
											Y variamos las edades y hasta las especies
de las distintas víctimas.
											Hasta ahora hemos recolectado
más de 5 millones de decisiones,
											de más de un millón de personas
en todo el mundo
											a través del sitio web.
											Esto nos está ayudando
a pintar un panorama inicial
											de las concesiones
que la gente está dispuesta a hacer
											y de qué es lo que les importa,
											incluso en distintas culturas.
											Pero, lo que es más importante,
											este ejercicio está ayudando
a la gente a comprender
											lo difícil que es tomar esas decisiones,
											y que los organismos reguladores
se enfrentan con decisiones imposibles.
											Y tal vez esto nos ayude, como sociedad,
a entender el tipo de concesiones
											que se van a implementar,
en última instancia, como normativa.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											And indeed, I was very happy to hear
											that the first set of regulations
											that came from
the Department of Transport —
											announced last week —
											included a 15-point checklist
for all carmakers to provide,
											and number 14 was ethical consideration —
											how are you going to deal with that.
											We also have people
reflect on their own decisions
											by giving them summaries
of what they chose.
											I'll give you one example —
											I'm just going to warn you
that this is not your typical example,
											your typical user.
											This is the most sacrificed and the most
saved character for this person.
									","
											Fiquei bastante feliz ao ouvir
											que o primeiro conjunto de regulamentações
											anunciado pelo Departamento de Transporte,
na semana passada,
											inclui uma lista de 15 pontos
											que todos os fabricantes
de automóveis devem fornecer.
											O número 14 foi uma reflexão ética
											sobre como a pessoa vai lidar com isso.
											Nós fazemos as pessoas 
refletir nas suas decisões
											ao dar-lhes uma síntese do que escolheram.
											Vou dar-vos um exemplo
											e desde já vos aviso que este não é 
o exemplo de um utilizador habitual.
											Estas são a personagem mais sacrificada 
e a mais salvo para esta pessoa.
									","
											Und ich war glücklich zu hören,
											dass die erste Reihe von Vorschriften
											vom Verkehrsministerium,
											wie letzte Woche angekündigt,
											eine 15-Punkte-Checkliste
für alle Autohersteller enthielten
											und Nummer 14 waren moralische Bedenken
											und wie man mit diesen umgeht.
											Wir haben Menschen
ihre Angaben reflektieren lassen,
											indem wir ihnen eine Zusammenfassung
ihrer Entscheidung gaben.
											Hier ist ein Beispiel.
											Ich muss Sie nur vorher warnen,
dies ist kein typisches Beispiel,
											kein typischer Nutzer.
											Dies ist der am meisten geopferte und
der am meisten geschützte Charakter.
									","
											En effet, j'ai été très heureux
											d'entendre que la première série
											venue du Département des Transports—
											annoncée la semaine dernière
											a inclus une liste de 15 points à remplir
par tous les fabricants de voitures.
											Le numéro 14 était la consideration 
éthique —
											comment allez-vous gérer ça ?
											Ces personnes peuvent aussi réfléchir
à leurs décisions
											en recevant des résumés à propos
de leurs choix.
											Je vais vous donner un exemple —
											je vous avertis juste que ceci n'est pas
un exemple typique,
											ni un utilisateur typique.
											Voici ce que la personne a sauvé
et a tué le plus.
									","
											Geçtiğimiz hafta,
											Ulaştırma Bakanlığı tarafından yapılan
											ilk yasal düzenlemelerden
											haberdar olduğuma çok sevindim.
											Tüm araba üreticilerinin sağlaması gereken
15 maddelik bir kontrol listesine sahip
											ve 14. madde işin
ahlaki boyutu ile alakalıydı,
											bu sorumluluğu
nasıl taşıyabileceğimizle alakalıydı.
											İnsanlara, seçimlerinin sonuçlarını
özet şeklinde sunarak
											kendi kararlarının getirilerini gösterdik.
											Sizlere bir örnek vereceğim.
											Belirtmeliyim ki bu genel bir örnek,
											genel bir kullanıcı değil.
											Bu kişi için en çok kurtarılan (kedi)
ve feda edilen (bebek) görüldüğü gibi.
									","
											Me alegré mucho cuando me enteré
											de que el primer conjunto de regulaciones
											que publicó el Departamento de Transporte
											la semana pasada
											incluye una lista de 15 ítems
que deben presentar los fabricantes,
											y el número 14
es ""consideraciones éticas"";
											cómo van a manejar ese tema.
											En el sitio, la gente también
puede reflexionar sobre sus decisiones
											al recibir un resumen
de las opciones que eligieron.
											Les voy a dar un ejemplo.
											Les advierto que no es un ejemplo típico;
											no es un usuario típico.
											Estos son los individuos que esta persona
más salvó y más sacrificó.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											Some of you may agree with him,
											or her, we don't know.
											But this person also seems to slightly
prefer passengers over pedestrians
											in their choices
											and is very happy to punish jaywalking.
									","
											Alguns de vocês podem concordar com ele,
ou com ela — não sabemos.
											Mas esta pessoa preferiu salvar
os passageiros ao invés dos peões
											nas suas escolhas,
											e parece muito feliz por punir
peões que não cumprem a lei.
									","
											Manche mögen seine Meinung teilen
											oder ihre Meinung, wer weiß.
											Diese Person neigt jedoch mehr dazu,
Passagiere über Fußgänger zu stellen
											und bei den Entscheidungen
											verkehrswidriges Verhalten zu bestrafen.
									","
											Certains d'entre vous allez être
											d'accord avec lui ou avec elle.
											Cette personne a aussi l'air de préférer
les passagers aux piétons
											dans ses choix
											et est très heureuse de punir
ceux qui traversent en dehors des clous.
									","
											Bazılarınız bu kişiye katılıyor olabilir,
											bilmiyoruz.
											Bu kişi aynı zamanda seçimlerinde,
yayalara karşın yolcuları daha çok tutuyor
											gibi gözüküyor
											ve kırmızı ışıkta geçenleri
cezalandırmaktan memnuniyet duyuyor.
									","
											Algunos de Uds. estarán de acuerdo con él,
											o ella, no sabemos.
											Esta persona también parece inclinarse
más a favor del pasajero que del peatón,
											según las opciones que escogió,
											y no tiene problema
en castigar al peatón imprudente.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Laughter)
									","
											(Risos)
									","
											(Lachen)
									","
											(Rires)
									","
											(Gülüşmeler)
									","
											(Risas)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											So let's wrap up.
											We started with the question —
let's call it the ethical dilemma —
											of what the car should do
in a specific scenario:
											swerve or stay?
											But then we realized
that the problem was a different one.
											It was the problem of how to get
society to agree on and enforce
											the trade-offs they're comfortable with.
											It's a social dilemma.
									","
											Vamos então, concluir.
											Começámos com a questão
— chamemos-lhe dilema ético —
											sobre o que o carro deverá
fazer num cenário específico:
											desviar-se ou continuar?
											Mas depois apercebemo-nos 
que o problema era outro.
											O problema era sobre como levar 
a sociedade a concordar e a impor
											as decisões que consideram adequadas.
											É um dilema social.
									","
											Fassen wir also zusammen.
											Wir starteten mit der Frage –
wir nennen sie moralisches Dilemma –
											wie sich das Auto in einem
spezifischen Szenario verhalten soll:
											ausweichen oder bleiben?
											Aber dann merkten wir,
dass das Problem ein anderes war.
											Die Frage war, wie man die Gesellschaft
dazu bringt, Kompromisse durchzusetzen,
											mit denen sie sich wohl fühlen.
											Ein soziales Dilemma.
									","
											Résumons.
											Nous avons commencé avec une question —
un dilemme éthique —
											de ce que devrait faire la voiture dans
un scénario précis :
											dévier ou rester ?
											Mais nous avons réalisé que
le problème était autre.
											Le problème était de comment faire pour
que la société accepte et applique
											les compromis qui lui conviennent.
											C'est un dilemme social.
									","
											Konuyu toparlayalım.
											Arabanın belirli bir senaryoda ne
yapması gerektiğini irdeleyen bir soruyla,
											daha doğrusu ahlaki bir ikilemle başladık:
											dönecek mi, kalacak mı?
											Fakat sonra, sorunun farklı
bir şey olduğunu fark ettik.
											Toplum olarak, risk durumunda insanların
nelerden fedakarlık yapabileceklerine
											uzlaşma ve uygulama sorunu.
											Toplumsal bir ikilemden bahsediyoruz.
									","
											Entonces, redondeando.
											Empezamos con la pregunta,
llamémosle dilema ético,
											de qué debería hacer el auto
en una situación específica:
											¿cambiar de dirección o seguir?
											Pero luego nos dimos cuenta
de que el problema es otro.
											El problema es que la sociedad
se ponga de acuerdo
											sobre qué concesiones le son aceptables
y cómo imponerlas.
											Es un dilema social.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											In the 1940s, Isaac Asimov
wrote his famous laws of robotics —
											the three laws of robotics.
											A robot may not harm a human being,
											a robot may not disobey a human being,
											and a robot may not allow
itself to come to harm —
											in this order of importance.
											But after 40 years or so
											and after so many stories
pushing these laws to the limit,
											Asimov introduced the zeroth law
											which takes precedence above all,
											and it's that a robot
may not harm humanity as a whole.
											I don't know what this means
in the context of driverless cars
											or any specific situation,
											and I don't know how we can implement it,
											but I think that by recognizing
											that the regulation of driverless cars
is not only a technological problem
											but also a societal cooperation problem,
											I hope that we can at least begin
to ask the right questions.
									","
											Nos anos 40, Isaac Asimov escreveu 
as suas famosas leis da robótica,
											as três leis da robótica.
											Um robô não pode magoar um ser humano,
											um robô não pode desobedecer 
a um ser humano,
											e um robô não se pode 
danificar-se a ele mesmo
											— seguindo esta ordem de importância.
											Mas cerca de 40 anos depois,
											e depois de tantas histórias 
que levavam estas leis ao limite,
											Asimov introduziu a lei zero,
											que as precede a todas,
											aquela em que um robô 
não pode prejudicar a humanidade.
											Eu não sei o que isto significa
no contexto de carros autónomos
											ou em qualquer situação específica,
											e não sei como é que 
podemos implementar isto,
											mas acho que, ao reconhecer
											que a regulamentação dos carros autónomos 
não é apenas um problema tecnológico,
											mas também um problema
de cooperação social,
											espero que possamos começar 
a fazer as questões certas.
									","
											In den 1940ern schrieb Isaac Asimov
die berühmten Robotergesetze –
											die drei Robotergesetze.
											Ein Roboter darf kein
menschliches Wesen verletzen.
											Ein Roboter muss einem Menschen gehorchen.
											Ein Roboter muss 
seine Existenz beschützen.
											In dieser Reihenfolge.
											Aber nach ungefähr 40 Jahren
											und nach so viele Geschichten,
die diese Gesetze an ihre Grenzen bringen,
											entwickelte Asimov das nullte Gesetz,
											das über allen anderen steht.
											Es besagt, dass ein Roboter
die Menschheit nicht verletzen darf.
											Ich weiß nicht, was das in Verbindung
mit fahrerlosen Autos bedeutet
											oder in Verbindung mit anderen Situationen
											und ich weiß nicht,
wie wir es umsetzen können.
											Wenn wir jedoch anerkennen,
											dass die Vorschriften für fahrerlose Autos
nicht nur ein technologisches Problem,
											sondern auch ein gesellschaftliches
Kooperationsproblem sind,
											dann können wir beginnen,
die richtigen Fragen zu stellen.
									","
											Dans les années 1940, Isaac Asimov a écrit
sa célèbre loi de la robotique —
											les trois règles de la robotique.
											Un robot ne nuira pas à un être humain,
											un robot ne désobéira pas
											et il ne s'autorisera pas
à faire au mal —
											dans cet ordre d'importance.
											Mais environ 40 ans plus tard
											et après tellement de scénarios qui ont
testé ces règles,
											Asimov a présenté la loi Zéro
											qui a préséance avant tout.
											Un robot ne devrait pas nuire
à l'Humanité.
											Je ne sais pas ce que cela représente dans
le cas des voitures sans conducteur
											ou dans une situation spécifique,
											et je ne sais pas comment
la mettre en œuvre ;
											mais en admettant que
											la législation de ces voitures n'est pas 
uniquement un problème technique
											mais aussi un problème de coopération
sociétale, j'espère que
											nous puissions au moins nous poser
les bonnes questions.
									","
											1940'larda, Isaac Asimov
o meşhur Üç Robot Yasasını
											kaleme aldı.
											Robot, bir insana zarar veremez,
											robot bir insana itaatsizlik edemez
											ve robot kendisini gelecek zararlardan
korumakla yükümlüdür,
											bu önem sırasına göre.
											40 yıl kadar sonra,
											bu yasaların sınırlarını zorlayan
birçok hikâyenin ardından Asimov,
											diğer bütün yasalara üstünlük gösteren
											sıfırıncı yasasını yayınladı;
											bu yasa bir robotun genel olarak
insanlığa zarar veremeyeceğini belirtiyor.
											Bu yasanın, sürücüsüz arabalar konusunda
											veya belirli bir durumdaki
yerini bilmiyorum.
											Bunu nasıl yürürlüğe
koyacağımızı da bilmiyorum,
											fakat sürücüsüz araba düzenlemesinin,
											yalnızca bir teknolojik problem olduğunu
değil de, aynı zamanda toplumsal uzlaşma
											problemi olduğunu kabul edersek,
											umuyorum ki, en azından sonunda
doğru soruları sormaya başlayabileceğiz.
									","
											En 1940, Isaac Asimov escribió
sus famosas leyes de la robótica;
											las tres leyes de la robótica.
											Un robot no hará daño al ser humano,
											un robot debe obedecer al ser humano,
											y un robot debe preservarse a sí mismo.
											En ese orden de importancia.
											Pero después de 40 años más o menos,
											y después de tantas historias
que llevaron estas leyes al límite,
											Asimov introdujo la ley cero,
											que precede a las demás,
											y es que un robot
no hará daño a la Humanidad.
											No sé qué quiere decir esto
en el contexto de los vehículos autónomos,
											o en cualquier situación específica,
											y no sé cómo lo podemos implementar,
											pero creo que reconociendo
											que la regulación de vehículos autónomos
no es solo un problema tecnológico
											sino también un problema
de cooperación social,
											espero que podamos al menos empezar
a hacer las preguntas adecuadas.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											Thank you.
									","
											Obrigado.
									","
											Danke.
									","
											Merci.
									","
											Teşekkürler.
									","
											Gracias.
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
											(Applause)
									","
											(Aplausos)
									","
											(Applaus)
									","
											(Applaudissements)
									","
											(Alkışlar)
									","
											(Aplausos)
									",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
"
","
","
","
","
","
",What moral decisions should driverless cars make?,Iyad Rahwan,13:35,"AI,driverless cars,law,innovation,morality,technology"
