en,tr,es,fr,title,speaker,duration,tags
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So, artificial intelligence
											is known for disrupting
all kinds of industries.
											What about ice cream?
											What kind of mind-blowing
new flavors could we generate
											with the power of an advanced
artificial intelligence?
											So I teamed up with a group of coders
from Kealing Middle School
											to find out the answer to this question.
											They collected over 1,600
existing ice cream flavors,
											and together, we fed them to an algorithm
to see what it would generate.
											And here are some of the flavors
that the AI came up with.
									","
											Yapay zekânın,
											her tür endüstriyi
bozduğu bilinmektedir.
											Peki ya dondurma?
											Gelişmiş bir yapay zekânın gücüyle
											akıllara durgunluk verecek
ne tür tatlar oluşturabiliriz?
											Bu sorunun cevabını bulmak için
Kealing orta okulundan
											bir grup kodlayıcı ile birlikte çalıştım.
											Mevcut olan yaklaşık 1600
dondurma tadını topladılar
											ve birlikte, ne oluşturacağını görmek için
onları bir algoritmaya çevirdik.
											İşte yapay zekânın
ürettiği tatlardan birkaçı.
									","
											La inteligencia artificial
											es conocida por transformar
todo tipo de industrias.
											Pensemos en los helados.
											¿Qué alucinantes sabores
nuevos podríamos generar
											con el poder de una
inteligencia artificial avanzada?
											Me junté con un grupo de programadores
de la escuela secundaria Kealing
											para descubrir la
respuesta a esta pregunta.
											Reunieron más de 1600
sabores de helado existentes,
											y los introducimos en un algoritmo
para ver qué podría generar.
											Estos son algunos de
los sabores que la IA inventó.
									","
											L'intelligence artificielle
											est réputée pour chambouler
tous genres d'industries.
											Qu'en est-il des glaces ?
											Quels genres de parfums hallucinants
pourrions-nous créer
											avec les capacités d'une intelligence
artificielle avancée ?
											J'ai fait équipe avec un groupe
de programmeurs d'un collège du Texas
											pour trouver la réponse à cette question.
											Ils ont collecté plus de 1 600
parfums de glace existants
											et ensemble, nous les avons
présentées à un algorithme
											pour voir ce qu'il générerait.
											Voici certains des parfums
que l'IA a inventés.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											[Pumpkin Trash Break]
									","
											[Kabak Çöpü Parçası]
									","
											[Helado fétido de calabaza]
									","
											[Pause poubelle au potiron]
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											(Laughter)
									","
											(Gülüşmeler)
									","
											(Risas)
									","
											(Rires)
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											[Peanut Butter Slime]
									","
											[Fıstık Ezmesi Balçığı]
									","
											[Babas con mantequilla de cacahuete]
									","
											[Boue de beurre de cacahuètes]
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											[Strawberry Cream Disease]
									","
											[Çilek Kreması Hastalığı]
									","
											[Cremosa dolencia de fresa]
									","
											[Maladie de crème à la fraise]
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											(Laughter)
									","
											(Gülüşmeler)
									","
											(Risas)
									","
											(Rires)
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											These flavors are not delicious,
as we might have hoped they would be.
											So the question is: What happened?
											What went wrong?
											Is the AI trying to kill us?
											Or is it trying to do what we asked,
and there was a problem?
									","
											Bu tatlar umduğumuz gibi
lezzetli değiller.
											Soru şu: Ne oldu?
											Yanlış giden neydi?
											Yapay zekâ bizi öldürmeye mi çalışıyor?
											Yoksa istediğimiz şeyi yapmaya mı
çalışıyor ve bir problem mi oluyor?
									","
											Estos no son sabores deliciosos,
como quizá hubiésemos esperado.
											Luego la pregunta es: ¿Qué sucedió,
qué es lo que ha fallado?
											¿Intenta la IA acabar con nosotros?
											¿O intenta hacer lo que le
pedimos, y había un problema?
									","
											Ces parfums ne sont pas délicieux,
											comme nous aurions pu
espérer qu'ils soient.
											La question est : que s'est-il passé ?
											Qu'est-ce qui a mal tourné ?
											L'IA essaye-t-elle de nous tuer ?
											Ou essaye-t-elle de faire
ce que nous avons demandé
											et il y a un problème ?
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											In movies, when something
goes wrong with AI,
											it's usually because the AI has decided
											that it doesn't want to obey
the humans anymore,
											and it's got its own goals,
thank you very much.
											In real life, though,
the AI that we actually have
											is not nearly smart enough for that.
											It has the approximate computing power
											of an earthworm,
											or maybe at most a single honeybee,
											and actually, probably maybe less.
											Like, we're constantly learning
new things about brains
											that make it clear how much our AIs
don't measure up to real brains.
											So today's AI can do a task
like identify a pedestrian in a picture,
											but it doesn't have a concept
of what the pedestrian is
											beyond that it's a collection
of lines and textures and things.
											It doesn't know what a human actually is.
											So will today's AI
do what we ask it to do?
											It will if it can,
											but it might not do what we actually want.
									","
											Filmlerde yapay zekâyla ilgili
bir hata olduğunda
											bu genelde yapay zekânın,
											artık insanlara itaat etmemeye
karar vermesi nedeniyle olur
											ve artık kendi kuralları vardır,
çok teşekkürler.
											Ancak, gerçek hayatta
sahip olduğumuz yapay zekâ
											bunu yapabilecek kadar zeki değil.
											Yaklaşık bir solucanın
											veya belki de
olsa olsa tek bir bal arısının
											programlama gücüne sahiptir
											ve aslında, belki de daha azına sahiptir.
											Beyinlerle ilgili sürekli yeni şeyler
öğreniyoruz ve bu da yapay zekânın
											neden gerçek beyinlerle
aynı düzeyde olmayacağını açıklıyor.
											Günümüzdeki yapay zekâ,
bir resimde yayayı saptamak gibi
											bir görevi yapabilir, fakat bir yayanın
ne olduğunu kavrayamaz,
											yaya onun için bir çizgiler, dokular
ve bazı şeylerin toplamıdır.
											Bir insanın aslında ne olduğunu bilmez.
											Peki günümüzün yapay zekâsı
biz ne istersek onu mu yapacak?
											Eğer yapabilirse evet,
											fakat gerçekten
istediğimizi yapamayabilir.
									","
											En las películas, 
cuando algo falla con la IA,
											habitualmente se debe
a que la IA ha decidido
											que no quiere seguir
obedeciendo a los humanos,
											y tiene sus propios objetivos,
no iba ella a ser menos.
											En realidad, la IA que tenemos 
no es lo bastante inteligente para eso.
											Tiene la capacidad de cálculo aproximada
de una lombriz, o quizá de una sola abeja.
											Y de hecho, probablemente incluso menos.
											Aprendemos constantemente
cosas nuevas sobre el cerebro
											que evidencian el grado en que la IA
no es comparable a cerebros reales.
											La IA actual puede identificar
a un peatón en una imagen,
											pero no tiene un concepto
de lo que un peatón es,
											más allá de un agregado de
líneas, texturas y otras cosas.
											No sabe lo que un humano realmente es.
											¿Hará entonces la IA actual
aquello que le pedimos?
											Lo hará si puede, pero es posible
que no haga lo que queremos de ella.
									","
											Dans les films, quand
cela tourne mal avec l'IA,
											c'est généralement que l'IA a décidé
											qu'elle ne voulait plus obéir aux humains
											et qu'elle a ses propres objectifs,
											merci bien.
											Dans la vraie vie, cependant,
l'IA que nous avons
											n'est pas assez intelligente pour cela.
											Elle a à peu près la puissance
de calcul d'un ver de terre
											ou peut-être, au mieux,
d'une seule abeille
											et probablement moins que cela.
											Nous apprenons constamment
de nouvelles choses sur le cerveau
											qui établissent clairement
											à quel point nos IA ne sont pas
à la hauteur de vrais cerveaux.
											L'IA actuelle peut réaliser une tâche
comme identifier un piéton sur une photo
											mais n'a pas de concept
expliquant ce qu'est un piéton
											au-delà d'un ensemble de lignes,
de textures et de choses.
											Elle ne sait pas
ce qu'est vraiment un humain.
											L'IA actuelle fera-t-elle
ce que nous lui demandons de faire ?
											Oui, si elle le peut,
											mais elle pourrait ne pas faire
ce que nous voulons.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So let's say that you
were trying to get an AI
											to take this collection of robot parts
											and assemble them into some kind of robot
to get from Point A to Point B.
											Now, if you were going to try
and solve this problem
											by writing a traditional-style
computer program,
											you would give the program
step-by-step instructions
											on how to take these parts,
											how to assemble them
into a robot with legs
											and then how to use those legs
to walk to Point B.
											But when you're using AI
to solve the problem,
											it goes differently.
											You don't tell it
how to solve the problem,
											you just give it the goal,
											and it has to figure out for itself
via trial and error
											how to reach that goal.
											And it turns out that the way AI tends
to solve this particular problem
											is by doing this:
											it assembles itself into a tower
and then falls over
											and lands at Point B.
											And technically, this solves the problem.
											Technically, it got to Point B.
											The danger of AI is not that
it's going to rebel against us,
											it's that it's going to do
exactly what we ask it to do.
											So then the trick
of working with AI becomes:
											How do we set up the problem
so that it actually does what we want?
									","
											Diyelim ki bir yapay zekânın
bu robot parçalarını alıp
											A noktasından B noktasına gidecek
											bir robota dönüştürmesini istiyorsunuz.
											Bu problemi geleneksel türden
bir bilgisayar programı yazarak
											çözmeyi deneyecek olsaydınız,
											programa bu parçaları nasıl alacağına,
											bunları bacaklı bir robota
nasıl dönüştüreceğine
											ve o bacakları B noktasına gitmesi
için nasıl kullanacağına dair
											adım adım talimatlar verirdiniz.
											Fakat problemi çözmek için
yapay zekâ kullandığınızda
											işler farklı ilerliyor.
											Ona problemi
nasıl çözeceğini söylemiyorsunuz,
											ona sadece amacı veriyorsunuz
											ve onun, amaca ulaşmak için
deneme yanılma aracılığıyla
											kendisi çözmesi gerekiyor.
											Yapay zekânın bu problemi
çözmek için gittiği yol
											şu şekilde görünüyor:
											kendisini bir kuleye
monte ediyor, sonra düşüyor
											ve B noktasına iniş yapıyor.
											Bu, teknik olarak problemi çözüyor.
											Teknik olarak B noktasına gidiyor.
											Yapay zekânın tehlikesi aslında
bizlere karşı ayaklanacağı değil,
											tam olarak yapmalarını istediğimiz
şeyleri yapacak olmalarıdır.
											O zaman da yapay zekâyla
çalışma hilesi şu hale geliyor:
											Problemi nasıl düzenleyelim ki
gerçekten istediğimizi yapsın?
									","
											Digamos que Uds. intentaran que una IA
tomara esta colección de piezas de robot,
											y las ensamblara en un robot
para ir del punto A al punto B.
											Si intentamos solucionar este problema
con un programa tradicional de ordenador,
											daríamos al programa instrucciones
paso a paso de cómo tomar estas partes,
											cómo ensamblarlas en un robot con piernas,
y cómo caminar con ellas hasta el punto B.
											Pero cuando utilizamos IA para solucionar
el problema, se procede de otra manera.
											No se le enseña cómo resolver el problema,
únicamente se le da el objetivo,
											y tiene que lograrlo por sí misma
a través de ensayo y error
											para alcanzar ese objetivo.
											El modo en que la IA tiende a resolver 
este particular problema es el siguiente:
											Se ensambla en una torre,
y luego se deja caer
											para ir a parar al punto B.
											Y técnicamente, soluciona el problema.
Técnicamente, llegó al punto B.
											El peligro de la IA no es que
vaya a rebelarse contra nosotros,
											sino que hará exactamente
lo que le pidamos que haga.
											Luego el quid de la cuestión
al trabajar con IA pasa a ser
											cómo estructuramos el problema
para que haga lo que queremos.
									","
											Disons que vous essayiez
de faire qu'une IA
											prenne cet ensemble de pièces d'un robot
											et les assemblent en une sorte de robot
pour aller du point A au point B.
											Si vous essayiez de résoudre ce problème
											en écrivant un programme
informatique traditionnel,
											vous lui donneriez
des instructions par étapes
											sur comment prendre ces pièces,
											les assembler en un robot ayant des jambes
											puis comment utiliser ces jambes
pour marcher jusqu'au point B.
											Si vous utilisez une IA
pour résoudre le problème,
											cela est différent.
											Vous ne lui dites pas
comment résoudre le problème,
											vous lui donnez juste l'objectif
											et elle doit trouver par tâtonnements
comment atteindre cet objectif.
											Il s'avère que l'IA a tendance
à résoudre ce problème en particulier
											en faisant ceci :
											elle s'assemble pour former une tour
puis se laisse tomber
											et atterrit au point B.
											Techniquement, cela résout le problème.
											Techniquement,
elle est arrivée au point B.
											Le danger lié à l'IA n'est pas
qu'elle va se rebeller contre nous,
											c'est qu'elle va faire exactement
ce que nous lui demandons.
											L'astuce pour travailler
avec une IA devient :
											comment poser le problème
pour qu'elle fasse ce que l'on veut ?
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So this little robot here
is being controlled by an AI.
											The AI came up with a design
for the robot legs
											and then figured out how to use them
to get past all these obstacles.
											But when David Ha set up this experiment,
											he had to set it up
with very, very strict limits
											on how big the AI
was allowed to make the legs,
											because otherwise ...
									","
											Bu küçük robot bir yapay zekâ
tarafından kontrol ediliyor.
											Yapay zekâ robot bacakları için
bir tasarım buldu
											ve sonra onları, bu engelleri aşmak için
nasıl kullanacağını çözdü.
											Fakat David Ha bu deneyi oluşturduğunda
											yapay zekânın bacakları ne kadar
büyük yapabileceğine dair
											çok, çok katı
kısıtlamalarla oluşturmalıydı,
											çünkü, aksi takdirde...
									","
											Este pequeño robot de aquí
está controlado por una IA.
											La IA ideó un diseño
para las piernas del robot,
											y luego averiguó cómo usarlas
para superar todos estos obstáculos.
											Pero cuando David Ha
preparó este experimento,
											tuvo que diseñarlo con
límites muy estrictos
											en cuanto al tamaño de piernas
permitido, porque de lo contrario...
									","
											Ce petit robot est contrôlé par une IA.
											L'IA a conçu un design
pour les jambes du robot
											puis elle a déterminé comment les utiliser
pour passer tous ces obstacles.
											Mais quand David Ha
a présenté cette expérience,
											il a dû établir des limites
très, très strictes
											sur la taille autorisée
des jambes que l'IA pouvait créer,
											car sinon...
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											(Laughter)
									","
											(Gülüşmeler)
									","
											(Risas)
									","
											(Rires)
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											And technically, it got
to the end of that obstacle course.
											So you see how hard it is to get AI
to do something as simple as just walk.
									","
											Teknik olarak bu engel rotasının
sonuna varabildi.
											Bir yapay zekânın, yürümek gibi basit
bir eylemi yapmasını sağlamak çok zor.
									","
											Y técnicamente, logró completar
el recorrido de obstáculos.
											Pueden ver lo difícil que es para la IA
hacer algo tan sencillo como caminar.
									","
											Techniquement, elle est arrivée
à la fin de cette course d'obstacles.
											Vous voyez à quel point il est difficile
											de faire faire une chose
aussi simple que marcher à une IA.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So seeing the AI do this,
you may say, OK, no fair,
											you can't just be
a tall tower and fall over,
											you have to actually, like,
use legs to walk.
											And it turns out,
that doesn't always work, either.
											This AI's job was to move fast.
											They didn't tell it that it had
to run facing forward
											or that it couldn't use its arms.
											So this is what you get
when you train AI to move fast,
											you get things like somersaulting
and silly walks.
											It's really common.
											So is twitching along the floor in a heap.
									","
											Yapay zekânın bunu yaptığını görünce,
bu haksızlık diyebilirsiniz,
											yüksek bir kule olup düşemezsiniz,
											yürümek için bacak
kullanmanız gerek diyebilirsiniz.
											Görünen o ki, bu da
her zaman işe yaramıyor.
											Yapay zekânın işi hızlı hareket etmek.
											Ona ileri doğru koşması gerektiğini
											veya kollarını
kullanamayacağını söylemediler.
											Yapay zekâya hızlı hareket etmeyi
öğrettiğiniz zaman olan şey budur,
											takla atmak veya şaşkınca yürüyüşler
gibi şeylerle karşılaşırsınız.
											Bu gerçekten yaygın.
											Yerde sürünmek de yaygın.
									","
											Viendo esto, quizá
pensemos que no es justo,
											no puede hacer una
torre y dejarse caer,
											tiene que usar piernas para caminar.
											Y resulta que eso
tampoco funciona siempre.
											La tarea de esta IA era
moverse con rapidez.
											No se le especificó que
tuviera que hacerlo de frente,
											o que no pudiera usar sus brazos.
											Esto es lo que se obtiene cuando
se entrena a la IA para moverse deprisa.
											Obtienes volteretas y andares cómicos.
											Es muy común.
											También lo es arrastrarse
por el suelo en un montón.
									","
											En voyant l'IA faire ceci, vous pourriez
dire que cela ne fonctionne pas,
											qu'elle ne peut pas juste
être une haute tour et tomber,
											qu'elle doit utiliser
des jambes pour marcher.
											Il s'avère que cela non plus
ne fonctionne pas toujours.
											L'objectif de l'IA
était de se déplacer rapidement.
											On ne lui a pas dit qu'elle devait
courir vers l'avant
											ou qu'elle ne pouvait pas
utiliser ses bras.
											Voilà ce qui arrive quand vous entraînez
une IA à se déplacer rapidement,
											vous obtenez des sauts périlleux
et des démarches ridicules.
											C'est très courant.
											Tout comme tressauter
sous forme d'amas informe.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											(Laughter)
									","
											(Gülüşmeler)
									","
											(Risas)
									","
											(Rires)
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So in my opinion, you know what
should have been a whole lot weirder
											is the ""Terminator"" robots.
											Hacking ""The Matrix"" is another thing
that AI will do if you give it a chance.
											So if you train an AI in a simulation,
											it will learn how to do things like
hack into the simulation's math errors
											and harvest them for energy.
											Or it will figure out how to move faster
by glitching repeatedly into the floor.
											When you're working with AI,
											it's less like working with another human
											and a lot more like working
with some kind of weird force of nature.
											And it's really easy to accidentally
give AI the wrong problem to solve,
											and often we don't realize that
until something has actually gone wrong.
									","
											Bana göre, bundan çok daha
garip olan şey,
											""Terminatör"" robotları.
											Ona bir şans verirseniz, yapay zekanın
yapacağı diğer şey ""Matrix""e girmektir.
											Bir simülasyonda
yapay zekâyı eğitirseniz,
											simülasyonun matematik hatalarına
girmek ve onları enerji için saklamak
											gibi şeyleri yapmayı öğrenir.
											Sürekli yerde sürünerek
hızlı hareket etmeyi de çözebilir.
											Bir yapay zekâyla çalışırken
											bu diğer bir insanla çalışmaktan ziyade,
											daha çok doğanın garip bir gücüyle
çalışmaya benziyor.
											Yapay zekâya çözmesi için kazara
yanlış problemi vermek de çok kolay
											ve bir şeyler yanlış gidene dek
bunu genelde fark etmeyiz.
									","
											En mi opinión, lo que debería
haber sido mucho más extraño
											son los robots de ""Terminator"".
											Hackear ""The Matrix"" es otra cosa que
una IA hará si le das la oportunidad.
											Si entrenas a la IA en una simulación,

											aprenderá cómo hackear los errores
matemáticos de la simulación
											y utilizarlos para obtener energía.
											O averiguará cómo moverse más rápido
explotando fallos encontrados en el suelo.
											Cuando trabajas con IA no es como
si trabajaras con otro ser humano
											sino como hacerlo con
una fuerza extraña de la naturaleza.
											Es muy fácil dar accidentalmente a
la IA el problema erróneo que resolver,
											y frecuentemente no nos percatamos
hasta que las consecuencias son evidentes.
									","
											A mon avis, ce qui aurait dû être
bien plus étrange,
											ce sont les robots de « Terminator ».
											Pirater la « Matrice » est une autre chose
que l'IA fera si elle en a l'occasion.
											Si vous entraînez votre IA
dans une simulation,
											elle apprendra à faire des choses
											comme exploiter les erreurs
de maths de la simulation
											pour en tirer de l'énergie.
											Ou elle trouvera
comment se déplacer plus vite
											en exploitant à répétition
un bug pour avancer sur le sol.
											Travailler avec une IA,
											c'est moins comme travailler
avec un autre humain
											et plutôt comme travailler
avec une étrange force de la nature.
											Il est très facile de donner
accidentellement à l'IA
											le mauvais problème à résoudre
											et nous ne nous en rendons
souvent pas compte
											avant que quelque chose
n'ait très mal tourné.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So here's an experiment I did,
											where I wanted the AI
to copy paint colors,
											to invent new paint colors,
											given the list like the ones
here on the left.
											And here's what the AI
actually came up with.
									","
											Yaptığım bir deneyde
											yapay zekâdan
boya renklerini kopyalamasını
											ve yeni boya renkleri
yaratmasını istedim,
											bu soldaki listedekiler gibi
bir liste verdim.
											Yapay zekânın önerdikleri ise şunlar.
									","
											He aquí un experimento que hice,
											quería que la IA copiara colores
para inventar otros nuevos,
											dada una lista como la de la izquierda.
											Y esto es lo que la IA propuso:
									","
											Voici une expérience que j'ai réalisée
											où je voulais que l'IA
copie des couleurs de peinture
											pour en inventer de nouvelles
											en ayant la liste de celles
qui sont sur la gauche.
											Et voici ce que l'IA a inventé.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											[Sindis Poop, Turdly, Suffer, Gray Pubic]
									","
											[Sindi Kakası, Gübremsi, Acı, Gri Kasık]
									","
											[Caca de Sindis, Zurullo,
Sufrimiento, Gris púbico]
									","
											[Caca de Sindis, Merdouille,
Souffrance, Pubis gris]
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											(Laughter)
									","
											(Gülüşmeler)
									","
											(Risas)
									","
											(Rires)
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So technically,
											it did what I asked it to.
											I thought I was asking it for,
like, nice paint color names,
											but what I was actually asking it to do
											was just imitate the kinds
of letter combinations
											that it had seen in the original.
											And I didn't tell it anything
about what words mean,
											or that there are maybe some words
											that it should avoid using
in these paint colors.
											So its entire world
is the data that I gave it.
											Like with the ice cream flavors,
it doesn't know about anything else.
									","
											Teknik olarak
											istediğimi yaptı.
											Ben güzel boya renkleri isimleri
istediğimi düşünmüştüm,
											fakat aslında yapmasını istediğim şey
											orijinalinde gördüğü
harf kombinasyonları türlerini
											taklit etmesiydi.
											Kelimelerin ne anlama geldiğine dair

											veya isimleri bulurken
kullanmaması gereken bazı kelimeler
											olabileceğine dair hiçbir şey söylemedim.
											Yani onun tüm dünyası,
benim ona sağladığım veri.
											Dondurma tatları gibi,
başka hiçbir şey bilmiyor.
									","
											Técnicamente, hizo lo que le pedí.
											Pensé que le estaba pidiendo
nombres apropiados para colores,
											pero lo que verdaderamente le pedí

											es que imitase las combinaciones de letras
que había visto en la lista original.
											No le dije lo que las palabras significan,
o que quizá haya ciertas palabras


											que debería evitar utilizar
en estos colores.
											Todo su mundo se reduce a 
la información que le proporcioné.
											Como con los sabores de helado,
no sabe de ninguna otra cosa.
									","
											Techniquement,
											elle a fait ce que je lui avais demandé.
											Je pensais lui demander
des noms de couleur sympa,
											mais ce que je lui demandais de faire,
											c'était d'imaginer le genre
de combinaisons de lettres
											qu'elle avait vues dans la liste initiale.
											Je ne lui ai rien dit sur le sens des mots
											ni sur le fait qu'il y a
peut-être des mots
											qu'elle devrait éviter d'utiliser
dans ces couleurs de peinture.
											Son monde se limite
aux données que je lui ai données.
											Comme pour les parfums de glace,
elle ne sait rien d'autre.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So it is through the data
											that we often accidentally tell AI
to do the wrong thing.
											This is a fish called a tench.
											And there was a group of researchers
											who trained an AI to identify
this tench in pictures.
											But then when they asked it
											what part of the picture it was actually
using to identify the fish,
											here's what it highlighted.
											Yes, those are human fingers.
											Why would it be looking for human fingers
											if it's trying to identify a fish?
											Well, it turns out that the tench
is a trophy fish,
											and so in a lot of pictures
that the AI had seen of this fish
											during training,
											the fish looked like this.
									","
											Yani genelde veri aracılığıyla
											yapay zekâya kazara yanlış şeyi
yapmasını söylüyoruz.
											Bu, karabalık adlı bir balık.
											Bir grup araştırmacı da yapay zekâyı
											resimlerde karabalığı
saptaması için eğitmişti.
											fakat ona, balığı saptamak için
											resmin hangi kısmını
kullandığını sorduklarında,
											işte bunu vurguladı.
											Evet, bunlar insan elinin parmakları.
											Bir balığı saptamayı deniyorsa,
											neden insan elinin parmaklarını arıyor?
											Görünen o ki bu karabalık bir ödül balığı
											ve eğitimi sırasında
yapay zekânın gördüğü
											birçok resimde,
											balık böyle görünüyordu.
									","
											Es a través de la información
											que con frecuencia decimos a la IA
accidentalmente que haga algo erróneo.
											Este pez se llama tenca.
											Había un grupo de investigadores
											que entrenó a una IA para
identificar a esta tenca en imágenes.
											Pero cuando le preguntaron qué parte de la
imagen utilizaba para identificar al pez,
											esto es lo que destacó.
											Son dedos humanos.
											¿Por qué estaría buscando dedos humanos
si está intentando identificar un pez?
											Resulta que la tenca es un pez trofeo,
											y en muchas imágenes que la IA había
visto del pez durante su entrenamiento,
											el pez aparecía así.
									","
											C'est à travers les données
											que nous disons souvent accidentellement
à l'IA de faire la mauvaise chose.
											Ceci est un poisson appelé une tanche.
											Un groupe de chercheurs
											a entraîné l'IA à identifier
cette tanche sur les photos.
											Mais quand ils lui ont demandé
											quelle partie de la photo
elle utilisait pour identifier le poisson,
											voici ce qui a été sélectionné.
											Oui, ce sont des doigts humains.
											Pourquoi chercherait-elle
des doigts humains
											si elle essaye d'identifier un poisson ?
											Il s'avère que la tanche
est un poisson trophée
											et donc sur de nombreuses photos
que l'IA avait vues de ce poisson
											durant son entraînement,
											le poisson ressemblait à ceci.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											(Laughter)
									","
											(Gülüşmeler)
									","
											(Risas)
									","
											(Rires)
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											And it didn't know that the fingers
aren't part of the fish.
									","
											Parmakların, balığın bir parçası
olmadığını bilmiyordu.
									","
											No sabía que los dedos
no son parte del pez.
									","
											Et elle ne savait pas que les doigts
ne faisaient pas partie du poisson.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So you see why it is so hard
to design an AI
											that actually can understand
what it's looking at.
											And this is why designing
the image recognition
											in self-driving cars is so hard,
											and why so many self-driving car failures
											are because the AI got confused.
											I want to talk about an example from 2016.
											There was a fatal accident when somebody
was using Tesla's autopilot AI,
											but instead of using it on the highway
like it was designed for,
											they used it on city streets.
											And what happened was,
											a truck drove out in front of the car
and the car failed to brake.
											Now, the AI definitely was trained
to recognize trucks in pictures.
											But what it looks like happened is
											the AI was trained to recognize
trucks on highway driving,
											where you would expect
to see trucks from behind.
											Trucks on the side is not supposed
to happen on a highway,
											and so when the AI saw this truck,
											it looks like the AI recognized it
as most likely to be a road sign
											and therefore, safe to drive underneath.
									","
											Baktığı şeyi gerçekten anlayabilecek
bir yapay zekâ tasarlamanın
											neden çok zor olduğunu
görüyorsunuz.
											Ayrıca sürücüsüz arabalarda
											görüntü tanımayı tasarlamanın
zor olmasının nedeni de bu
											ve sürücüsüz arabalardaki
birçok başarısızlık da
											yapay zekânın şaşırması nedenlidir.
											2016'dan bir örnek vermek istiyorum.
											Birisi Tesla'nın oto-pilot yapay zekasını
kullanırken ölümcül bir kaza oldu,
											fakat tasarlandığı üzere
otoyolda kullanmak yerine,
											şehrin sokaklarında kullandılar.
											Olan şey de şuydu;
											bir kamyon, arabanın önüne sürdü
ve araba fren yapamadı.
											Yapay zekâ kesinlikle resimlerde
kamyonları saptamak üzere eğitilmişti.
											Fakat olan şey şu gibi görünüyor,
											yapay zekâ otoyolda giden
kamyonları saptamayı öğrenmişti,
											yani kamyonları arkadan
göreceğimiz bir şekilde öğrenmişti.
											Yanı görünen kamyonların
otoyolda olmaları beklenmez
											ve yapay zekâ bu kamyonu gördüğünde,
											büyük olasılıkla
bir yol işareti olarak algıladı
											ve altından geçmenin
güvenli olduğunu düşündü.
									","
											Pueden ver por qué es tan
complicado diseñar una IA
											que verdaderamente entienda
aquello que está viendo.
											Por eso diseñar en coches autónomos el
reconocimiento de imágenes es tan difícil,
											y muchos fallos de coches autónomos
se deben a que la IA se confundió.
											Quiero hablar de un ejemplo de 2016.
											Hubo un funesto accidente cuando alguien
usaba la IA de piloto automático de Tesla,
											pero en lugar de hacerlo en la autopista
para la que estaba diseñada,
											la usó en las vías urbanas.
											Lo que sucedió fue que un camión condujo
frente al coche, y el coche no frenó.
											La IA estaba entrenada para
reconocer camiones en las imágenes.
											Pero al parecer la IA había sido entrenada
para reconocer camiones en la autopista,
											donde esperarías verlos
desde la parte trasera.
											Que los camiones se te crucen no es
algo que suceda en la autopista,
											y cuando la IA vio a este camión,
											parece que lo reconoció
como una señal de carretera,
											y por tanto que la conducción
por debajo era segura.
									","
											Vous voyez pourquoi il est si dur
de concevoir une IA
											qui comprend vraiment
ce qu'elle considère.
											C'est pourquoi concevoir
la reconnaissance d'images
											dans les voitures autonomes
est si difficile
											et pourquoi tant
de défaillances de ces voitures
											sont dues au fait
que l'IA ait confondu des choses.
											Je veux parler d'un exemple de 2016.
											Il y a eu un accident mortel
											où quelqu'un utilisait l'IA
de pilote automatique de Tesla,
											mais au lieu de l'utiliser
sur l'autoroute,
											ce pour quoi elle était conçue,
											il l'a utilisé dans les rues de la ville.
											Ce qu'il s'est passé,
											c'est qu'un camion est passé
devant la voiture
											et la voiture n'a pas freiné.
											L'IA avait été entraînée à reconnaître
les camions sur des photos.
											Mais il semble que ce qu'il s'est passé,
											c'est qu'elle reconnaissait
les camions sur l'autoroute,
											où vous vous attendez
à les voir de derrière.
											Les camions ne sont pas censés
être vus de côté sur l'autoroute
											et donc quand l'IA a vu ce camion,
											il semblerait que l'IA l'ait reconnu
comme étant un panneau de signalisation,
											il était donc sans danger
de passer en dessous.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											Here's an AI misstep
from a different field.
											Amazon recently had to give up
on a résumé-sorting algorithm
											that they were working on
											when they discovered that the algorithm
had learned to discriminate against women.
											What happened is they had trained it
on example résumés
											of people who they had hired in the past.
											And from these examples, the AI learned
to avoid the résumés of people
											who had gone to women's colleges
											or who had the word ""women""
somewhere in their resume,
											as in, ""women's soccer team""
or ""Society of Women Engineers.""
											The AI didn't know that it wasn't supposed
to copy this particular thing
											that it had seen the humans do.
											And technically, it did
what they asked it to do.
											They just accidentally asked it
to do the wrong thing.
									","
											Yapay zekânın başka alanda
attığı yanlış bir adım daha.
											Amazon, algoritmanın kadınlara karşı
ayrımcılık yapmayı öğrendiğini
											keşfettiği zaman,
											bir özgeçmiş-sıralama algoritmasından
vazgeçmek zorunda kaldı.
											Olan şey şuydu, yapay zekâyı
geçmişte işe aldıkları insanlara ait
											örnek özgeçmişlerle eğittiler.
											Yapay zekâ da bu örneklerden,
kadın okullarına gitmiş olan
											veya özgeçmişinin herhangi bir yerinde
											""kadın"" kelimesi geçen, 
— ""kadın futbol takımı""
											veya ""Kadın Mühendisler Derneği"" gibi —
özgeçmişlerden kaçınmayı öğrendi.
											Yapay zekâ, insanların
yaptığını gördüğü bu şeyi
											kopyalaması gerekmediğini bilmiyordu.
											Teknik olarak da
yapmasını istedikleri şeyi yaptı.
											Sadece, yanlış şeyi yapmasını istediler.
									","
											Aquí tenemos una equivocación
de una IA en otra área.
											Amazon tuvo que abandonar un
algoritmo de clasificación de currículums
											en el que trabajaban
											cuando descubrieron que el algoritmo había
aprendido a discriminar a las mujeres.
											Lo que pasó fue que la habían
entrenado con currículums
											de gente que habían
contratado en el pasado.
											De estos ejemplos, la IA aprendió
a evitar currículums de personas
											que hubieran ido a
universidades de mujeres,
											o que contuvieran la palabra
""mujer"" en su currículum,
											como ""equipo de fútbol de mujeres"",
o ""Sociedad de Mujeres Ingenieras"".
											La IA no sabía que no debía
copiar este modo de proceder
											que había visto emplear a los humanos.
											Y técnicamente, hizo lo
que se requería de ella.
											Simplemente, de forma accidental
le solicitaron algo incorrecto.
									","
											Voici une bévue de l'IA
dans un autre domaine.
											Amazon a récemment dû abandonner
un algorithme de tri de CV
											sur lequel ils travaillaient
											quand ils ont découvert
											que l'algorithme avait appris
à discriminer contre les femmes.
											Ils l'avaient entraîné
avec des exemples de CV
											de gens qu'ils avaient
embauchés dans le passé.
											D'après ces exemples, l'IA a appris
à éviter les CV les gens
											ayant été dans des universités de femmes
											ou ayant le mot « femmes »
quelque part sur leur CV
											comme dans « équipe de sport de femmes »
											ou « Société des femmes ingénieures ».
											L'IA ne savait pas
qu'elle n'était pas censée
											copier cette chose en particulier
											qu'elle avait vu les humains faire.
											Techniquement, elle a fait
ce qu'ils lui ont demandé.
											Ils lui ont juste accidentellement demandé
de faire la mauvaise chose.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											And this happens all the time with AI.
											AI can be really destructive
and not know it.
											So the AIs that recommend
new content in Facebook, in YouTube,
											they're optimized to increase
the number of clicks and views.
											And unfortunately, one way
that they have found of doing this
											is to recommend the content
of conspiracy theories or bigotry.
											The AIs themselves don't have any concept
of what this content actually is,
											and they don't have any concept
of what the consequences might be
											of recommending this content.
									","
											Yapay zekâyla bu her zaman olur.
											Yapay zeka çok zararlı olabilir
ve bunu bilmeyebilir.
											Facebook, YouTube'da yeni içerik
öneren yapay zekâlar,
											tıklama ve görüntüleme sayısını
yükseltmek üzere optimize edilmiştir.
											Ne yazık ki bunu yapmak için
buldukları bir yol da,
											komplo teorisi veya fanatiklik
içerikleri önermek.
											Yapay zekâların, bu içeriklere dair
herhangi bir fikirleri yok
											ve bu içeriği önerdikleri zaman
sonucun ne olacağına dair de
											herhangi bir fikirleri yok.
									","
											Esto sucede constantemente con la IA.
											La IA puede ser muy destructiva
sin tener conciencia de ello.
											Las IAs que recomiendan nuevo
contenido en Facebook, o en Youtube,
											están optimizadas para incrementar
el número de clics y visualizaciones.
											Y desafortunadamente, una forma
que han encontrado de lograrlo
											es recomendar contenido concerniente
a teorías conspiratorias o fanatismo.
											Las IAs no tienen concepto alguno
de qué es realmente este contenido,
											ni tienen un entendimiento
de las posibles consecuencias
											de recomendar este contenido.
									","
											Cela arrive constamment avec l'IA.
											L'IA peut être destructrice
et ne pas le savoir.
											Les IA qui recommandent
de nouveaux contenus
											sur Facebook, sur YouTube,
											elles sont optimisées pour augmenter
le nombre de clics et de vues.
											Malheureusement, une des façons
trouvées pour faire cela
											est de recommander du contenu
de théories conspirationnistes
											ou relevant du fanatisme religieux.
											Les IA n'ont aucune idée
de ce qu'est ce contenu
											et elles n'ont aucune idée
des conséquences possibles
											de la recommandation de ce contenu.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											So, when we're working with AI,
											it's up to us to avoid problems.
											And avoiding things going wrong,
											that may come down to
the age-old problem of communication,
											where we as humans have to learn
how to communicate with AI.
											We have to learn what AI
is capable of doing and what it's not,
											and to understand that,
with its tiny little worm brain,
											AI doesn't really understand
what we're trying to ask it to do.
											So in other words, we have
to be prepared to work with AI
											that's not the super-competent,
all-knowing AI of science fiction.
											We have to be prepared to work with an AI
											that's the one that we actually have
in the present day.
											And present-day AI is plenty weird enough.
									","
											Yani, yapay zekâyla çalışırken
											problemlerden kaçınmak bize bağlıdır.
											Yanlış giden şeylerden kaçınmak da öyle,
											bu çok eski iletişim
problemine kadar da inebilir,
											insanlar yapay zekâyla nasıl iletişim
kuracağını öğrenmelidir.
											Yapay zekânın ne yapabildiğini
ve ne yapamadığını öğrenmeliyiz
											ve yapay zekânın,
çok küçük solucan beyniyle,
											ondan yapmasını istediğimiz şeyi
aslında anlamadığını anlamalıyız.
											Yani, süper-yetkili, her şeyi bilen
bilim kurgu yapay zekâlarına benzemeyen
											yapay zekâ ile çalışmaya
hazırlıklı olmalıyız.
											Şimdiki zamanda sahip olduğumuz
											tek yapay zekâyla
çalışmaya hazırlıklı olmalıyız.
											Günümüzün yapay zekâsı da yeterince garip.
									","
											Al trabajar con IA, depende de nosotros
evitar los problemas.
											Eludir estos errores puede depender
del viejo problema de la comunicación,
											y que nosotros los humanos tengamos 
que aprender a comunicarnos con la IA.
											Tenemos que aprender lo que
la IA es capaz de hacer y lo que no,
											y entender que, 
con su pequeño cerebro de lombriz,
											la IA no entiende verdaderamente
lo que le estamos pidiendo que haga.
											En otras palabras, hemos de estar
preparados para trabajar con una IA
											que no es la súper competente
sabelotodo de la ciencia ficción.
											Hemos de estar preparados
para trabajar con la IA
											que tenemos disponible en la actualidad.
											Y la IA actual es ya lo bastante extraña.
									","
											Quand nous travaillons avec une IA,
											c'est à nous d'éviter les problèmes.
											Éviter que les choses tournent mal,
											cela pourrait se résumer au sempiternel
problème de communication
											où, en tant qu'humains,
nous devons apprendre
											à communiquer avec l'IA.
											Nous devons apprendre ce dont l'IA
est capable et ce dont elle est incapable,
											et comprendre qu'avec
son petit cerveau de ver,
											l'IA ne comprend pas vraiment
ce que nous lui demandons de faire.
											En d'autres mots, nous devons
être prêts à travailler avec une IA
											qui n'est pas l'IA super compétente,
omnisciente de la science-fiction.
											Nous devons être prêts
à travailler avec une IA
											qui est celle que nous avons actuellement.
											Et l'IA actuellement est très étrange.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											Thank you.
									","
											Teşekkürler.
									","
											Gracias.
									","
											Merci.
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
											(Applause)
									","
											(Alkış)
									","
											(Aplausos)
									","
											(Applaudissements)
									",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
"
","
","
","
",The danger of AI is weirder than you think,Janelle Shane,10:28,"AI,technology,future,computers,algorithm,machine learning"
