en,pt,tr,de,title,speaker,duration,tags
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											So whenever I visit a school
and talk to students,
											I always ask them the same thing:
											Why do you Google?
											Why is Google the search engine
of choice for you?
											Strangely enough, I always get
the same three answers.
											One, ""Because it works,""
											which is a great answer;
that's why I Google, too.
											Two, somebody will say,
											""I really don't know of any alternatives.""
											It's not an equally great answer
and my reply to that is usually,
											""Try to Google the word 'search engine,'
											you may find a couple
of interesting alternatives.""
											And last but not least, thirdly,
											inevitably, one student will raise
her or his hand and say,
											""With Google, I'm certain to always get
the best, unbiased search result.""
											Certain to always get the best,
unbiased search result.
									","
											Sempre que visito uma escola
e falo com estudantes
											pergunto-lhes sempre a mesma coisa:
											""Porque é que usam o Google?
											""Porque é que o Google é 
o vosso motor de pesquisa preferido?""
											É curioso que obtenho sempre
as mesmas três respostas.
											Um: ""Porque funciona"",
											o que é uma ótima resposta,
também é por isso que eu uso o Google.
											Dois, há alguém que diz:
											""Não conheço nenhuma alternativa"".
											Não é uma resposta tão boa
e a minha resposta habitualmente é:
											""Experimenta pesquisar 
no Google 'motor de busca',
											""talvez encontres
algumas alternativas interessantes"".
											Por fim, mas não menos
frequente, terceiro,
											inevitavelmente, um estudante
levanta a mão e diz:
											""Com o Google, tenho a certeza
de obter sempre
											""o melhor resultado de pesquisa,
e imparcial"".
											A certeza de obter sempre 
o melhor resultado de pesquisa, imparcial.
									","
											Ne zaman bir okula gidip,
öğrencilerle konuşsam,
											onlara hep aynı şeyi sorarım:
											neden Google-larsınız?
											Arama motoru olarak tercihiniz 
neden Google'dır?
											Garip belki ama sürekli 
aynı üç cevap verilir.
											İlki, “işe yarıyor”,
											güzel bir cevap, 
benim de Google’ı tercih sebebim.
											İkincisi, bazıları,
											“gerçekten alternatifini bilmiyorum.” der.
											Bu o kadar güzel bir cevap sayılmaz, 
onlara genellikle cevabım
											""Google’a 'arama motoru' 
yazmayı denersen,
											birkaç ilginç 
alternatif bulabilirsin.” olur.
											Sonuncusu ise,
											kaçınılmaz bir şekilde, bir öğrenci 
parmak kaldırıp
											“Google'la kesin olarak, hep en iyi ve
önyargısız arama sonucuna ulaşırım.” der.
											En iyi ve önyargısız arama sonucuna 
kesin olarak, hep ulaşmak.
									","
											Wann immer ich eine Schule besuche
und mit den Schülern spreche,
											frage ich immer das Gleiche:
											""Warum googelt ihr?
											Warum benutzt ihr Google
als Suchmaschine?""
											Jedes Mal bekomme ich 
die gleichen drei Antworten.
											Erstens: ""Weil es funktioniert.""
											Das stimmt, deshalb google ich ja auch.
											Zweitens:
											""Ich kenne keine gute Alternative.""
											Das ist nicht so eine gute Antwort,
und meistens erwidere ich dann:
											""Google doch mal 'Suchmaschine',
											dann findest du bestimmt eine.""
											Und drittens,
											das wird immer ein Schüler sagen:
											""Mit Google kann ich mir sicher sein,

											immer das beste, 
wertneutralste Ergebnis zu bekommen.""
											Sicher sein, immer das beste, 
wertfreie Suchergebnis zu bekommen.
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											Now, as a man of the humanities,
											albeit a digital humanities man,
											that just makes my skin curl,
											even if I, too, realize that that trust,
that idea of the unbiased search result
											is a cornerstone in our collective love
for and appreciation of Google.
											I will show you why that, philosophically,
is almost an impossibility.
									","
											Enquanto homem de Humanidades.
											apesar de ser uma pessoa
de Humanidades Digitais,
											fico todo arrepiado,
											embora eu também perceba
que essa confiança,
											essa ideia de resultado
imparcial de pesquisa
											seja uma pedra basilar no nosso amor
e apreciação coletiva do Google.
											Vou mostrar-vos porque é que,
filosoficamente, isso é quase impossível.
									","
											Bir beşeri bilim insanı olarak,
											hatta dijital insani bilim insanı olarak,
											bu durum beni ürpertiyor,
											bu önyargısız arama sonucuna güvenin, 
Google’a olan ortak sevgimizin ve
											ve Google'ı takdirimizin
köşetaşı olmasını anlayabilsem bile.
											Size bunun felsefi açıdan neden
neredeyse imkansız olduğunu göstereceğim.
									","
											Da ich aus den
Geisteswissenschaften komme,
											wenn auch aus den digitalen,
											läuft mir bei dieser Antwort
ein Schauer über den Rücken.
											Ich verstehe zwar, dass diese Sicherheit,
die Idee des wertneutralen Ergebnisses,
											der Grundstein unserer Liebe 
und Wertschätzung für Google ist.
											Aber ich werde Ihnen zeigen, warum das
schon rein theoretisch nicht möglich ist.
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											But let me first elaborate,
just a little bit, on a basic principle
											behind each search query
that we sometimes seem to forget.
											So whenever you set out
to Google something,
											start by asking yourself this:
""Am I looking for an isolated fact?""
											What is the capital of France?
											What are the building blocks
of a water molecule?
											Great — Google away.
											There's not a group of scientists
who are this close to proving
											that it's actually London and H30.
											You don't see a big conspiracy
among those things.
											We agree, on a global scale,
											what the answers are
to these isolated facts.
									","
											Mas, primeiro, vou refletir um pouco
sobre um princípio básico
											por detrás de cada pesquisa,
que por vezes esquecemos.
											Sempre que se dispuserem a usar o Google,
comecem por pensar nisto:
											""Estou à procura de um facto isolado?
											""Qual é a capital da França?
											""Quais são os elementos constitutivos
duma molécula da água?""
											Ótimo... Google para a frente.
											Não há nenhum grupo de cientistas 
que estejam dispostos a provar
											que é Londres e H3O.
											Não vemos nenhuma 
conspiração nestas coisas.
											Numa escala global, estamos de acordo
											quanto às respostas 
para este tipo de factos isolados.
									","
											Ancak ilkin, her sorgumuzun ardındaki,
bazen görmeyi unuttuğumuz
											temel kuralı kısaca açıklamama izin verin.
											Google’a bir şey yazdığınız zaman,
											kendinize şunu sorun: 
“kesin bir gerçekliği mi arıyorum?""
											Fransa’nın başkenti neresidir?
											Su molekülünün yapıtaşları nelerdir?
											Harika, hemen Google-layın.
											Cevapların Londra ve H3O olduğunu
											ispatlamaya çalışan
bilim insanları yoktur.
											Bu tür şeylerde büyük
komplolara rastlamazsınız.
											Küresel ölçekli
											kesin gerçekliklerin cevabı ne ise ,
hepimiz kabul ederiz.
									","
											Zuerst müssen wir uns dafür 
ein Prinzip genauer anschauen,
											das hinter jedem Suchvorgang steckt
und das wir gerne vergessen.
											Wann immer Sie etwas googeln,
											fragen Sie sich zuerst:
""Suche ich nach einem isolierten Fakt?""
											Was ist die Hauptstadt von Frankreich?
											Was sind die Teile eines Wassermoleküls?
											Super — dann können Sie googeln.
											Es gibt keine Wissenschaftler,
die kurz davor stehen, zu beweisen,
											dass das in Wirklichkeit 
London und H3O ist.
											Hier gibt es keine Uneinigkeiten.
											Wir sind uns alle einig, was die Antworten
auf diese isolierten Fakten sind.
											Wenn Sie jetzt Ihre Frage 
ein wenig komplizierter stellen
											und zum Beispiel fragen:
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											But if you complicate your question
just a little bit and ask something like,
											""Why is there
an Israeli-Palestine conflict?""
											You're not exactly looking
for a singular fact anymore,
											you're looking for knowledge,
											which is something way more
complicated and delicate.
											And to get to knowledge,
											you have to bring 10 or 20
or 100 facts to the table
											and acknowledge them and say,
""Yes, these are all true.""
											But because of who I am,
											young or old, black or white,
gay or straight,
											I will value them differently.
											And I will say, ""Yes, this is true,
											but this is more important
to me than that.""
											And this is where it becomes interesting,
											because this is where we become human.
											This is when we start
to argue, to form society.
											And to really get somewhere,
we need to filter all our facts here,
											through friends and neighbors
and parents and children
											and coworkers and newspapers
and magazines,
											to finally be grounded in real knowledge,
											which is something that a search engine
is a poor help to achieve.
									","
											Mas, se complicarem um pouco
a pergunta e perguntarem:
											""Porque é que há
um conflito israelo-palestino?""
											já não estão propriamente a procurar 
um facto singular,
											estão a procurar conhecimentos,
											o que é uma coisa
mais complicada e delicada.
											Para chegar ao conhecimento
											precisamos de pôr em cima da mesa
10 ou 20 ou 100 factos,
											analisá-los e dizer:
""Sim, estes são todos verdadeiros"".
											Mas, consoante eu seja
											novo ou velho, negro ou branco,
""gay"" ou hetero,
											avalio-los de modo diferente e digo:
											""Sim, isto é verdade, mas, para mim,
isto é mais importante do que aquilo"".
											É aqui que as coisas
se tornam interessantes,
											porque é aqui que nos tornamos humanos.
											É aqui que começamos a argumentar,
a formar sociedade.
											Para chegar a algum lado, é preciso
filtrar todos os nossos factos
											com os amigos e vizinhos, 
com os pais e os filhos
											e colegas e jornais e revistas,
											para finalmente chegarmos
a um conhecimento real,
											coisa que um motor de busca
dificilmente consegue.
									","
											Ancak sorunuzu biraz daha
karmaşıklaştırırsanız:
											“Neden İsrail – Filistin 
çatışması var?” gibi,
											artık kesin kabul görmüş
bir gerçeklik aramıyorsunuz,
											bir bilgiyi araştırıyorsunuz,
											ki bu daha karmaşık 
ve hassas bir şeydir.
											Bu bilgiye ulaşmak için,
											masaya 10 veya 20 
veya 100 gerçeklik getirmek,
											onları kabul etmek ve 
“Bunların hepsi doğru.” demelisiniz.
											Fakat kim olduğuma göre,
											genç, yaşlı, siyah,
beyaz, eşcinsel ya da değil,
											her birini farklı değerlendireceğim.
											“Evet bu doğru, ancak
											diğeri benim için
daha önemli.” diyeceğim.
											İşin ilginç tarafı tam burası,
											çünkü bizi insan yapan şey de bu.
											Toplumu şekillendirmek için 
tartışmaya başladığımız yer burası.
											Bir yerlere varmak için 
gerçeklerimizi filtrelememiz gerekir.
											Arkadaşlar, komşular,
aileler, çocuklar,
											iş arkadaşları, gazeteler,
dergiler yardımıyla.
											Sonuçta gerçek bilgiye ulaşmak için,
											bir arama motorunun bunu başarmanızda
çok az yardımı olabilecektir.
									","
											""Warum gibt es einen Konflikt
zwischen Israel und Palästina?""
											suchen Sie nicht mehr nach einem Fakt,
											sondern nach Wissen,
											das viel komplizierter und heikler ist.
											Um Wissen zu erlangen,
											müssen Sie 10, 20, 100 Fakten sammeln,
											ihnen zustimmen und sagen können,
""Ja, die sind alle wahr.""
											Aber durch das, was ich bin,
											jung oder alt, weiß oder schwarz, 
homo- oder heterosexuell,
											bewerte ich jeden Fakt unterschiedlich.
											Ich werde sagen: ""Ja, das stimmt,
											aber das hier ist wichtiger für mich.""
											Ab da wird's interessant,
											weil wir ab dem Punkt menschlich werden.
											An diesem Punkt fangen wir an,
zu diskutieren, Gesellschaften zu formen.
											Um wirklich etwas zu erreichen, 
müssen wir alle Fakten filtern,
											durch unsere Freunde und Nachbarn,
Eltern und Kinder, Kollegen,
											Zeitungen und Zeitschriften.
											Erst dann haben wir echtes Wissen,
											bei dem uns eine Suchmaschine
eigentlich nicht helfen kann.
											Ich sprach von einem Beispiel,
um zu zeigen, warum es so schwierig ist,
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											So, I promised you an example
just to show you why it's so hard
											to get to the point of true, clean,
objective knowledge —
											as food for thought.
											I will conduct a couple of simple
queries, search queries.
											We'll start with ""Michelle Obama,""
											the First Lady of the United States.
											And we'll click for pictures.
											It works really well, as you can see.
											It's a perfect search
result, more or less.
											It's just her in the picture,
not even the President.
									","
											Prometi-vos um exemplo, só para mostrar
porque é tão difícil
											chegar ao ponto da verdade, nua e crua,
de um conhecimento objetivo,
											como alimento para o pensamento.
											Vou fazer algumas pesquisas simples.
											Vamos começar com ""Michelle Obama"",
											a primeira dama dos EUA.
											E clicamos em imagens.
											Funciona mesmo bem, como podem ver.
											É um resultado de pesquisa perfeito,
mais ou menos.
											É só ela na imagem, 
sem sequer o Presidente.
									","
											Doğru, açık ve tarafsız bilgiyi 
elde etmenin neden
											bu kadar zor olduğunu 
bir örnekle size göstermek istiyorum.
											Konu üzerinde düşünmek için.
											Bazı basit arama sorguları
yapacağım.
											""Michelle Obama"" ile başlayacağız.
											ABD'nin first lady’si.
											Görsellere tıklayacağız.
											Gördüğünüz üzere oldukça iyi çalışıyor.
											Neredeyse mükemmel bir arama sonucu.
											Resimde sadece o var, 
başkan bile yok.
									","
											dieses objektive, reine,
wahre Wissen zu erlangen —
											sozusagen als Denkanstoß.
											Ich werde einfache Suchanfragen starten.
											Fangen wir mit ""Michelle Obama"" an,
											der First Lady der USA.
											Wir suchen nach Bildern.
											Das funktioniert super, wie man sieht.
											Es sind ziemlich perfekte Suchergebnisse.
											Nur Michelle ist im Bild, 
nicht mal der Präsident.
											Wie funktioniert das?
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											How does this work?
											Quite simple.
											Google uses a lot of smartness
to achieve this, but quite simply,
											they look at two things
more than anything.
											First, what does it say in the caption
under the picture on each website?
											Does it say ""Michelle Obama""
under the picture?
											Pretty good indication
it's actually her on there.
											Second, Google looks at the picture file,
											the name of the file as such
uploaded to the website.
											Again, is it called ""MichelleObama.jpeg""?
											Pretty good indication it's not
Clint Eastwood in the picture.
											So, you've got those two and you get
a search result like this — almost.
									","
											Como é que isto funciona?
											Muito simples.
											O Google usa muita esperteza 
para conseguir isto, mas é muito simples,
											olha sobretudo para duas coisas.
											Primeiro, o que é que diz na legenda
por baixo da imagem em cada website?
											Diz: ""Michelle Obama"" por baixo da imagem?
											É uma boa indicação de que 
é realmente ela que ali está.
											Segundo, o Google olha
para o ficheiro da imagem,
											para o nome do ficheiro,
tal como carregado no ""website"".
											Chama-se ""MichelleObama.jpeg""?
											Uma boa indicação de que 
não é o Clint Eastwood na imagem.
											Portanto, temos estes dois e obtemos
um resultado de pesquisa como este... quase.
									","
											Nasıl çalışıyor?
											Oldukça basit.
											Bir çok akıllıca yöntem kullanılıyor, 
ama basitleştirirsek,
											iki şeye diğerlerinden daha çok bakıyor.
											İlki, her bir internet sitesinde
resmin altında ne yazdığı.
											Resmin altında 
""Michelle Obama"" mı yazıyor?
											Gerçekten onun olduğuna dair
iyi bir gösterge.
											İkinci olarak Google internet sitesine
											yüklenen resim dosyasının
adına bakıyor.
											""Michelle Obama.jpeg” mi denmiş?
											Resimde Clint Eastwood olmadığına dair
iyi bir gösterge.
											Böylece bu iki yöntemle böyle bir
arama sonucuna ulaştınız — neredeyse.
									","
											Erstaunlich einfach:
											Google ist dabei sehr clever, 
aber um es einfach zu erklären:
											Sie schauen sich zwei Dinge an.
											Erstens: Was sagt die Bildunterschrift?
											Steht ""Michelle Obama"" unter dem Bild?
											Ein gutes Zeichen,
dass wirklich sie im Bild ist.
											Zweitens schaut sich Google
den Dateinamen an,
											also den Namen, unter
dem das Foto hochgeladen wurde.
											Heißt es ""MichelleObama.jpeg""?
											Ein gutes Indiz dafür,
dass es nicht Clint Eastwood ist.
											Man hat also diese beiden Kriterien
und bekommt dieses Ergebnis — fast.
											2009 wurde Michelle Obama 
Opfer einer rassistischen Kampagne,
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											Now, in 2009, Michelle Obama
was the victim of a racist campaign,
											where people set out to insult her
through her search results.
											There was a picture distributed
widely over the Internet
											where her face was distorted
to look like a monkey.
											And that picture was published all over.
											And people published it
very, very purposefully,
											to get it up there in the search results.
											They made sure to write
""Michelle Obama"" in the caption
											and they made sure to upload the picture
as ""MichelleObama.jpeg,"" or the like.
											You get why — to manipulate
the search result.
											And it worked, too.
											So when you picture-Googled
for ""Michelle Obama"" in 2009,
											that distorted monkey picture
showed up among the first results.
									","
											Ora bem, em 2009, Michelle Obama
foi vítima duma campanha racista,
											em que as pessoas se puseram a insultá-la,
através dos resultados de pesquisa.
											Houve uma imagem distribuída
amplamente na Internet
											com a cara dela distorcida
para parecer um macaco.
											Essa imagem foi publicada
por toda a parte.
											As pessoas publicaram-na de propósito
											para que ela aparecesse
no resultado da pesquisa.
											Tiveram o cuidado de escrever 
""Michelle Obama"" na legenda
											e tiveram o cuidado de carregar a imagem
como ""MichelleObama.jpeg"", ou equivalente.
											Porquê? Para manipularem
o resultado da pesquisa.
											E também funcionou.
											Quando, em 2009, procurávamos
no Google imagens de Michelle Obama,
											essa imagem distorcida
aparecia entre os primeiros resultados.
									","
											Michelle Obama 2009 yılında 
arama sonuçları üzerinden
											ona hakaret etmek üzere ayarlanmış 
ırkçı bir kampanyanın mağduruydu.
											İnternette yaygın olarak paylaşılan,
											yüzünün maymuna benzetildiği,
oynanmış bir resim vardı.
											Bu resim her yerde yayınlandı.
											İnsanlar bilinçli bir şekilde,
											o resmin arama sonuçlarında 
çıkması için uğraştılar.
											Resmin başlığına
“Michelle Obama” yazdılar
											ve resmi ""MichelleObama.jpeg” veya benzer 
bir dosya adıyla yüklediler.
											Neden olduğunu anladınız,
arama sonuçlarını manipüle etmek için.
											İşe de yaradı.
											2009'da Google görsellerinde
“Michelle Obama” aratıldığında,
											üzerinde oynanmış o maymun resmi
ilk sonuçlar arasında çıkıyordu.
									","
											in der sie durch ihre Suchergebnisse
beleidigt werden sollte.
											Es gab ein weit verbreitetes Bild,
											in dem ihr Gesicht so entstellt war,
dass sie aussah wie ein Affe.
											Das Bild wurde überall hochgeladen.
											Man hat das sehr strategisch getan,
											um es in die Suchergebnisse zu bekommen.
											Es wurde ""Michelle Obama"" betitelt,
											und man lud es als ""MichelleObama.jpeg"" 
oder etwas ähnliches hoch.
											Sie verstehen, warum —
um die Suchergebnisse zu manipulieren.
											Und das hat tatsächlich funktioniert.
											Wenn man also 2009 
""Michelle Obama"" gegoogelt hat,
											fand man unter den ersten Bildern
auch dieses Affen-Bild.
											Die Ergebnisse bereinigen sich selbst,
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											Now, the results are self-cleansing,
											and that's sort of the beauty of it,
											because Google measures relevance
every hour, every day.
											However, Google didn't settle
for that this time,
											they just thought, ""That's racist
and it's a bad search result
											and we're going to go back
and clean that up manually.
											We are going to write
some code and fix it,""
											which they did.
											And I don't think anyone in this room
thinks that was a bad idea.
											Me neither.
									","
											Ora bem, os resultados
fazem uma auto-limpeza,
											— é o que faz a beleza do sistema —
											porque o Google está sempre
a medir a relevância.
											Mas, dessa vez, o Google 
não se contentou com isso e pensou:
											""Isto é racista, e é um 
mau resultado da pesquisa,
											""vamos limpar isto manualmente.
											""Vamos escrever um código
qualquer e consertar isto"".
											E assim fizeram.
											Penso que ninguém nesta sala acha
que foi uma má ideia.
											Eu também não.
									","
											Sonuçlar kendini yeniliyor
											ve bu işin güzel tarafı,
											çünkü Google her saat, her gün
sonuçların uygunluğunu ölçmektedir.
											Ancak bu sefer Google bununla yetinmedi,
											şöyle düşündüler; 
“bu ırkçı ve kötü bir arama sonucu,
											geriye dönüp bunu elle düzelteceğiz.
											Bazı kodlar yazıp bunu düzelteceğiz.”,
											ki yaptılar da.
											Salonda hiç kimsenin bunun kötü bir fikir 
olduğunu düşündüğünü sanmıyorum.
											Ben de dahil.
									","
											und das ist das Schöne dabei,
											weil Google jede Stunde, jeden Tag,
die Relevanz der Ergebnisse misst.
											Dieses Mal ging Google aber weiter,
											da sie fanden: ""Das ist rassistisch
und ein schlechtes Suchergebnis.
											Wir entfernen das manuell.
											Wir müssen einen Code schreiben,
und das Ganze reparieren.""
											Und das taten sie.
											Ich glaube, niemand hier denkt,
dass das eine schlechte Idee war.
											Ich auch nicht.
											Aber dann, ein paar Jahre später,
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											But then, a couple of years go by,
											and the world's most-Googled Anders,
											Anders Behring Breivik,
											did what he did.
											This is July 22 in 2011,
											and a terrible day in Norwegian history.
											This man, a terrorist, blew up
a couple of government buildings
											walking distance from where we are
right now in Oslo, Norway
											and then he traveled
to the island of Utøya
											and shot and killed a group of kids.
											Almost 80 people died that day.
									","
											Mas depois, passaram uns anos
											e Anders Behring Breivik,
											o Anders mais procurado no Google,
											fez o que fez.
											Foi a 22 de julho de 2011,
											um dia terrível na história da Noruega.
											Este homem, um terrorista, fez explodir
alguns edifícios governamentais
											perto do sítio onde nos encontramos
em Oslo, na Noruega.
											Depois, foi para a ilha de Utøya
											e matou a tiro um grupo de jovens.
									","
											Ancak birkaç yıl sonra,
											dünyanın en çok Google-lanan Anders’i,
											Anders Behring Breivik,
											yapacağını yaptı.
											22 Temmuz 2011’de
											Norveç tarihinin korkunç günlerinden biri.
											Terörist olan bu adam Oslo, Norveç'te
şu an bulunduğumuz yere
											yürüme mesafesinde olan bazı
devlet binalarını havaya uçurdu;
											ve sonra Utøya Adasına gitti,
											bir grup çocuğa ateş etti 
ve onları öldürdü.
											80'e yakın kişi o gün öldü.
									","
											tat der meist gegoogelte Anders,
											Anders Behring Breivik,
											was er tat.
											Das war am 22. Juli 2011,
											einem schrecklichen Tag für Norwegen.
											Dieser Mann, ein Terrorist,
jagte einige Regierungsgebäude hoch,
											in Gehweite von hier, wo wir grade sind,
in Oslo, Norwegen,
											und fuhr dann auf die Insel Utøya,
											schoss auf und tötete eine Gruppe Kinder.
											Fast 80 Menschen starben an diesem Tag.
											Viele würden diesen Terrorakt
in zwei Schritten beschreiben:
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											And a lot of people would describe
this act of terror as two steps,
											that he did two things: he blew up
the buildings and he shot those kids.
											It's not true.
											It was three steps.
											He blew up those buildings,
he shot those kids,
											and he sat down and waited
for the world to Google him.
											And he prepared
all three steps equally well.
									","
											Morreram quase 80 pessoas nesse dia.
											Muita gente pensou que este ato
de terrorismo teve duas fases:
											fazer explodir os edifícios
e matar aqueles jovens.
											Não é verdade.
											Foram três fases.
											Fez explodir os edifícios,
matou aqueles jovens,
											sentou-se e esperou que o mundo
o procurasse no Google.
									","
											Birçok insan bu terör hadisesini 
iki aşamalı tasvir ediyor,
											binaları patlattı ve o çocukları öldürdü.
											Bu doğru değil.
											Üç aşamalı idi.
											O binaları patlattı, o çocukları öldürdü
											ve oturup dünyanın 
onu Google-lamasını bekledi.
											Üç aşamayı da oldukça iyi hazırladı.
									","
											Er jagte die Gebäude in die Luft
und erschoss die Kinder.
											Aber das stimmt nicht.
											Es gab drei Schritte.
											Er jagte die Gebäude in die Luft, 
erschoss die Kinder,
											und wartete, dass die Welt ihn googelt.
											Jeden dieser Schritte 
bereitete er sorgfältig vor.
											Und wenn das einer sofort verstanden hat,
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											And if there was somebody
who immediately understood this,
											it was a Swedish web developer,
											a search engine optimization expert
in Stockholm, named Nikke Lindqvist.
											He's also a very political guy
											and he was right out there
in social media, on his blog and Facebook.
											And he told everybody,
											""If there's something that
this guy wants right now,
											it's to control the image of himself.
											Let's see if we can distort that.
											Let's see if we, in the civilized world,
can protest against what he did
											through insulting him
in his search results.""
									","
											E preparou igualmente bem
todas essas três fases.
											Houve alguém que percebeu
isto imediatamente,
											um programador sueco, Nikke Lindqvist.
											um especialista de otimização
de motores de busca, em Estocolmo.
											É também um tipo muito político.
											Saltou logo para as redes sociais,
no seu blogue e no Facebook.
											Disse a toda a gente:
											""O que este tipo quer, neste momento,
é controlar a própria imagem.
											""Vejamos se podemos contrariar isso.
											""Vejamos se nós, no mundo civilizado,
podemos protestar contra o que ele fez
									","
											Eğer bunu hemen anlayan biri varsa,
											o da İsveçli
internet tasarımcısı,
											Stockholm’de arama motoru optimizasyonu
uzmanı olan Nikke Lindqvist'tir.
											Aynı zamanda oldukça
siyasi birisiydi.
											sosyal medyada bloğunu ve 
Facebook'u aktif kullanan biriydi.
											Herkese şunu dedi:
											“Şu anda bu adamın
yapmak istediği bir şey varsa,
											o da kendi imajını kontrol etmektir.
											Bunu değiştirebilecek miyiz görelim.
											Bakalım yaptığı eylemi medeni dünya olarak
kendi arama sonuçlarında
											ona hakaret ederek 
protesto edebilecek miyiz?”
									","
											dann war das ein
schwedischer Webentwickler
											und Suchmaschinen-Optimierungs-Experte
aus Stockholm, Nikke Linqvist.
											Er ist auch politisch engagiert
											und war an jenem Tag in seinem Blog
und auf Facebook sehr aktiv.
											Er sagte allen:
											""Wenn es eines gibt, was dieser Kerl will,
											dann ist es, sein Bild zu kontrollieren.
											Mal sehen, ob wir es verzerren können.
											Mal sehen, ob wir, die Zivilisierten,
gegen das, was er getan hat,
											protestieren können, indem wir ihn
durch seine Suchergebnisse beleidigen.""
											Wie ging das?
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											And how?
											He told all of his readers the following,
											""Go out there on the Internet,
											find pictures of dog poop on sidewalks —
											find pictures of dog poop on sidewalks —
											publish them in your feeds,
on your websites, on your blogs.
											Make sure to write the terrorist's
name in the caption,
											make sure to name
the picture file ""Breivik.jpeg.""
											Let's teach Google that that's
the face of the terrorist.""
											And it worked.
											Two years after that campaign
against Michelle Obama,
											this manipulation campaign
against Anders Behring Breivik worked.
											If you picture-Googled for him weeks after
the July 22 events from Sweden,
											you'd see that picture of dog poop
high up in the search results,
											as a little protest.
									","
											""insultando-o nos resultados da pesquisa.""
											Mas como?
											Ele disse o seguinte
a todos os seus leitores:
											""Vão à Internet,
											""procurem imagens
de cocó de cão nos passeios,
											""encontrem imagens 
de cocó de cão nos passeios,
											""publiquem-nas nos vossos 
websites, nos vossos blogues.
											""Não se esqueçam de escrever
o nome do terrorista na legenda,
											""não se esqueçam de pôr o nome
'Breivik.jpeg' no ficheiro da imagem.
											""Vamos ensinar ao Google
que é esse o rosto do terrorista"".
											E funcionou.
											Dois anos depois da campanha
contra Michelle Obama,
											esta campanha de manipulação 
contra Anders Behring Breivik funcionou.
											Quem procurou imagens dele no Google,
depois de 22 de julho na Suécia,
											viu que as imagens de cocó de cão
apareciam nos resultados da pesquisa,
									","
											Peki nasıl?
											Tüm okurlarına şunları dedi,
											“İnternete girin,
											kaldırım üzerinde 
köpek dışkısı resimleri bulun —
											kaldırım üzerinde 
köpek dışkısı resimleri bulun —
											yayınlarınızda, internet sitelerinizde ve
bloglarınızda bunu yayınlayın.
											Resmin altına teröristin ismini 
yazdığınızdan emin olun,
											resim dosyasının adının 
“Breivik.jpeg” olduğundan emin olun.
											Google’a teröristin yüzünün 
bu olduğunu öğretelim.”
											Ve işe yaradı.
											Michelle Obama’ya karşı yürütülen 
kampanyadan iki yıl sonra,
											Anders Behring Breivik'e karşı
manipülasyon kampanyası işe yaradı.
											22 Temmuz'dan bir süre sonra İsveç’ten 
Google görsellerinde onu aratsaydınız,
											arama sonuçlarının üst kısımlarında 
köpek dışkısı resmini görebilirdiniz,
											küçük bir protesto olarak.
									","
											Er sagte all seinen Lesern Folgendes:
											""Geht ins Internet,
											sucht Bilder von Hundehaufen —
											sucht Bilder von Hundehaufen —
											und ladet sie bei euch hoch,
auf euren Websites und Blogs.
											Stellt sicher, dass ihr seinen Namen
als Überschrift benutzt,
											und die Datei ""Breivik.jpeg"" nennt.
											Lasst uns Google beibringen, dass das
das Gesicht des Terroristen ist.""
											Es hat funktioniert.
											Zwei Jahre nach Michelle Obama
											funktionierte diese Kampagne 
gegen Anders Behring Breivik.
											Googelte man ihn in den Wochen danach,
											sah man unter den ersten Bild-Ergebnissen
diese Hundehaufen als Protest.
											Seltsamerweise schritt Google
dieses Mal nicht ein.
											Die Suchergebnisse wurden
nicht manuell bereinigt.
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											Strangely enough, Google
didn't intervene this time.
											They did not step in and manually
clean those search results up.
											So the million-dollar question,
											is there anything different
between these two happenings here?
											Is there anything different between
what happened to Michelle Obama
											and what happened
to Anders Behring Breivik?
											Of course not.
											It's the exact same thing,
											yet Google intervened in one case
and not in the other.
									","
											como um pequeno protesto.
											Estranhamente, o Google
dessa vez não interferiu.
											Não limparam manualmente
os resultados da pesquisa.
											Então, a pergunta de ouro,
											""Há alguma diferença
entre estes dois acontecimentos?""
											""Há alguma diferença entre
o que aconteceu a Michelle Obama
											""e o que aconteceu 
a Anders Behring Breivik?""
											Claro que não.
											Foi exatamente a mesma coisa.
									","
											Garip bir şekilde 
Google bu kez müdahale etmedi.
											Devreye girip arama sonuçlarını 
elle düzeltmediler.
											Şimdi milyon dolarlık soru,
											bu iki hadise arasında fark var mı?
											Michelle Obama’ya yapılan ile 
Anders Behring Breivik’e yapılan
											eylem arasında bir fark var mı?
											Elbetteki yok.
											Kesinlikle aynı şey
											ama bir durumda Google müdahale etti, 
diğerinde ise etmedi.
									","
											Die Eine-Millionen-Dollar-Frage ist:
											Gibt es irgendeinen Unterschied
zwischen den beiden Kampagnen?
											Ist das, was Michelle Obama passierte,
											anders als das, was Anders
Behring Breivik passierte?
											Natürlich nicht.
											Es ist genau das Gleiche,
											aber Google schritt nur in einem Fall ein.
											Warum?
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											Why?
											Because Michelle Obama
is an honorable person, that's why,
											and Anders Behring Breivik
is a despicable person.
											See what happens there?
											An evaluation of a person takes place
											and there's only one
power-player in the world
											with the authority to say who's who.
											""We like you, we dislike you.
											We believe in you,
we don't believe in you.
											You're right, you're wrong.
You're true, you're false.
											You're Obama, and you're Breivik.""
											That's power if I ever saw it.
									","
											No entanto, o Google interveio
num caso e não no outro.
											Porquê?
											Porque Michelle Obama 
é uma pessoa respeitável, é por isso,
											e Anders Behring Breivik
é uma pessoa ignóbil.
											Estão a ver o que acontece aqui?
											Fez-se um juízo de valor duma pessoa
											e só há um todo-poderoso no mundo
com autoridade para dizer quem é quem.
											""Gosto de ti, não gosto de ti.
											""Acredito em ti, em ti não.
											""Tens razão, tu não.
Estás certo, estás errado.
											""És o Obama, e tu és o Breivik.""
									","
											Neden?
											Çünkü Michelle Obama 
saygıdeğer bir insan, sebep bu
											ve Anders Breivik ise aşağılık bir insan.
											Ne olduğunu anlıyor musunuz?
											Bir kişi değerlendiriliyor
											ve dünya üzerinde kimin kim olduğunu
											söyleme otoritesine sahip
tek bir güç var.
											""Seni seviyoruz. Seni sevmiyoruz.
											Sana inanıyoruz. Sana inanmıyoruz.
											Haklısın. Haksızsın. 
Doğrusun. Yanlışsın.
											Obama'sın. Breivik'sin.”
											Bu, eğer şu ana kadar
gördüysem, gücün kendisidir.
									","
											Weil Michelle Obama 
eine ehrhafte Person ist,
											und Anders Behring Breivik 
eine verabscheuenswürdige.
											Sehen Sie, was passiert?
											Es findet eine Bewertung statt,
											und es gibt nur einen
Power-Player in der Welt,
											der die Autorität hat, zu sagen,
wer gut und wer schlecht ist.
											""Wir mögen dich. Dich mögen wir nicht.
											Wir glauben an dich, aber nicht an dich.""
											""Du hast Recht, du nicht.
											Du bist Obama, und du bist Breivik.""
											Das ist wahre Macht.
											Ich möchte, dass Ihnen bewusst wird,
dass hinter jedem Algorithmus
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											So I'm asking you to remember
that behind every algorithm
											is always a person,
											a person with a set of personal beliefs
											that no code can ever
completely eradicate.
											And my message goes
out not only to Google,
											but to all believers in the faith
of code around the world.
											You need to identify
your own personal bias.
											You need to understand that you are human
											and take responsibility accordingly.
									","
											Esse é um poder sem igual.
											Portanto, peço-vos que se lembrem 
de que, por detrás de cada algoritmo,
											está sempre uma pessoa,
											uma pessoa com um conjunto
de crenças pessoais
											que nenhum código
consegue eliminar totalmente.
											A minha mensagem não se dirige
exclusivamente ao Google,
											mas a todos os que acreditam
na fé do código, pelo mundo inteiro.
											Precisamos de identificar
os nossos preconceitos pessoais.
											Precisamos de perceber
que somos seres humanos
									","
											Sizden şunu hatırlamanızı rica ediyorum:
her algoritmanın ardında
											her zaman bir insan vardır.
											Hiçbir kodun tamamen yok edemeyeceği
											bir takım kişisel değerleri olan birisi.
											Mesajım sadece Google’a değil,
											aynı zamanda kodların 
doğruluğuna inananlaradır.
											Kişisel önyargılarınızı 
belirlemek zorundasınız.
											İnsan olduğunuzu anlamanız
											ve sorumluluğu ona göre almanız
gerekiyor.
									","
											immer eine Person sitzt,
											eine Person mit individuellen Meinungen,
											die kein Code jemals entfernen kann.
											Meine Botschaft gilt nicht nur Google,
											sondern allen, die fest an Codes glauben.
											Sie müssen Ihre eigenen Neigungen einsehen
											und verstehen, dass Sie ein Mensch sind
											und dementsprechend handeln.
											Ich bin der Meinung, dass wir
an einem Punkt angelangt sind,
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											And I say this because I believe
we've reached a point in time
											when it's absolutely imperative
											that we tie those bonds
together again, tighter:
											the humanities and the technology.
											Tighter than ever.
											And, if nothing else, to remind us
that that wonderfully seductive idea
											of the unbiased, clean search result
											is, and is likely to remain, a myth.
									","
											e assumir essa responsabilidade,
em conformidade com isso.
											Digo isto porque acredito
que chegámos a um ponto
											em que é totalmente imperativo
											que voltemos a ligar estes laços,
mais apertados ainda,
											as humanidades e a tecnologia.
											Mais apertados do que nunca.
											E, pelo menos, lembrarmo-nos de que
essa ideia maravilhosamente sedutora
											de resultados de pesquisa 
limpos, imparciais,
									","
											Bunu şunun için söylüyorum:
öyle bir noktaya geldik ki
											kesinlikle şu iki şeyi
											sıkı bir şekilde tekrar bağlamak 
zorundayız, daha sıkı bir şekilde:
											beşeri bilim ve teknolojiyi.
											Şimdiye kadarkinden 
daha da sıkı.
											Bir de muhteşem bir şekilde 
cezbediciliği olan
											önyargısız, temiz arama sonucu
fikrinin bir efsane olduğunu
											hatırlatmak istiyorum.
									","
											an dem es absolut notwendig wird,
											dass wir diese Verknüpfungen
immer enger machen:
											Technik und Geisteswissenschaften.
											Enger als je zuvor,
											nicht zuletzt, um uns daran zu erinnern, 
dass diese so verlockende Idee,
											eines wertfreien Suchergebnisses
ein Mythos ist,
											und wahrscheinlich auch bleiben wird.
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											Thank you for your time.
									","
											é, e provavelmente
continuará a ser, um mito.
									","
											Zamanınızı ayırdığınız
için teşekkürler.
									","
											Vielen Dank.
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
											(Applause)
									","
											Obrigado pelo vosso tempo.
											(Aplausos)
									","
											(Alkış)
									","
											(Applaus)
									",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
"
","
","
","
",The moral bias behind your search results,Andreas Ekström,9:18,"TEDx,algorithm,communication,decision-making,society,Google,Internet,software,technology,web,computers"
