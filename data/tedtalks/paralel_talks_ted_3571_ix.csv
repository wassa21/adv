tr,en,title,speaker,duration,tags
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Birçoğumuzun muzdarip olduğu
											bir önsezi yetersizliğinden bahsedeceğim.
											Belirli tür bir tehlikeyi
sezmek gerçekten bir yetersizliktir.
											Bir senaryo anlatacağım,
											korkunç olduğunu düşündüğüm
											ve gerçekleşmesi muhtemel olan
											ve görünen o ki
											iyi bir kombinasyon da değil.
											Yine de korkmak yerine
çoğunuz, bahsettiklerimin
											havalı olduğunu düşüneceksiniz.
									","
											I'm going to talk
about a failure of intuition
											that many of us suffer from.
											It's really a failure
to detect a certain kind of danger.
											I'm going to describe a scenario
											that I think is both terrifying
											and likely to occur,
											and that's not a good combination,
											as it turns out.
											And yet rather than be scared,
most of you will feel
											that what I'm talking about
is kind of cool.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Yapay zekâdaki kazanımlarımızın
											nihayetinde bizi nasıl 

											mahvedeceğinden bahsedeceğim.
											Hatta bence, bizi mahvetmeyeceğini
veya kendimizi mahvetmeyi bize
											aşılamayacağını düşünmek çok güç.
											Fakat sizler de benim gibiyseniz,
											bunları düşünmenin zevkli
olacağını keşfedeceksiniz.
											Ve bu yanıtta sorunun bir parçası.
											Bu yanıt sizi endişelendirmeli.
											Bu konuşmada sizi, olası bir
küresel bir kıtlığa,
											iklim değişikliği veya 
başka bir afetten dolayı,
											torunlarınız veya 
onların torunlarının muhtemelen
											bu şekilde yaşama durumuna
											yakın olduğuna ikna ediyor olsaydım,
											""İlginç.
											Bu TED konuşmasını beğendim.""
											diye düşünmezdiniz.
									","
											I'm going to describe
how the gains we make
											in artificial intelligence
											could ultimately destroy us.
											And in fact, I think it's very difficult
to see how they won't destroy us
											or inspire us to destroy ourselves.
											And yet if you're anything like me,
											you'll find that it's fun
to think about these things.
											And that response is part of the problem.
											OK? That response should worry you.
											And if I were to convince you in this talk
											that we were likely
to suffer a global famine,
											either because of climate change
or some other catastrophe,
											and that your grandchildren,
or their grandchildren,
											are very likely to live like this,
											you wouldn't think,
											""Interesting.
											I like this TED Talk.""
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Kıtlık eğlenceli değildir.
											Diğer taraftan bilim 
kurgudaki ölüm ise eğlencelidir
											ve bu noktada beni yapay zekâdaki
											en çok endişelendiren gelişmelerden biri,
											önümüzde uzanan tehlikelere,
uygun duyarlı bir yanıtı
											sıralayamıyor gibi görünüyoruz.
											Bu yanıtı sıralayamıyorum ve 
bu konuşmayı yapıyorum.
									","
											Famine isn't fun.
											Death by science fiction,
on the other hand, is fun,
											and one of the things that worries me most
about the development of AI at this point
											is that we seem unable to marshal
an appropriate emotional response
											to the dangers that lie ahead.
											I am unable to marshal this response,
and I'm giving this talk.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											İki kapının önünde duruyoruz gibi.
											1 numaralı kapının ardında
											zeki makine üretmedeki
gelişmeleri durduruyoruz.
											Her nedense bilgisayarlarımızın donanım
											ve yazılımı daha iyi olmayı durduruyor.
											Şimdi bir dakikanızı ayırın ve bunun
											neden olabileceğini değerlendirin.
											Yani, zekâ ve otomasyonun ne kadar
											değerli olduğu göz önüne alındığında,
											yapabilirsek, teknolojimizi geliştirmeye
devam edeceğiz.
											Bunu yapmamızı ne engelleyebilir?
											Büyük çaplı bir nükleer savaş mı?
											Küresel bir salgın mı?
											Asteroit çarpması mı?
											Justin Bieber'in Amerika Başkanı 
olması mı?
									","
											It's as though we stand before two doors.
											Behind door number one,
											we stop making progress
in building intelligent machines.
											Our computer hardware and software
just stops getting better for some reason.
											Now take a moment
to consider why this might happen.
											I mean, given how valuable
intelligence and automation are,
											we will continue to improve our technology
if we are at all able to.
											What could stop us from doing this?
											A full-scale nuclear war?
											A global pandemic?
											An asteroid impact?
											Justin Bieber becoming
president of the United States?
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Kahkahalar)
									","
											(Laughter)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Mesele şu ki, bildiğimiz üzere
											bir şeyler medeniyeti yok etmeli.
											Ne kadar kötü
olabileceğini hayal etmelisiniz,
											teknolojimizde iyileştirme 
yapmamızı engellemenin,
											daimi olarak,
											nesilden nesile.
											Neredeyse, doğası gereği
											bu, insan tarihinde gerçekleşen
en kötü şey.
									","
											The point is, something would have to
destroy civilization as we know it.
											You have to imagine
how bad it would have to be
											to prevent us from making
improvements in our technology
											permanently,
											generation after generation.
											Almost by definition,
this is the worst thing
											that's ever happened in human history.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Bu yüzden tek alternatif,
											ikinci kapının ardındaki,
											akıllı makinelerimizi yıllar geçtikçe
											geliştirmeye devam etmemiz.
											Bir noktada da bizden daha 
akıllı makineler inşa edeceğiz
											ve bizden akıllı makinelerimiz
olduğunda onlar,
											kendilerini geliştirmeye başlayacaklar.
											Ve sonra, matematikçi IJ Good'un
""zekâ patlaması"" olarak
											adlandırdığı bu süreçle,
											bizden kurtulabilecekler.
									","
											So the only alternative,
											and this is what lies
behind door number two,
											is that we continue
to improve our intelligent machines
											year after year after year.
											At a certain point, we will build
machines that are smarter than we are,
											and once we have machines
that are smarter than we are,
											they will begin to improve themselves.
											And then we risk what
the mathematician IJ Good called
											an ""intelligence explosion,""
											that the process could get away from us.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Sıklıkla karikatürize edilir,
benim de burada yaptığım gibi,
											korku kötücül robot ordularının
											bize saldırmaları.
											Ama bu çok da olası bir senaryo değil.
											Kendiliğinden makinelerimiz
kötücül olacak değil.
											Asıl kaygılandıran ise;
bizden o kadar çok daha yetkin
											makineler üreteceğiz ki bizim ve onların
											amaçları arasındaki 
en küçük bir fark, bizi
											ortadan kaldırabilecek.
									","
											Now, this is often caricatured,
as I have here,
											as a fear that armies of malicious robots
											will attack us.
											But that isn't the most likely scenario.
											It's not that our machines
will become spontaneously malevolent.
											The concern is really
that we will build machines
											that are so much
more competent than we are
											that the slightest divergence
between their goals and our own
											could destroy us.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Nasıl da karıncalar gibi
olacağımızı bir düşünün.
											Onlardan nefret etmiyoruz.
											Onlara zarar vermek için
yolumuzu değiştirmiyoruz.
											Üstelik bazen onlara zarar
vermemeye çalışıyoruz.
											Kaldırımlarda üzerlerinden geçiyoruz.
											Ancak ne zaman onların varlıkları
											bizim hedeflerimizle çakışsa,
											diyelim ki bu gibi bir bina inşa ederken,
											tereddütsüz imha edebiliyoruz onları.
											Endişe uyandıran ise bir gün,
bilinçli olsun veya olmasın
											bize de benzer bir umursamazlıkla
muamele edebilecek
											makineler üreteceğiz.
									","
											Just think about how we relate to ants.
											We don't hate them.
											We don't go out of our way to harm them.
											In fact, sometimes
we take pains not to harm them.
											We step over them on the sidewalk.
											But whenever their presence
											seriously conflicts with one of our goals,
											let's say when constructing
a building like this one,
											we annihilate them without a qualm.
											The concern is that we will
one day build machines
											that, whether they're conscious or not,
											could treat us with similar disregard.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Zannederim ki bir çoğunuza ihtimal
dışı görünüyor bu durum.
											Eminim ki bazılarınız süper zeki
											Yapay Zekâ'nın kaçınılmaz olması
şöyle dursun,
											mümkünlüğünden dahi şüphe duyuyor.
											Ancak sonra ileriki varsayımlardan
											bazılarında bir tuhaflık bulmalısınız.
											Ve sadece üç tanesi var.
									","
											Now, I suspect this seems
far-fetched to many of you.
											I bet there are those of you who doubt
that superintelligent AI is possible,
											much less inevitable.
											But then you must find something wrong
with one of the following assumptions.
											And there are only three of them.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Zekâ, fiziksel sistemlerde
bilgi işleme ile ilgilidir.
											Aslında bu bir varsayımdan biraz fazla.
											Zaten makinelerimizde kısıtlı
zekâyı kurduk ve
											bu makinelerin çoğu çoktan
											üstün insan seviyesinde bir
performansta.
											Ve biliyoruz ki bu mutlak mesele,
											""genel zekâ"" denilen birçok
alanda esneklikle
											düşünebilme yeteneğine sebep olabilir,
											çünkü beyinlerimiz bunu başardı değil mi?
											Yani sadece atomlar var burada
											ve biz gitgide daha zeki 
davranışlar sergileyen atomlar
											sistemi kurmaya devam ettikçe,
											nihayetinde makinelerimize
											genel zekâyı kurabileceğiz,
											engellenmedikçe.
									","
											Intelligence is a matter of information
processing in physical systems.
											Actually, this is a little bit more
than an assumption.
											We have already built
narrow intelligence into our machines,
											and many of these machines perform
											at a level of superhuman
intelligence already.
											And we know that mere matter
											can give rise to what is called
""general intelligence,""
											an ability to think flexibly
across multiple domains,
											because our brains have managed it. Right?
											I mean, there's just atoms in here,
											and as long as we continue
to build systems of atoms
											that display more and more
intelligent behavior,
											we will eventually,
unless we are interrupted,
											we will eventually
build general intelligence
											into our machines.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											İlerlemenin seviyesinin önemli
olmadığının farkına varmak çok mühim,
											çünkü herhangi bir gelişme
bizi sayı çizgisine getirmeye yetebilir.
											Devam etmek için Moore
kanununa gerek yok.
											Üstel bir gelişime ihtiyacımız yok.
											Sadece devam etmeliyiz.
									","
											It's crucial to realize
that the rate of progress doesn't matter,
											because any progress
is enough to get us into the end zone.
											We don't need Moore's law to continue.
We don't need exponential progress.
											We just need to keep going.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											İkinci varsayım ise devam etmemiz.
											Akıllı makinelerimizi geliştirmeye
devam edeceğiz.
											Ve zekânın değeri göz önüne alınırsa,
											yani zekâ ya bütün değer
verdiklerimizin kaynağıdır ya da
											değer verdiğimiz her şeyi
											korumak için ona ihtiyacımız vardır.
											Bizim en değerli kaynağımızdır.
											O yüzden bunu yapmak isteriz.
											Umutsuzca çözmek istediğimiz
problemlerimiz vardır.
											Alzheimer ve kanser gibi
hastalıkları tedavi etmek isteriz.
											Ekonomi sistemlerini anlamak isteriz.
											İklim bilimini ilerletmek isteriz.
											Yani yapabilirsek bunu yapacağız.
											Tren çoktan istasyondan çıktı ve
basılabilecek bir fren yok.
									","
											The second assumption
is that we will keep going.
											We will continue to improve
our intelligent machines.
											And given the value of intelligence —
											I mean, intelligence is either
the source of everything we value
											or we need it to safeguard
everything we value.
											It is our most valuable resource.
											So we want to do this.
											We have problems
that we desperately need to solve.
											We want to cure diseases
like Alzheimer's and cancer.
											We want to understand economic systems.
We want to improve our climate science.
											So we will do this, if we can.
											The train is already out of the station,
and there's no brake to pull.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Velhasıl, zekânın zirvesinde duramayız
											ya da yakınında herhangi bir yerde.
											Ve bu gerçekten mühim bir öngörüdür.
											Durumumuzu istikrarsız yapan ve
											risk hakkındaki sezgilerimizi güvenilmez
kılan bu durum.
									","
											Finally, we don't stand
on a peak of intelligence,
											or anywhere near it, likely.
											And this really is the crucial insight.
											This is what makes
our situation so precarious,
											and this is what makes our intuitions
about risk so unreliable.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Şimdi yaşamış en zeki insanı düşünün.
											Buradaki hemen hemen herkesin
son listesinde John von Neumann vardır.
											Yani, John von Neumann' nın çevresindeki
insanlardaki etkisi,
											zamanının en iyi matematikçileri
ve fizikçileri de dâhil olmak üzere,
											oldukça detaylı olarak hazırlanmış.
											Hakkında anlatılanların yarısı
yarı gerçek ise
											şimdiye dek yaşamış
											en zeki insan olduğuna şüphe yok.
											Öyleyse zekâ spektrumunu bir düşünün.
											Bir tarafta John von Neumann
											ve diğer tarafta siz ve ben.
											Ve bir de tavuk.
									","
											Now, just consider the smartest person
who has ever lived.
											On almost everyone's shortlist here
is John von Neumann.
											I mean, the impression that von Neumann
made on the people around him,
											and this included the greatest
mathematicians and physicists of his time,
											is fairly well-documented.
											If only half the stories
about him are half true,
											there's no question
											he's one of the smartest people
who has ever lived.
											So consider the spectrum of intelligence.
											Here we have John von Neumann.
											And then we have you and me.
											And then we have a chicken.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Gülüşmeler)
									","
											(Laughter)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Pardon, bir tavuk.
									","
											Sorry, a chicken.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Gülüşmeler)
									","
											(Laughter)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Bu konuşmayı gereğinden daha
depresif yapmama gerek yok.
									","
											There's no reason for me to make this talk
more depressing than it needs to be.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Gülüşmeler)
									","
											(Laughter)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Ezici bir üstünlükle olası görünüyor
ancak zekâ spektrumu
											şu anda tasarlayabileceğimizden
daha da ileriye uzanıyor
											ve kendimizden daha zeki
makineler üretirsek
											büyük ihtimalle bu spektrumu
hayal edemeyeceğimiz
											ölçüde keşfedecekler
											ve o ölçüde bizi aşacaklar.
									","
											It seems overwhelmingly likely, however,
that the spectrum of intelligence
											extends much further
than we currently conceive,
											and if we build machines
that are more intelligent than we are,
											they will very likely
explore this spectrum
											in ways that we can't imagine,
											and exceed us in ways
that we can't imagine.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Ve hızın fazileti gereği bunun
doğru olduğunu anlamak önemli.
											Değil mi? Stanford veya MIT'deki
ortalama araştırmacı takımınızdan
											daha zeki olmayan süper zeki 
Yapay Zekâ
											geliştirdiğimizi düşünün.
											Elektronik devreler, 
biyokimyasallardan milyon kez
											daha hızlı çalışır, yani
											bu makine onu yapan beyinlerden
milyon kez daha
											hızlı çalışmalıdır.
											Bir haftalığına çalışmaya ayarlasanız
											ve insan seviyesinde 20.000 yıl 
sürecek zihinsel
											işleri yapacak, haftalarca.
											Engellemek şöyle dursun,
bu tarz bir zihinsel
											ilerlemeyi nasıl durdurabiliriz ki?
									","
											And it's important to recognize that
this is true by virtue of speed alone.
											Right? So imagine if we just built
a superintelligent AI
											that was no smarter
than your average team of researchers
											at Stanford or MIT.
											Well, electronic circuits
function about a million times faster
											than biochemical ones,
											so this machine should think
about a million times faster
											than the minds that built it.
											So you set it running for a week,
											and it will perform 20,000 years
of human-level intellectual work,
											week after week after week.
											How could we even understand,
much less constrain,
											a mind making this sort of progress?
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Endişe uyandıran diğer bir şey ise,
											açıkcası, olabilecek en iyi
senaryoyu düşünün.
											Hiçbir kaygı barındırmayan
bir süper zeki Yapay Zekâ
											tasarımı keşfettiğimizi düşünün.
											İlk seferde en iyi tasarımı bulduk.
											Tam da istenilen şekilde davranan bir
											kâhin bize verilmiş gibi.
											Bu makine müthiş bir işten
tasarruf ettiren bir aygıt olurdu.
											Güneş ışığıyla çalışan, herhangi
bir fiziksel işi yapabilen,
											aşağı yukarı ham maddeleri
											maliyetinde olan makineyi
											yapabilecek makineyi tasarlayabilir.
											Yani insanların yaptığı angarya 
işlerin sonundan bahsediyoruz.
											Aynı zamanda çoğu zihinsel işlerin de
sonundan bahsediyoruz.
									","
											The other thing that's worrying, frankly,
											is that, imagine the best case scenario.
											So imagine we hit upon a design
of superintelligent AI
											that has no safety concerns.
											We have the perfect design
the first time around.
											It's as though we've been handed an oracle
											that behaves exactly as intended.
											Well, this machine would be
the perfect labor-saving device.
											It can design the machine
that can build the machine
											that can do any physical work,
											powered by sunlight,
											more or less for the cost
of raw materials.
											So we're talking about
the end of human drudgery.
											We're also talking about the end
of most intellectual work.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Böyle bir durumda biz
maymunlar ne yapardık?
											Birbirimize masaj yapabilir ve
frizbi oynayabiliriz.
											Biraz LSD ve tartışmaya açık
giysi seçimlerini de ekleyin

											ve bütün dünya Burning
Man (festival) gibi olabilir.
									","
											So what would apes like ourselves
do in this circumstance?
											Well, we'd be free to play Frisbee
and give each other massages.
											Add some LSD and some
questionable wardrobe choices,
											and the whole world
could be like Burning Man.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Gülüşmeler)
									","
											(Laughter)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Şimdi kulağa hoş gelebilir ama
											kendinize şu anki ekonomik
ve siyasi düzenimizde
											ne olabileceğini sorun.
											Daha önce görmediğimiz düzeyde
											eşitsiz bir zenginlik ve işsizliğe
											tanık olurduk gibi görünüyor.
											Bu yeni zenginliği derhal tüm 
insanlığın hizmetine
											sunmadaki isteksizlikle,
											dünyanın geri kalanı açlıktan
ölürken birkaç trilyoner
											ekonomi dergilerimizin
kapaklarını süslüyor olabilir.
									","
											Now, that might sound pretty good,
											but ask yourself what would happen
											under our current economic
and political order?
											It seems likely that we would witness
											a level of wealth inequality
and unemployment
											that we have never seen before.
											Absent a willingness
to immediately put this new wealth
											to the service of all humanity,
											a few trillionaires could grace
the covers of our business magazines
											while the rest of the world
would be free to starve.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Peki ya Ruslar ya da Çinliler,
Silikon Vadisi'ndeki
											bazı şirketlerin üstün zeki 
Yapay Zekâ'yı dağıtmak
											üzere olduğunu duysa ne yaparlardı?
											Karasal ya da siber, bu makine
											tahmin edilemez bir güçle savaş
											çıkarabilecek potansiyelde olurdu.
											Bu kazananın her şeyi
aldığı bir senaryo.
											Buradaki rekabetten 6 ay
ilerde olmak
											minimum 500.000 yıl
											ileride olmaktır.
											Demek ki bu tür bir atılımın
sadece söylentisi bile
											türümüzün çıldırmasına yol açabiliyor.
									","
											And what would the Russians
or the Chinese do
											if they heard that some company
in Silicon Valley
											was about to deploy a superintelligent AI?
											This machine would be capable
of waging war,
											whether terrestrial or cyber,
											with unprecedented power.
											This is a winner-take-all scenario.
											To be six months ahead
of the competition here
											is to be 500,000 years ahead,
											at a minimum.
											So it seems that even mere rumors
of this kind of breakthrough
											could cause our species to go berserk.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Şimdi en korkutucu şeylerden bir tanesi
											bana göre, şu anda,
											Yapay Zekâ araştırmacılarının
güven verici olmak istediklerinde
											söyledikleri şeyler.
											Ve en sık bize endişe etmememiz
											için söylenen neden ise zaman.
											Çok çok uzakta, haberin yok mu?
											Muhtemelen 50 ya da 100 yıl kadar uzakta.
											Bir araştırmacı dedi ki;
											""Yapay Zekâ güvenliği için endişelenmek
											Mars'ta aşırı nüfus artışına
endişelenmek gibi.""
											Bu Silikon Vadisi'nin
											""Sıkmayın tatlı canınızı"" versiyonu.
									","
											Now, one of the most frightening things,
											in my view, at this moment,
											are the kinds of things
that AI researchers say
											when they want to be reassuring.
											And the most common reason
we're told not to worry is time.
											This is all a long way off,
don't you know.
											This is probably 50 or 100 years away.
											One researcher has said,
											""Worrying about AI safety
											is like worrying
about overpopulation on Mars.""
											This is the Silicon Valley version
											of ""don't worry your
pretty little head about it.""
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Gülüşmeler)
									","
											(Laughter)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Zamana referanslamanın
											tamamen yersiz bir deyim
											olduğunu kimse fark etmiyor.
											Zekâ eğer bilgi işlemeden ibaretse
											ve biz makinelerimizi geliştirmeye
devam edersek
											bir tür süper zekâ üreteceğiz.
											Ve güvenli bir biçimde yapmak için
gerekli şartları yaratmanın
											ne kadar süreceği hakkında 
hiçbir fikrimiz yok.
											Bir daha söyleyeyim.
											Güvenli bir biçimde yapmak için
gerekli şartları yaratmanın
											ne kadar süreceği hakkında 
hiçbir fikrimiz yok.
									","
											No one seems to notice
											that referencing the time horizon
											is a total non sequitur.
											If intelligence is just a matter
of information processing,
											and we continue to improve our machines,
											we will produce
some form of superintelligence.
											And we have no idea
how long it will take us
											to create the conditions
to do that safely.
											Let me say that again.
											We have no idea how long it will take us
											to create the conditions
to do that safely.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Ve eğer fark etmediyseniz,
50 yıl eskisi gibi değil artık.
											Bu ay olarak 50 yıl.
											Bu kadar zamandır iPhone var.
											Bu kadar zamandır ""The Simpsons"" 
(Simpsonlar) televizyonda.
											50 yıl, türümüzün karşılaşabileceği
											en büyük zorluklar için
fazla bir zaman değil.
											Bir defa daha uygun duygusal karşılık
vermede başarısız gibiyiz,
											yaklaştığına inanmamız için 
tüm gerekçelere sahipken.
									","
											And if you haven't noticed,
50 years is not what it used to be.
											This is 50 years in months.
											This is how long we've had the iPhone.
											This is how long ""The Simpsons""
has been on television.
											Fifty years is not that much time
											to meet one of the greatest challenges
our species will ever face.
											Once again, we seem to be failing
to have an appropriate emotional response
											to what we have every reason
to believe is coming.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Bilgisayar bilimcisi Stuart Russell'ın 
güzel bir benzetimi var.
											Diyor ki; uzaylı bir medeniyetten
bir mektup aldığımızı düşünün,
											şöyle diyor:
											""Dünya Halkı,
											50 yıl içinde gezegeninize ulaşacağız.
											Hazırlanın.""
											Ve şimdi, ana gemi varana kadar 
ay ay geri mi sayacağız?
											Normalden biraz daha fazla
aciliyet hissederdik.
									","
											The computer scientist Stuart Russell
has a nice analogy here.
											He said, imagine that we received
a message from an alien civilization,
											which read:
											""People of Earth,
											we will arrive on your planet in 50 years.
											Get ready.""
											And now we're just counting down
the months until the mothership lands?
											We would feel a little
more urgency than we do.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Endişelenmememiz söylenen
											bir diğer gerekçe ise
											bu makinelerin istemeden bizim
değerlerimizi paylaşacak
											olmaları, çünkü
bizim devamımız gibi olacaklar.
											Beyinlerimize aşılanacaklar
											ve temelde onların limbik
sistemi olacağız.
											Şimdi bir dakikanızı ayırın ve
											önümüzdeki en sağlam ve ihtiyatlı yolun,
											önerilenin, bu teknolojiyi
											direkt olarak beyinlerimize
											yerleştirmek olduğunu değerlendirin.
											Belki de bu, önümüzdeki en güvenli
ve özenli yol olabilir
											ama genelde kişinin teknoloji hakkındaki 
güvenlik endişelerinin
											kafasının içine bir şey yerleştirmeden
çözülmesi gerekir.
									","
											Another reason we're told not to worry
											is that these machines
can't help but share our values
											because they will be literally
extensions of ourselves.
											They'll be grafted onto our brains,
											and we'll essentially
become their limbic systems.
											Now take a moment to consider
											that the safest
and only prudent path forward,
											recommended,
											is to implant this technology
directly into our brains.
											Now, this may in fact be the safest
and only prudent path forward,
											but usually one's safety concerns
about a technology
											have to be pretty much worked out
before you stick it inside your head.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Kahkahalar)
									","
											(Laughter)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Daha derindeki problem ise süper zeki
YZ geliştirmek başlı başına
											daha kolay gibi görünüyor,
											sorunsuzca zihinlerimizle entegre
											olabilen tamamlanmış sinirbilimli
											bir yapay zekâ geliştirmektense.
											Ve farz edelim ki devletlerin ve 
şirketlerin bunu yapıyorken
											birbirleriyle yarış
içerisindeymişçe algılamaları
											ve bu yarışı kazanmalarının da
dünyayı kazanmak sanmaları,
											peşi sıra mahvetmemek şartıyla,
											sonrasında hangisi en kolaysa
											ilk o yapılacakmış gibi görünüyor.
									","
											The deeper problem is that
building superintelligent AI on its own
											seems likely to be easier
											than building superintelligent AI
											and having the completed neuroscience
											that allows us to seamlessly
integrate our minds with it.
											And given that the companies
and governments doing this work
											are likely to perceive themselves
as being in a race against all others,
											given that to win this race
is to win the world,
											provided you don't destroy it
in the next moment,
											then it seems likely
that whatever is easier to do
											will get done first.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Şu an ne yazık ki bu soruna bir
çözümüm yok,
											çoğumuza bunu düşünmeyi önermek dışında.
											Yapay Zekâ konusunda Manhattan 
Projesi gibi
											bir şeye ihtiyacımız var.
											Geliştirmek için değil, çünkü
											kaçınılamaz bir şekilde
yapacağız bana göre,
											ama silahlanma yarışından
nasıl kaçıncağımızı anlamak
											ve menfaatlerimiz doğrultusunda 
inşa etmek için.
											Süper zeki YZ 'nın kendi
başına değişiklikler
											yapabileceğinden bahsederken,
											ana koşulları doğru anlamada tek
şansımız varmış gibi görünüyor
											ve o zaman dahi bunları doğru anlamanın
											siyasi ve ekonomik sonuçlarını
özümsememiz gerekecektir.
									","
											Now, unfortunately,
I don't have a solution to this problem,
											apart from recommending
that more of us think about it.
											I think we need something
like a Manhattan Project
											on the topic of artificial intelligence.
											Not to build it, because I think
we'll inevitably do that,
											but to understand
how to avoid an arms race
											and to build it in a way
that is aligned with our interests.
											When you're talking
about superintelligent AI
											that can make changes to itself,
											it seems that we only have one chance
to get the initial conditions right,
											and even then we will need to absorb
											the economic and political
consequences of getting them right.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Bilgi işlemenin yapay zekânın
											kaynağı olduğunu kabul ettiğimiz an,
											bu bazı uygun hesaplama sistemlerinin
zekânın temeli olduğunu
											ve bu sistemleri aralıksız
geliştireceğimizi kabul ettiğimizde
											ve bilişin ufkunun bildiğimizden 
daha uzaklara uzandığını
											kabul ettiğimizde,
											bir çeşit yaratıcı
											geliştirme sürecinde olduğumuzu
											kabul etmek durumunda olacağız.

											Şu an ise bu yaratıcıyla
yaşayabilme durumumuza
											karar vermek için doğru zaman olabilir.
									","
											But the moment we admit
											that information processing
is the source of intelligence,
											that some appropriate computational system
is what the basis of intelligence is,
											and we admit that we will improve
these systems continuously,
											and we admit that the horizon
of cognition very likely far exceeds
											what we currently know,
											then we have to admit
											that we are in the process
of building some sort of god.
											Now would be a good time
											to make sure it's a god we can live with.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											Çok teşekkürler.
									","
											Thank you very much.
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
											(Alkışlar)
									","
											(Applause)
									",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
"
","
",Can we build AI without losing control over it?,Sam Harris,14:27,"brain,AI,choice,history,future,humanity,innovation,intelligence,invention,mind,machine learning,neuroscience,potential,robots,science,technology,society"
