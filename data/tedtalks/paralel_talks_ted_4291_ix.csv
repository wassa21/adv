en,tr,fr,es,pt,title,speaker,duration,tags
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So when people voice fears
of artificial intelligence,
											very often, they invoke images
of humanoid robots run amok.
											You know? Terminator?
											You know, that might be
something to consider,
											but that's a distant threat.
											Or, we fret about digital surveillance
											with metaphors from the past.
											""1984,"" George Orwell's ""1984,""
											it's hitting the bestseller lists again.
											It's a great book,
											but it's not the correct dystopia
for the 21st century.
											What we need to fear most
											is not what artificial intelligence
will do to us on its own,
											but how the people in power
will use artificial intelligence
											to control us and to manipulate us
											in novel, sometimes hidden,
											subtle and unexpected ways.
											Much of the technology
											that threatens our freedom
and our dignity in the near-term future
											is being developed by companies
											in the business of capturing
and selling our data and our attention
											to advertisers and others:
											Facebook, Google, Amazon,
											Alibaba, Tencent.
									","
											İnsanlar yapay zekayla ilgili
korkularını dile getirdiğinde
											genellikle kontrolden çıkmış
insansı robotları hayal ederler.
											Terminatör gibi.
											Düşünmeye değer olsa da
											uzak bir tehdit bu.
											Bazen de geçmişe özgü benzetmelerle
											dijital gözetlenme kaygısı taşıyoruz.
											George Orwell'in ''1984'' adlı eseri
											şu an yine en çok satanlar listesinde.
											Harika bir kitap
											ama 21. yüzyıl için doğru distopya değil.
											En çok korkmamız gereken şey
											yapay zekanın kendi başına
bize ne yapacağı değil,
											güç sahibi insanların
bizi kontrol ve manipüle etmek adına
											yeni, bazen saklı,
											bazen de belirsiz ve beklenmeyen şekilde
											bunu nasıl kullanacakları.
											Yakın gelecekteki bağımsızlığımızı
											ve itibarımızı tehdit eden 
teknolojinin büyük kısmı
											verilerimizi ve dikkatimizi toplayıp
											reklamcı ve benzerlerine satan
											şirketler tarafından geliştiriliyor:
											Facebook, Google, Amazon,
											Alibaba, Tencent.
									","
											Quand les gens expriment de la peur
envers l'intelligence artificielle,
											très souvent, ils évoquent des images
de robots humanoïdes qui se déchaînent.
											Vous voyez ? Terminator ?
											Ce pourrait être à considérer
											mais c'est une menace très lointaine.
											Ou nous nous tracassons
au sujet de la surveillance numérique
											avec des métaphores du passé.
											« 1984 » de George Orwell
											est à nouveau parmi les livres
les plus vendus.
											C'est un super livre,
											mais ce n'est pas la bonne dystopie
pour le 21e siècle.
											Ce que nous devons craindre
											n'est pas ce que
l'intelligence artificielle fera seule,
											mais comment les gens au pouvoir
utiliseront l'intelligence artificielle
											pour nous contrôler et nous manipuler
											de façons nouvelles, parfois cachées,
											subtiles et inattendues.
											La plupart des technologies
											qui menacent notre liberté
et notre dignité dans un avenir proche
											sont développées par des entreprises
											dans le domaine
de l'enregistrement et de la vente
											de nos données et notre attention
											à des publicitaires et autres :
											Facebook, Google, Amazon,
											Alibaba, Tencent.
									","
											Cuando la gente manifiesta temor
por la inteligencia artificial,
											muchas veces recurre a imágenes
de robots humanoides enloquecidos.
											Ya saben: Terminator.
											Quizá debamos considerarlo,
											pero es una amenaza lejana.
											O si no, nos inquietamos
por la vigilancia electrónica
											con metáforas del pasado.
											""1984"", el ""1984"" de George Orwell,
											es un libro superventas otra vez.
											Es un gran libro,
											pero no es la distopía
correcta para el siglo XXI.
											Lo que debemos temer más
											no es lo que la inteligencia artificial
nos hará por sí misma,
											sino cómo la gente en el poder
usará la inteligencia artificial
											para controlarnos y manipularnos
											de maneras nuevas, a veces escondidas,
											sutiles e inesperadas.
											Mucha de la tecnología
											que amenaza nuestra libertad
y dignidad en un futuro cercano
											la están desarrollando compañías
											que se dedican a capturar y vender
nuestra información y nuestra atención
											a anunciantes y demás:
											Facebook, Google, Amazon,
											Alibaba, Tencent.
									","
											Quando as pessoas falam
dos seus medos da inteligência artificial,
											comummente, invocam figuras
de robôs humanoides fora de controlo.
											Sabem? O Exterminador?
											Bem, isso pode ser algo a considerar,
											mas é uma ameaça distante.
											Ou então, preocupamo-nos
com a vigilância digital
											com metáforas do passado.
											""1984"" de George Orwell
											está a chegar ao topo de vendas novamente.
											É um ótimo livro
											mas não é a distopia correta
para o século XXI.
											O que mais devemos temer
											não é o que a inteligência artificial
nos vai fazer por si própria,
											mas sim como as pessoas no poder
vão usar a inteligência artificial
											para nos controlar e manipular
											de formas novas, e às vezes escondidas,
											subtis e inesperadas.
											Muita da tecnologia
											que ameaça a nossa libertade
e a nossa dignidade, no futuro próximo
											está a ser desenvolvida por empresas
											que estão no ramo de recolher e vender
											as nossas informações e a nossa atenção
											a publicitários e outros
											— o Facebook, a Google, a Amazon,
											o Alibaba, o Tencent.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now, artificial intelligence has started
bolstering their business as well.
											And it may seem
like artificial intelligence
											is just the next thing after online ads.
											It's not.
											It's a jump in category.
											It's a whole different world,
											and it has great potential.
											It could accelerate our understanding
of many areas of study and research.
											But to paraphrase
a famous Hollywood philosopher,
											""With prodigious potential
comes prodigious risk.""
									","
											Şimdi yapay zeka da onların işlerine
katkıda bulunmaya başladı.
											Yapay zeka, internet
reklamcılığından sonra gelen
											yeni bir teknoloji gibi görünse de
											durum farklı.
											Söz konusu olan, 
ilgili alanda yepyeni bir açılım.
											Tamamen farklı bir dünya
											ve büyük potansiyeli var.
											Araştırma ve inceleme alanlarındaki
kavrayışımızı hızlandırabilir.
											Ancak ünlü bir Hollywood filozofundan
alıntı yapacak olursam,
											''Muhteşem potansiyel
muhteşem riskler barındırır.''
									","
											L'intelligence artificielle a également
commencé à stimuler leur marché.
											On pourrait croire
que l'intelligence artificielle
											sera la suite des publicités en ligne.
											Ce n'est pas le cas.
											C'est un saut dans la catégorie.
											C'est un monde complètement différent
											qui a un énorme potentiel.
											Ça pourrait accélérer
notre compréhension
											de nombreux domaines
d'étude et de recherche.
											Pour paraphraser un célèbre
philosophe hollywoodien :
											« Un grand pouvoir implique
de grandes responsabilités. »
									","
											La inteligencia artificial ha comenzado
a respaldar esos negocios también.
											Y parece que la inteligencia artificial
											es lo que le sigue 
a los anuncios en línea.
											Pero no lo es.
											Es un salto de categoría.
											Es un mundo totalmente distinto,
											y tiene un gran potencial.
											Podría acelerar nuestro entendimiento
											de muchas áreas
de estudio e investigación.
											Pero, parafraseando a un famoso
filósofo hollywoodense,
											""Un enorme potencial
viene con un enorme riesgo"".
									","
											Agora, a inteligência artificial
											também começou
a reforçar os seus negócios.
											E pode parecer que
a inteligência artificial
											é o que se seguirá aos anúncios ""online"".
											Não é.
											É uma subida de patamar.
											É um mundo completamente diferente
											e tem um grande potencial.
											Pode acelerar a nossa compreensão
											de muitas áreas de estudo e investigação.
											Mas, para parafrasear
um famoso filósofo de Hollywood,
											""Com um prodigioso potencial,
vem um prodigioso risco.""
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now let's look at a basic fact
of our digital lives, online ads.
											Right? We kind of dismiss them.
											They seem crude, ineffective.
											We've all had the experience
of being followed on the web
											by an ad based on something
we searched or read.
											You know, you look up a pair of boots
											and for a week, those boots are following
you around everywhere you go.
											Even after you succumb and buy them,
they're still following you around.
											We're kind of inured to that kind
of basic, cheap manipulation.
											We roll our eyes and we think,
""You know what? These things don't work.""
											Except, online,
											the digital technologies are not just ads.
											Now, to understand that,
let's think of a physical world example.
											You know how, at the checkout counters
at supermarkets, near the cashier,
											there's candy and gum
at the eye level of kids?
											That's designed to make them
whine at their parents
											just as the parents
are about to sort of check out.
											Now, that's a persuasion architecture.
											It's not nice, but it kind of works.
											That's why you see it
in every supermarket.
											Now, in the physical world,
											such persuasion architectures
are kind of limited,
											because you can only put
so many things by the cashier. Right?
											And the candy and gum,
it's the same for everyone,
											even though it mostly works
											only for people who have
whiny little humans beside them.
											In the physical world,
we live with those limitations.
									","
											Dijital hayatlarımızdaki
temel bir gerçeğe bakalım.
											İnternet reklamları. Öyle değil mi? 
Onları yok sayıyoruz.
											Basit ve dikkat dağıtıcı görünüyorlar.
											Okuduğumuz veya arattığımız
bir konuyla ilgili reklamlar tarafından
											internette takip edilme tecrübesini
hepimiz yaşadık.
											Hani bir çift botun fiyatına bakarsınız
											ve sonra bütün hafta girdiğiniz
her sayfada botlar sizi takip eder.
											Karşı koyamayıp satın aldıktan sonra bile
sizi takip ederler.
											Bu basit ve ucuz manipülasyonu
adeta kanıksamış durumdayız.
											Göz devirip kendi kendimize
''İşe yaramıyor bunlar.'' diyoruz.
											Ne var ki internet ortamında,
											dijital teknolojiler
reklamlardan ibaret değil.
											Bunu anlamak için
fiziksel bir dünya örneği ele alalım.
											Süpermarketlerde
kasaların hemen yanında
											çocukların göz hizasında
şekerleme ve sakız olur.
											İlgili düzenek, aileler tam
marketten çıkmak üzereyken
											çocuklarının bunları
ısrarla istemeleri için tasarlanmıştır.
											Bu bir ikna mimarisi.
											Pek hoş değil ama işe yarıyor.
											Bu yüzden de her süpermarkette görüyoruz.
											Fiziksel dünyada,
											bu ikna mimarileri sınırlıdır,
											çünkü kasiyerin yanına koyabileceğiniz
şeylerin bir sınırı var, değil mi?
											Şeker ve sakız herkes için aynı,
											her ne kadar yanında
											sızlanan çocuklar olan 
aileler için işe yarasa da.
											Fiziksel dünyada bu sınırlarla yaşıyoruz.
									","
											Considérons un fait fondamental
de nos vies numériques : les publicités.
											Nous les ignorons.
											Elles semblent grossières, inefficaces.
											Nous avons tous été suivis sur internet
											par une pub basée sur une chose
que nous avions cherchée ou lue.
											Vous cherchez un paire de bottes
											et pendant une semaine, ces bottes
vous suivent partout où vous allez.
											Même après avoir succombé
et les avoir achetées,
											elles vous suivent encore.
											Nous sommes un peu protégés
contre cette manipulation bon marché.
											Nous levons les yeux au ciel et pensons :
« Ça ne marche pas. »
											Mis à part qu'en ligne,
											les technologies numériques
ne sont pas que des publicités.
											Pour le comprendre, réfléchissons
à un exemple du monde physique.
											Vous savez comment à la caisse
au supermarché, près du caissier,
											il y a des bonbons et chewing-gums
à hauteur des yeux des enfants ?
											C'est conçu pour les faire pleurnicher
auprès de leurs parents
											alors que les parents
sont sur le point de payer.
											C'est une architecture de persuasion.
											Ce n'est pas sympa, mais ça marche.
											C'est pourquoi vous le voyez partout.
											Dans le monde physique,
											de telles architectures
de persuasion sont limitées
											car on ne peut mettre qu'un certain nombre
de choses près de la caisse.
											Les bonbons et chewing-gums
sont les mêmes pour tout le monde,
											même si ça fonctionne
											surtout pour les gens ayant des petits
êtres pleurnichant à leurs côtés.
											Dans le monde physique,
nous vivons avec ces limites.
									","
											Ahora hablemos de un hecho básico
de nuestra vida digital: los anuncios.
											Como que los ignoramos, ¿no?
											Parecen ordinarios, inefectivos.
											Todos hemos tenido esa experiencia
de ser perseguidos en la web
											por un anuncio basado en algo
que buscamos o leímos.
											Ya saben, buscas un par de botas
											y durante una semana, esas botas
te siguen a todos lados donde vayas.
											Incluso después de haber sucumbido
a comprarlas, te continúan siguiendo.
											Estamos habituados a ese tipo
de manipulación simple y barata.
											Ponemos los ojos en blanco y pensamos,
""¿Sabes qué? Esto no funciona"".
											Excepto que, en línea,
											las tecnologías digitales 
no son solo anuncios.
											Para entender eso, pensemos
en un ejemplo del mundo físico.
											¿Han visto que en la caja de cobro
del supermercado, cerca del cajero,
											hay dulces y goma de mascar
a la altura de los ojos de los niños?
											Eso está diseñado para hacerlos
rogar a sus padres
											justo cuando los padres están por pagar.
											Eso es arquitectura de la persuasión.
											No es agradable, pero funciona.
											Por eso se ve en todos los supermercados.
											Ahora, en el mundo físico,
											la arquitectura de la persuasión
es un poco limitada,
											porque solo puedes poner 
unas cuantas cosas cerca de la caja, ¿no?
											Y los dulces y goma de mascar
son iguales para todos,
											aunque en general funciona
											solo con la gente que va acompañada
de personitas caprichosas.
											En el mundo físico, 
vivimos con esas limitantes.
									","
											Olhemos para factos básicos
da nossa vida digital,
											os anúncios ""online"".
											Quase nos passam despercebidos.
											Parecem brutos, ineficazes.
											Já todos tivemos a experiência
de sermos perseguidos na Internet
											por um anúncio, baseado em algo
que pesquisámos ou lemos.
											Procuramos um par de botas
											e, durante uma semana, aquelas botas
perseguem-nos, aonde quer que vamos.
											Mesmo após termos cedido
e as termos comprado, ainda nos perseguem.
											Estamos quase habituados a este tipo
de manipulação, básica e barata.
											Reviramos os olhos e pensamos:
											""Sabem que mais? 
Estas coisas não funcionam.""
											Mas ""online"", as tecnologias digitais
não são apenas os anúncios.
											Para percebermos isso, pensemos
num exemplo do mundo físico.
											Sabem como, nos balcões à saída
do supermercado, ao pé das caixas,
											há doces e pastilhas ao nível
do olhar das crianças?
											Isso foi feito para as fazer
choramingar para os pais,
											quando os pais estão quase
a pagar e sair.
											Isso é uma arquitetura de persuasão.
											Não é simpático, mas até funciona.
											É por isso que o vemos
em todos os supermercados.
											No mundo físico,
											estas arquiteturas de persuasão
são um pouco limitadas,
											porque só dá para pôr algumas coisas
ao pé da caixa, certo?
											E os doces e as pastilhas
são os mesmos para toda a gente,
											apesar de funcionar maioritariamente
											só com pessoas que têm
aqueles seres birrentos ao lado.
											No mundo físico, vivemos
com estas limitações.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											In the digital world, though,
											persuasion architectures
can be built at the scale of billions
											and they can target, infer, understand
											and be deployed at individuals
											one by one
											by figuring out your weaknesses,
											and they can be sent
to everyone's phone private screen,
											so it's not visible to us.
											And that's different.
											And that's just one of the basic things
that artificial intelligence can do.
									","
											Ancak dijital dünyada,
											ikna mimarisi, milyarlara erişecek 
şekilde inşa edilebilir
											ve bu reklamlar aynı zamanda
											bireyleri teker teker
hedef alarak anlayabilir,
											zayıf noktalarını tespit ederek
											onlara kişisel seviyede nüfuz edebilir
											hatta herkesin kişisel telefon ekranına
bile gönderilebilir,
											böylelikle bizler görmeyiz.
											Ve bu oldukça farklı.
											Bu, yapay zekanın yapabileceği
temel şeylerden yalnızca biri.
									","
											Dans le monde numérique cependant,
											les architectures de persuasion
peuvent être adaptées
											pour des milliards de personnes,
											elles peuvent cibler,
déduire, comprendre
											et être déployées pour des individus,
											un par un,
											en déterminant nos faiblesses
											et elles peuvent être envoyées
sur l'écran privé des téléphones
											afin que ce ne soit pas
visible à nos yeux.
											C'est différent.
											Ce n'est qu'une chose basique dont
est capable l'intelligence artificielle.
									","
											No obstante, en el mundo digital,
											las arquitecturas de la persuasión
pueden tener miles de millones de opciones
											y pueden apuntar, inferir, entender
											y ser aplicadas a cada individuo
											uno por uno
											descubriendo nuestras debilidades,
											y pueden ser enviadas directamente
a la pantalla personal de cada teléfono,
											así que son invisibles para nosotros.
											Y eso es diferente.
											Es solo una de las cosas que puede hacer
la inteligencia artificial.
									","
											No entanto, no mundo digital,
as arquiteturas de persuasão
											podem ser construidas
à escala de milhares de milhões
											e podem escolher o alvo, deduzir,
											compreender e ser utilizadas
em indivíduos, um a um,
											percebendo as suas fraquezas,
											e podem ser enviadas para o ecrã
do telefone privado de cada pessoa
											e, por isso, nós não as vemos.
											E isso é diferente.
											E é só uma das coisas básicas
que a inteligência artificial faz.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now, let's take an example.
											Let's say you want to sell
plane tickets to Vegas. Right?
											So in the old world, you could think
of some demographics to target
											based on experience
and what you can guess.
											You might try to advertise to, oh,
											men between the ages of 25 and 35,
											or people who have
a high limit on their credit card,
											or retired couples. Right?
											That's what you would do in the past.
									","
											Bir örnek verelim.
											Diyelim ki Las Vegas'a uçak bileti 
satmak istiyorsunuz.
											Eski düzende,
deneyim ve öngörülerinize dayanarak
											hedef bir demografik kesim belirlersiniz.
											Reklam yapmayı da deneyebilirsiniz,
											25-35 yaş aralığındaki erkekler
											veya kredi kartı limiti 
yüksek olan insanlar
											veya emekli çiftler, değil mi?
											Geçmişte böyle yapardınız.
									","
											Prenons un exemple.
											Vous voulez vendre
des billets d'avion pour Las Vegas.
											Dans l'ancien monde, vous pensiez
à des segments démographiques à cibler
											d'après votre expérience
et ce que vous pouvez imaginer.
											Vous pourriez faire de la publicité
											aux hommes ayant entre 25 et 35 ans
											ou aux gens qui ont une limite élevée
sur leur carte de crédit
											ou aux couples à la retraite.
											C'est ce que vous auriez fait.
									","
											Pongamos un ejemplo.
											Digamos que quieren vender
boletos de avión a Las Vegas.
											En el viejo mundo, se dirigirían
a ciertos sectores demográficos
											basándose en la experiencia
y lo que podían suponer.
											Podrían tratar de anunciar para
											hombres entre los 25 y 35 años,
											o gente con un límite alto 
en la tarjeta de crédito,
											o parejas retiradas, ¿no?
											Eso es lo que harían en el pasado.
									","
											Vejamos um exemplo.
											Suponhamos que queremos vender
bilhetes de avião para Las Vegas.
											No mundo antigo, pensaríamos
nalgumas demografias como alvo
											com basea na experiência e em palpites.
											Poderíamos colocar anúncios
para homens entre os 25 e os 35 anos,
											ou pessoas que tenham
um limite elevado no cartão de crédito,
											ou casais reformados, certo?
											Isso seria o que faríamos no passado.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											With big data and machine learning,
											that's not how it works anymore.
											So to imagine that,
											think of all the data
that Facebook has on you:
											every status update you ever typed,
											every Messenger conversation,
											every place you logged in from,
											all your photographs
that you uploaded there.
											If you start typing something
and change your mind and delete it,
											Facebook keeps those
and analyzes them, too.
											Increasingly, it tries
to match you with your offline data.
											It also purchases
a lot of data from data brokers.
											It could be everything
from your financial records
											to a good chunk of your browsing history.
											Right? In the US,
such data is routinely collected,
											collated and sold.
											In Europe, they have tougher rules.
									","
											Şimdi büyük veri ve makine öğrenimi ile
											işler artık böyle yürümüyor.
											Bunu anlamak için
											Facebook'un sizinle ilgili
sahip olduğu tüm verileri düşünün:
											Yazdığınız her durum bildirisi,
											her bir Messenger sohbeti,
											oturum açtığınız her konum,
											yüklediğiniz tüm fotoğraflar.
											Bir şey yazmaya başlayıp
sonra vazgeçip silerseniz
											Facebook bu silinenleri de
saklayıp analiz ediyor.
											Çevrimdışı verilerinizle sizi
gitgide eşleştirmeye çalışıyor.
											Ayrıca veri acentalarından da
çok fazla veri satın alıyor.
											Finansal kayıtlarınızdan
tarama geçmişinize kadar
											her şey bu veri setinde olabilir.
											ABD'de bu tür veriler
rutin olarak toplanıyor,
											karşılaştırılıyor ve satılıyor.
											Avrupa'da daha sıkı kurallar var.
									","
											Avec le big data
et l'apprentissage des machines,
											ça ne marche plus comme ça.
											Pour l'imaginer,
											pensez à toutes les données
que Facebook a sur vous :
											tous les status tapés,
											toutes les conversations Messenger,
											tous vos lieux de connexion,
											toutes les photos
que vous avez téléchargées.
											Si vous tapez quelque chose,
changez d'avis et le supprimez,
											Facebook le garde et l'analyse également.
											De plus en plus, il essaye
de vous relier à vos données hors ligne.
											Il achète également des données
auprès de courtiers de données.
											Ce pourrait être n'importe quoi,
de vos documents financiers
											à votre historique de recherche.
											Aux Etats-Unis, de telles données
sont systématiquement collectées,
											comparées et vendues.
											En Europe, les règles sont plus strictes.
									","
											Con big data y aprendizaje automático,
											ya no funciona más así.
											Así que, para imaginar eso,
											piensen en todos los datos
que Facebook tiene sobre Uds.:
											cada actualización de estado
que jamás hayan escrito,
											cada conversación en el Messenger,
											cada lugar desde donde accedieron,
											todas las fotografías que hayan subido.
											Lo que comenzaron a escribir y borraron
porque cambiaron de opinión;
											Facebook guarda y analiza eso también.
											Cada vez trata de aproximarse más
a los datos de tu vida fuera de línea.
											También adquiere muchos datos
de los corredores de datos.
											Podría ser cualquier cosa,
desde registros financieros
											hasta una buena parte
de tu historial de búsqueda.
											En EE. UU. esos datos
son habitualmente recolectados,
											cotejados y vendidos.
											En Europa tienen reglas más estrictas.
									","
											Com a grande quantidade de informações
e a aprendizagem de máquinas,
											já não é assim que funciona.
											Para imaginar isso,
											pensemos em todas as informações
que o Facebook tem sobre nós:
											cada atualização de estado
que escrevemos,
											cada conversa no Messenger,
											cada local em que acedemos ao Facebook,
											cada fotografia que carregámos
para a plataforma.
											Se começamos a escrever uma coisa
e mudamos de ideias e a apagamos
											o Facebook guarda essas informações
e também as analisa.
											Cada vez mais, tenta
fazer a correspondência
											entre nós e as nossas
informações ""offline"".
											Também compra muitas informações
a corretores de dados.
											Pode ser qualquer coisa,
desde registos financeiros,
											até uma boa parte
do nosso histórico da Internet.
											Nos EUA estas informações
são rotineiramente recolhidas,
											reunidas e vendidas.
											Na Europa, há regras mais restritas.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So what happens then is,
											by churning through all that data,
these machine-learning algorithms —
											that's why they're called
learning algorithms —
											they learn to understand
the characteristics of people
											who purchased tickets to Vegas before.
											When they learn this from existing data,
											they also learn
how to apply this to new people.
											So if they're presented with a new person,
											they can classify whether that person
is likely to buy a ticket to Vegas or not.
											Fine. You're thinking,
an offer to buy tickets to Vegas.
											I can ignore that.
											But the problem isn't that.
											The problem is,
											we no longer really understand
how these complex algorithms work.
											We don't understand
how they're doing this categorization.
											It's giant matrices,
thousands of rows and columns,
											maybe millions of rows and columns,
											and not the programmers
											and not anybody who looks at it,
											even if you have all the data,
											understands anymore
how exactly it's operating
											any more than you'd know
what I was thinking right now
											if you were shown
a cross section of my brain.
											It's like we're not programming anymore,
											we're growing intelligence
that we don't truly understand.
									","
											Yani aslında olan şey,
											tüm bu veriler harmanlanarak
bu makine öğrenimli algoritmalar -
											onlara bu yüzden öğrenen 
algoritmalar deniyor -
											daha önce Las Vegas'a gitmek için 
uçak bileti alan insanların
											özelliklerini nasıl
ayrıştıracaklarını öğreniyorlar.
											Var olan verilerden bunu öğrendiklerinde
											bunu yeni insanlara 
uygulamayı da öğreniyorlar.
											Böylece, yeni bir bireyle
karşılaştıklarında
											onun Vegas'a bilet alıp almayacağını
sınıflandırabiliyorlar.
											Olsun diye düşünüyorsunuz,
alt tarafı Vegas'a uçak bileti teklifi.
											Görmezden gelebilirim.
											Ancak asıl sorun bu değil.
											Asıl sorun şu ki
											biz bu karmaşık algoritmaların
nasıl çalıştığını artık anlamıyoruz.
											Bu sınıflandırmayı nasıl yaptıklarını
artık anlamıyoruz.
											Dev matematik matrisleri,
binlerce sıra ve sütun,
											belki de milyonlarcası...
											Ve tüm verilere sahip olsalar bile,
											ne programcılar,
											ne de bunları inceleyen biri
											bunun tam olarak nasıl 
işlediğini anlayabiliyor.
											Tıpkı size beynimden bir kesit göstersem
											ne düşündüğümü anlayamayacağınız gibi.
											Sanki artık programlama yapmıyoruz,
											tam olarak anlayamadığımız 
bir bilinç geliştiriyoruz.
									","
											Ce qu'il se passe alors c'est que,
											en fouillant toutes ces données,
											ces algorithmes d'apprentissage
des machines —
											ils sont appelés algorithmes
d'apprentissage pour cette raison —
											ils apprennent à comprendre
les caractéristiques des gens
											ayant déjà acheté
des billets pour Las Vegas.
											Quand ils l'apprennent
de données existantes,
											ils apprennent aussi comment
l'appliquer à de nouvelles personnes.
											Face à une nouvelle personne,
											ils peuvent classifier
											si cette personne a des chances
d'acheter un billet pour Las Vegas ou pas.
											Bien. Vous vous dites qu'une offre
pour acheter des billets pour Las Vegas,
											vous pouvez l'ignorer.
											Mais le problème n'est pas là.
											Le problème,
											c'est que nous ne comprenons plus vraiment
											comment fonctionnent
ces algorithmes complexes.
											Nous ne comprenons pas
comment ils font cette catégorisation.
											Ce sont d'énormes matrices,
des milliers de lignes et colonnes,
											peut-être même des millions,
											et ni les programmeurs,
											ni quiconque les regardant,
											même avec toutes les données,
											ne comprend plus
comment ça opère exactement,
											pas plus que vous ne sauriez
ce que je pense en ce moment
											si l'on vous montrait
une coupe transversale de mon cerveau.
											C'est comme si nous ne programmions plus,
											nous élevons une intelligence
que nous ne comprenons pas vraiment.
									","
											Entonces, lo que ocurre es lo siguiente:
											al procesar todos esos datos,
esos algoritmos de aprendizaje automático,
											y por esto se llaman
algoritmos de aprendizaje,
											aprenden a entender
las características de la gente
											que compró boletos 
a Las Vegas anteriormente.
											Una vez que aprenden esto
de los datos existentes,
											también aprenden cómo aplicarlo
a un nuevo grupo de gente.
											Entonces, si se encuentran
con una persona nueva,
											pueden clasificar si esa persona
compraría un boleto a Las Vegas o no.
											Ahora bien, Uds. están pensando:
											""Una oferta para comprar
boletos a Las Vegas... Puedo ignorarlo"".
											Pero el problema no es ese.
											El problema es
											que ya no comprendemos realmente
cómo funcionan estos algoritmos complejos.
											No entendemos cómo categorizan.
											Son matrices gigantes,
miles de filas y columnas,
											quizá millones de filas y columnas,
											y ya ni los programadores
											ni nadie que los analice,
											aun teniendo todos los datos,
											comprende cómo operan exactamente;
											no más de lo que Uds. sabrían
lo que estoy pensado en este momento
											si les enseñaran
una disección de mi cerebro.
											Es como que ya no estamos programando;
											estamos creando inteligencia 
que no comprendemos totalmente.
									","
											Então o que acontece é que,
ao remexer em todas estas informações
											os algoritmos de aprendizagem
destas máquinas,
											— é por isso que são chamados,
algoritmos de aprendizagem —
											aprendem a detetar
as características das pessoas
											que já compraram
bilhetes para Las Vegas antes.
											Quando aprendem isto a partir
de informações já existentes,
											também aprendem
como o aplicar a novas pessoas.
											Se lhes apresentarem uma nova pessoa,
											eles conseguem classificar se essa pessoa
											poderá comprar um bilhete
para Las Vegas ou não.
											Ok, vocês estão a pensar:
											""Uma oferta para comprar
um bilhete para Las Vegas?
											""Consigo ignorar isso"".
											Mas o problema não é isso.
											O problema é que já não percebemos
como funcionam estes algoritmos complexos.
											Nós não percebemos como estão
a fazer essa categorização.
											São matrizes gigantes,
milhares de linhas e colunas,
											talvez milhões de linhas e colunas.
											E já nem os programadores
											nem alguém que olhe para aquilo,
											mesmo que tenha todas as informações,
											percebem como, exatamente,
é que aquilo funciona,
											tal como vocês não saberiam
em que é que eu estou a pensar agora,
											se eu vos mostrasse um corte
transversal do meu cérebro.
											É como se já não estivéssemos a programar,
											estamos a desenvolver inteligência
que já não percebemos verdadeiramente.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											And these things only work
if there's an enormous amount of data,
											so they also encourage
deep surveillance on all of us
											so that the machine learning
algorithms can work.
											That's why Facebook wants
to collect all the data it can about you.
											The algorithms work better.
									","
											Üstelik bu mekanizmalar yalnızca
müthiş miktarda veri varsa çalışıyor,
											dolayısı ile hepimizin üzerinde kapsamlı 
bir gözetleme de teşvik ediliyor ki
											makine öğrenimli algoritmalar
işini yapabilsin.
											Bu yüzden Facebook, hakkınızda
toplayabildiği tüm veriyi istiyor.
											Algoritmalar daha iyi çalışıyor.
									","
											Ces choses fonctionnent seulement
s'il y a un énorme volume de données,
											elles pourraient donc aussi encourager
une surveillance intensifiée à notre égard
											afin que les algorithmes
d'apprentissage marchent.
											C'est pour ça que Facebook veut
collecter toutes les données sur vous.
											Les algorithmes marchent mieux.
									","
											Y estas cosas solo funcionan
con una enorme cantidad de datos,
											así que también fomentan una
vigilancia profunda de todos nosotros
											para que los algoritmos
de aprendizaje funcionen.
											Por eso Facebook quiere acumular
todos los datos que pueda sobre Uds.
											Los algoritmos funcionan mejor.
									","
											Tudo isto só funciona se houver
quantidades enormes de informações.
											Então, eles também encorajam
uma forte vigilância sobre todos nós
											para que os algoritmos
de aprendizagem funcionem.
											É por isso que o Facebook recolhe
todas as informações possíveis.
											Os algoritmos funcionam melhor.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So let's push that Vegas example a bit.
											What if the system
that we do not understand
											was picking up that it's easier
to sell Vegas tickets
											to people who are bipolar
and about to enter the manic phase.
											Such people tend to become
overspenders, compulsive gamblers.
											They could do this, and you'd have no clue
that's what they were picking up on.
											I gave this example
to a bunch of computer scientists once
											and afterwards, one of them came up to me.
											He was troubled and he said,
""That's why I couldn't publish it.""
											I was like, ""Couldn't publish what?""
											He had tried to see whether you can indeed
figure out the onset of mania
											from social media posts
before clinical symptoms,
											and it had worked,
											and it had worked very well,
											and he had no idea how it worked
or what it was picking up on.
									","
											Şu Vegas örneğinin biraz üstüne gidelim.
											Ya anlamadığımız bu sistem
											mani döneme geçmek üzere olan
bipolar insanlara
											Vegas bileti satmanın 
daha kolay olduğunu anlarsa?
											Bu insanlar çok para harcamaya
ve dürtüsel kumarbazlığa meyilli oluyor.
											Bunu yapabilirler ve söz konusu kriteri 
seçtiklerinden haberiniz bile olmaz.
											Bu örneği bir grup
bilgisayar bilimcisine verdim,
											sonra içlerinden biri yanıma geldi.
											Rahatsız olmuştu ve şöyle dedi:
''İşte bu yüzden yayınlayamadım.''
											''Neyi yayınlayamadın?'' dedim.
											Mani halinin ön belirtilerinin
klinik semptomlardan önce
											sosyal medya paylaşımlarından
anlaşılabilirliğini incelemişti
											ve işe yaramıştı,
											gerçekten işe yaramıştı
											ama nasıl işe yaradığı veya ne tür 
bilgi topladığını o da bilmiyordu.
									","
											Allons un peu plus loin
avec cet exemple de Las Vegas.
											Et si le système
que nous ne comprenons pas
											déterminait qu'il est plus simple
de vendre des billets pour Las Vegas
											aux gens bipolaires qui sont sur le point
d'entrer dans la phase maniaque.
											De telles personnes ont tendance
à dépenser et parier de façon compulsive.
											Ils pourraient le faire, vous ignoreriez
que c'était là leur conclusion.
											Une fois, j'ai donné cet exemple
à quelques informaticiens
											et après, l'un d'eux est venu me voir.
											Il était préoccupé : « C'est pour ça
que je n'ai pas pu le publier ».
											J'ai dit : « Publier quoi ? »
											Il avait essayé de voir s'il l'on pouvait
détecter le début d'une manie
											d'après les posts sur les réseaux sociaux
avant les symptômes cliniques
											et ça avait fonctionné,
											ça avait très bien fonctionné,
											et il n'avait aucune idée de comment
ça marchait ou ce que ça détectait.
									","
											Así que continuemos
con el ejemplo de Las Vegas.
											¿Qué pasaría si ese sistema 
que no entendemos
											aprendiera que es más fácil
venderle boletos a Las Vegas
											a gente bipolar a punto de entrar
en un episodio maníaco?
											Esa gente tiende a gastar de más
y a apostar compulsivamente.
											Podrían hacerlo y no tendríamos
ni idea de que se fijaron en eso.
											Di este ejemplo una vez a un grupo
de científicos de la computación
											y después, uno se me acercó.
											Estaba afligido y dijo:
""Por eso no pude publicarlo"".
											Yo le pregunté: ""¿Publicar qué?"".
											Él había tratado de ver si realmente
se podría predecir el arranque maníaco
											en publicaciones de redes sociales
antes de los síntomas clínicos,
											y había funcionado,
											había funcionado muy bien,
											y no tenía idea de cómo funcionaba
o qué había descubierto.
									","
											Vamos forçar um pouco
o exemplo de Las Vegas.
											E se o sistema,
que nós não compreendemos,
											estivesse a captar que é mais fácil
vender bilhetes para Las Vegas
											a pessoas que são bipolares

											e estão prestes a entrar na fase maníaca?
											Essas pessoas tendem a gastar demais
e a serem jogadores compulsivos.
											Eles podiam fazer isso,
e nós não faríamos a ideia
											que era esse o critério
que estariam a usar.
											Uma vez, dei este exemplo
a um grupo de cientistas informáticos
											e no final, um deles veio ter comigo.
											Estava perturbado e disse:
											""Foi por isso que eu não pude publicar.""
											E eu: ""Não pôde publicar o quê?""
											Ele tinha tentado 
perceber se seria possível
											apercebermo-nos do início
de uma fase de mania
											a partir das publicações nas redes sociais
antes de haver sintomas clínicos,
											e tinha conseguido.
											Tinha funcionado muito bem.
											Ele não fazia ideia
de como é que tinha funcionado
											ou como é que lá tinha chegado
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now, the problem isn't solved
if he doesn't publish it,
											because there are already companies
											that are developing
this kind of technology,
											and a lot of the stuff
is just off the shelf.
											This is not very difficult anymore.
									","
											Yayınlamadığı zaman problem çözülmüyor
											çünkü zaten bu teknolojiyi geliştiren
											halihazırda şirketler var.
											Bunun pek çoğu satışa hazır.
											Artık bunu yapmak çok zor değil.
									","
											Le problème n'est pas résolu
s'il ne le publie pas
											car il y a déjà des entreprises
											qui développent ce genre de technologie
											et beaucoup de choses existent déjà.
											Ce n'est plus très compliqué.
									","
											El problema no se resuelve
si él no lo publica,
											porque ya hay compañías
											que están desarrollando
este tipo de tecnología,
											y muchas de estas cosas
ya están a la venta.
											Esto ya no es tan difícil.
									","
											O problema não fica resolvido
se ele não o publicar,
											porque já há empresas
a desenvolver este tipo de tecnologia,
											e há muita coisa já disponível.
											Isto já não é muito difícil.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Do you ever go on YouTube
meaning to watch one video
											and an hour later you've watched 27?
											You know how YouTube
has this column on the right
											that says, ""Up next""
											and it autoplays something?
											It's an algorithm
											picking what it thinks
that you might be interested in
											and maybe not find on your own.
											It's not a human editor.
											It's what algorithms do.
											It picks up on what you have watched
and what people like you have watched,
											and infers that that must be
what you're interested in,
											what you want more of,
											and just shows you more.
											It sounds like a benign
and useful feature,
											except when it isn't.
									","
											Tek bir video izlemek için YouTube'a girip
											bir saat sonra 27 video izlediğiniz
oluyor mu hiç?
											YouTube'ta sağ tarafta
											''Sıradaki'' diye bir sütun var
											ve otomatik yeni video başlatıyor.
											Bu bir algoritma,
											ilgilendiğinizi ve kendi başınıza
bulamayacağınızı düşündüğü
											videoları seçiyor.
											Editör bir insan değil.
											Algoritmaların işi bu.
											Sizin ve sizin gibi insanların
izlediklerini derliyor,
											ilgi alanlarınızın bunlar olduğu
											ve daha fazlasını görmek istediğiniz
çıkarımını yapıyor,
											daha fazlasını gösteriyor.
											İyi, faydalı bir özelllik gibi görünüyor
											ama öyle değil.
									","
											Vous arrive-t-il d'aller sur YouTube
pour regarder une vidéo
											et, une heure plus tard,
d'en avoir regardées 27 ?
											Vous voyez cette colonne
que YouTube a sur la droite,
											qui dit « A suivre »
											et qui se lance automatiquement ?
											C'est un algorithme
											qui choisit ce qu'il pense
qui pourrait vous intéresser
											et que vous ne trouveriez pas seul.
											Ce n'est pas un humain,
											ce sont des algorithmes.
											Il considère ce que vous avez regardé
et ce que d'autres comme vous ont regardé
											et il déduit que ce doit être
ce qui vous intéresse,
											ce dont vous voulez voir plus
											et vous en montre plus.
											Ça semble être une fonction
bénigne et utile,
											mais ça ne l'est pas.
									","
											¿Les ha pasado entrar a YouTube
para ver un video en específico
											y una hora más tarde vieron 27?
											¿Vieron que YouTube tiene 
una columna a la derecha
											que dice: ""A continuación""
											y que reproduce algo automáticamente?
											Es un algoritmo
											que elige lo que cree que les interesaría 
y que quizá no encuentren por sí mismos.
											No es un editor humano.
											Eso hacen los algoritmos.
											Se fijan en lo que han mirado
y lo que la gente como Uds. ha mirado,
											e infiere que eso debe ser
lo que les interesa,
											y de lo que quieren más,
											y entonces les muestra más.
											Parece una herramienta benigna y útil,
											excepto cuando no lo es.
									","
											Já aconteceu irem ao Youtube
com intenção de ver um vídeo
											e uma hora depois, já viram 27?
											Sabem, o YouTube tem
aquela coluna à direita,

											que diz ""A seguir""
											e começa automaticamente outro vídeo?
											É um algoritmo a escolher
o que acha que nos pode interessar
											e talvez não encontremos sozinhos.
											Não é um editor humano.
É o que os algoritmos fazem.
											Vê o que já vimos e o que pessoas
como nós já viram,
											e presume que aquilo deve ser
do nosso interesse,
											aquilo que queremos ver mais,
e mostra-nos mais.
											Parece uma funcionalidade benigna e útil,
											exceto quando não é.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So in 2016, I attended rallies
of then-candidate Donald Trump
											to study as a scholar
the movement supporting him.
											I study social movements,
so I was studying it, too.
											And then I wanted to write something
about one of his rallies,
											so I watched it a few times on YouTube.
											YouTube started recommending to me
											and autoplaying to me
white supremacist videos
											in increasing order of extremism.
											If I watched one,
											it served up one even more extreme
											and autoplayed that one, too.
											If you watch Hillary Clinton
or Bernie Sanders content,
											YouTube recommends
and autoplays conspiracy left,
											and it goes downhill from there.
									","
											2016'da o zaman aday olan
Trump'ın toplantılarına
											destekçilerini araştırmak üzere
akademisyen olarak katıldım.
											İşim gereği sosyal akımları inceliyorum,
yani araştırıyordum da.
											Sonra toplantılarından
biri hakkında yazmak istedim,
											o yüzden de toplantıyı 
YouTube'da birkaç kez izledim.
											YouTube, beyaz ırk üstünlüğü ile ilgili
											radikallik seviyesi giderek artan 
videolar önermeye
											ve onları otomatik oynatmaya başladı.
											Eğer bir tane izlediysem
											YouTube daha marjinal bir tanesini buldu
											ve onu da otomatik yürüttü.
											Hillary Clinton veya Bernie Sanders
ile ilgili içerikler izlerseniz
											YouTube komplocu solcuları
öneriyor ve oynatıyor,
											ondan sonra da gittikçe kötüleşiyor.
									","
											En 2016, j'ai été à des rassemblements
du candidat Donald Trump
											pour étudier en tant que chercheuse
le mouvement le soutenant.
											J'étudie les mouvements sociaux,
alors j'étudiais ça aussi.
											Puis j'ai voulu écrire quelque chose
au sujet d'un de ses rassemblements
											alors je l'ai regardé sur YouTube.
											YouTube a commencé à me recommander
											et à lancer automatiquement
des vidéos de suprématistes blancs
											étant de plus en plus extrémistes.
											Si j'en regardais une,
											il m'en recommandait une
encore plus extrême
											et la lançais automatiquement.
											Si vous regardez du contenu
d'Hillary Clinton ou Bernie Sanders,
											YouTube recommande et lance
des vidéos gauchistes de conspiration
											et plus ça va, plus ça empire.
									","
											En 2016 asistí a actos electorales
del entonces candidato Donald Trump
											para estudiar, como académica,
el movimiento que lo apoyaba.
											Estudio los movimientos sociales,
así que por eso lo estudiaba también.
											Quise escribir algo 
sobre uno de sus actos,
											así que lo miré varias veces en YouTube.
											YouTube comenzó a recomendarme
											una lista de reproducción de videos
de supremacistas blancos
											en orden de extremismo creciente.
											Si miraba uno,
											me llevaba a otro incluso más extremo
											y se reproducía automáticamente.
											Si miran contenido sobre
Hillary Clinton o Bernie Sanders,
											YouTube les recomienda y reproduce
conspiraciones de izquierda,
											de ahí hacia abajo.
									","
											Em 2016, fui a comícios
do então candidato, Donald Trump
											para estudar, como especialista,
o movimento que o apoiava.
											Eu estudo movimentos sociais,
então estava a estudar isso também.
											Depois, quis escrever qualquer coisa
sobre um dos comícios dele,
											portanto vi-o umas vezes no YouTube.
											O YouTube começou a recomendar-me
											e a reproduzir automaticamente
vídeos de supremacia da raça branca
											por ordem crescente de extremismo.
											Se eu visse um,
											aparecer-me-ia outro ainda mais extremo
											que também se reproduzia automaticamente.
											Se virmos conteúdos de Hillary Clinton
ou de Bernie Sanders,
											o YouTube recomenda e reproduz
vídeos de conspirações de esquerda,
											e a partir daí só piora.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Well, you might be thinking,
this is politics, but it's not.
											This isn't about politics.
											This is just the algorithm
figuring out human behavior.
											I once watched a video
about vegetarianism on YouTube
											and YouTube recommended
and autoplayed a video about being vegan.
											It's like you're never
hardcore enough for YouTube.
									","
											Bunun yalnızca siyaset olduğunu
düşünebilirsiniz ama değil.
											Bu siyasetle ilgili değil.
											Bu sadece insan davranışını
anlayan algoritma.
											Bir kez YouTube'ta vejeteryanlıkla
ilgili bir video izledim
											ve YouTube vegan olmak hakkında
bir video önerip oynattı.
											YouTube için hiçbir zaman
yeteri kadar cüretkar olamıyoruz.
									","
											Vous pensez peut-être
que c'est de la politique, mais non.
											Il ne s'agit pas de politique.
											Ce n'est qu'un algorithme
déterminant le comportement humain.
											Une fois, j'ai regardé une vidéo
sur le végétarisme sur YouTube
											et YouTube a recommandé et lancé
une vidéo sur le fait d'être végétalien.
											Vous n'êtes jamais
assez extrême pour YouTube.
									","
											Quizá estén pensando 
que se trata de política, pero no.
											No se trata de política.
											Es solo el algoritmo
entendiendo la conducta humana.
											Una vez miré un video
sobre el vegetarianismo en YouTube
											y YouTube me recomendó y reprodujo
un video sobre veganismo.
											Uno nunca es lo suficientemente
extremo para YouTube.
									","
											Podemos pensar que isto é política,
mas não é.
											Não se trata de política.
											Isto é só o algoritmo a desvendar
o comportamento humano.
											Uma vez, vi um vídeo
sobre vegetarianismo no YouTube
											e o YouTube recomendou e reproduziu
um vídeo sobre ser vegan.
											É como se nunca fôssemos
duros o suficiente para o YouTube.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											(Laughter)
									","
											(Gülüşmeler)
									","
											(Rires)
									","
											(Risas)
									","
											(Risos)
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So what's going on?
											Now, YouTube's algorithm is proprietary,
											but here's what I think is going on.
											The algorithm has figured out
											that if you can entice people
											into thinking that you can
show them something more hardcore,
											they're more likely to stay on the site
											watching video after video
going down that rabbit hole
											while Google serves them ads.
											Now, with nobody minding
the ethics of the store,
											these sites can profile people
											who are Jew haters,
											who think that Jews are parasites
											and who have such explicit
anti-Semitic content,
											and let you target them with ads.
											They can also mobilize algorithms
											to find for you look-alike audiences,
											people who do not have such explicit
anti-Semitic content on their profile
											but who the algorithm detects
may be susceptible to such messages,
											and lets you target them with ads, too.
											Now, this may sound
like an implausible example,
											but this is real.
											ProPublica investigated this
											and found that you can indeed
do this on Facebook,
											and Facebook helpfully
offered up suggestions
											on how to broaden that audience.
											BuzzFeed tried it for Google,
and very quickly they found,
											yep, you can do it on Google, too.
											And it wasn't even expensive.
											The ProPublica reporter
spent about 30 dollars
											to target this category.
									","
											Peki aslında ne oluyor?,
											YouTube algoritması patentli,
											yine de şöyle olduğunu düşünüyorum.
											Algoritma şunu fark etti ki
											insanları etkilemek için
											onlara daha cüretkar videolar sunarsan,
											muhtemelen sitede daha fazla kalacak,
											o anlaşılmaz yola girerek
ardı ardına video izleyecek,
											bu esnada Google da 
reklam sunacak.
											Hazır, işin etik kısmını 
önemseyen kimse de yokken,
											bu siteler,
											Yahudiler aleyhine paylaşım yapan
											ve onların parazit olduğunu düşünen
											radikal Yahudi düşmanları özelinde
profilleme yapabiliyor
											ve reklamlarla onları 
hedeflemenizi sağlıyor.
											Ayrıca algoritmaları genişleterek,
											sizin için benzer kitleler bulup
											profillerinde bu tip, Yahudi karşıtı, 
aykırı içerik bulunmayan
											fakat algoritmanın bu tür mesajlara karşı

											duyarlı olabileceğini belirlediği 
kişileri yakalıyor
											ve onları da reklamlarla 
hedeflemenize izin veriyor.
											İnanılmaz bir örnek gibi gelebilir
											ama bu gerçek.
											ProPublica bunu soruşturdu

											ve Facebook'ta bunu gerçekten
yapabileceğinizi ortaya koydu,
											Facebook ilgili kitleyi genişletmede
											öneriler sunarak yardımcı oldu.
											BuzzFeed bunu Google için denedi
ve hızla anladılar ki
											bunu Google'da da yapabiliyoruz.
											Pahalı bile değildi.
											ProPublica habercisi
bu kategoriyi hedeflemek için
											30 dolar kadar harcadı.
									","
											Que se passe-t-il ?
											L'algorithme de YouTube est propriétaire,
											mais voici ce qui, à mon avis, se passe.
											L'algorithme a déterminé
											que si vous pouvez pousser les gens
											à penser que vous pouvez leur montrer
quelque chose de plus extrême,
											ils ont plus de chances
de rester sur le site
											à regarder vidéo sur vidéo,
descendant dans le terrier du lapin
											pendant que Google leur sert des pubs.
											Puisque personne ne fait attention
à l'éthique du magasin,
											ces sites peuvent profiler des gens
											comme haïssant les juifs,
											pensant que les juifs sont des parasites,
											qui ont du contenu
anti-sémite très explicite,
											et vous laisser les cibler avec des pubs.
											Ils peuvent mobiliser les algorithmes
											pour trouver des publics similaires,
											des gens n'ayant pas de contenu
anti-sémite si explicite sur leur profil
											mais que les algorithmes détectent
comme étant sensibles à de tels messages,
											et vous laisser les cibler avec des pubs.
											Ça peut sembler être
un exemple peu plausible,
											mais c'est vrai.
											ProPublica a enquêté sur ça
											et a découvert que vous pouviez
vraiment le faire sur Facebook
											et Facebook, serviable,
offrait des suggestions
											sur comment étendre ce public.
											BuzzFeed l'a essayé pour Google
et a rapidement découvert
											que vous pouvez le faire sur Google.
											Ce n'était même pas cher.
											Le reporter de ProPublica
a dépensé environ 30 dollars
											pour cibler cette catégorie.
									","
											¿Qué está ocurriendo?
											El algoritmo de YouTube está patentado,
											pero esto es lo que creo que está pasando.
											El algoritmo ha descubierto
											que si puedes persuadir a la gente
											haciéndoles pensar que puedes
mostrarles algo más extremo,
											son más propensos a quedarse en el sitio
											viendo video tras video
adentrándose en el agujero de conejo
											mientras Google les sirve anuncios.
											Sin alguien a quien le importe
la ética de la tienda,
											estos sitios pueden retratar gente
											que odia a los judíos,
											que cree que los judíos son parásitos
											y que tiene contenido
antisemita explícito,
											y permitirte que les envíes anuncios.
											También pueden movilizar algoritmos
											para encontrar audiencias parecidas,
											gente que no tiene ese contenido
antisemita explícito en su perfil,
											pero a quien el algoritmo detecta
como susceptible a esos mensajes,
											y te permite enviarles anuncios también.
											Esto puede sonar
como un ejemplo inverosímil,
											pero es real.
											ProPublica lo investigó
											y encontró que de hecho
se puede hacer esto en Facebook,
											y Facebook amablemente 
nos ofreció sugerencias
											de cómo ampliar la audiencia.
											BuzzFeed lo intentó con Google,
											y en seguida vieron que sí,
que se puede hacer en Google también.
											Y no fue ni siquiera costoso.
											El reportero de ProPublica
gastó alrededor de 30 dólares
											para anunciarle a esa categoría.
									","
											Então o que é que se está a passar?
											O algoritmo do YouTube é patenteado,
											mas eis o que eu acho
que se está a passar:
											O algoritmo percebeu
											que, se pudermos levar as pessoas a pensar
											que lhes podemos mostrar
algo ainda mais forte,
											é mais provável que elas
se mantenham no ""site""
											a ver vídeo atrás de vídeo,
indo pela espiral abaixo,
											enquanto o Google lhes apresenta anúncios.
											Sem ninguém a preocupar-se
com a ética da loja,
											estes ""sites"" podem fazer
o perfil das pessoas
											que odeiam judeus,
											que acham que os judeus são parasitas
											e que têm conteúdos
explícitos antissemíticos
											e deixa-os selecioná-los para anúncios.
											Também podem mobilizar algoritmos
											para encontrarem
audiências semelhantes para nós,
											pessoas que não tenham conteúdos
antissemíticos explícitos no seu perfil
											mas que o algoritmo detetou como
possivelmente suscetíveis a tais mensagens
											e deixa que sejam também
alvos desses anúncios.
											Isto pode parecer um exemplo
pouco plausível,
											mas é a realidade.
											A ProPublica investigou isto
											e descobriu que se pode
fazer isto no Facebook.
											E o Facebook, prestavelmente,
oferecia sugestões
											para alargar essa audiência.
											O BuzzFeed tentou com o Google
e rapidamente descobriram
											que também dá para fazer com o Google.
											E nem sequer era caro.
											O repórter da ProPublica
gastou cerca de 30 dólares
											para escolher o grupo-alvo.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So last year, Donald Trump's
social media manager disclosed
											that they were using Facebook dark posts
to demobilize people,
											not to persuade them,
											but to convince them not to vote at all.
											And to do that,
they targeted specifically,
											for example, African-American men
in key cities like Philadelphia,
											and I'm going to read
exactly what he said.
											I'm quoting.
									","
											Geçen sene Trump'ın sosyal medya yetkilisi
kargaşayı sona erdirmek için
											gizli Facebook paylaşımları 
kullandıklarını açıkladı,
											insanları ikna için değil,
											hiç oy vermemelerini sağlamak için.
											Bunu yapmak için 
özel olarak hedef belirlediler,
											mesela önemli Philadelphia kentlerindeki 
Afro Amerikalı erkekler,
											hatta tam olarak ne dediğini okuyacağım.
											Alıntı yapıyorum.
									","
											L'année dernière, le responsable
des réseaux sociaux de Donald Trump
											a révélé utiliser les dark posts
de Facebook pour démobiliser les gens,
											pas pour les persuader,
											mais pour les convaincre
de ne pas voter du tout.
											Pour ce faire,
ils ont spécifiquement ciblé,
											par exemple, les hommes afro-américains
dans des villes clés comme Philadelphie
											et je vais lire exactement ce qu'il a dit.
											Je cite.
									","
											El año pasado, el asesor de medios 
de Donald Trump reveló
											que usaban publicaciones de página oculta
en Facebook para desmovilizar gente.
											No para persuadirlos,
											sino para convencerlos de no votar.
											Y para lograr eso,
se dirigieron a grupos específicos,
											por ejemplo, hombres afroamericanos
en ciudades clave como Filadelfia,
											y voy a leer exactamente lo que dijo.
											Cito.
									","
											No ano passado, o gestor
das redes sociais de Donald Trump
											revelou que estavam a usar
""publicações negras"" do Facebook
											para desmobilizar as pessoas
e não para as persuadir,
											mas para as convencer a não votar de todo.
											Para o fazer, escolheram especificamente
											por exemplo, homens afro-americanos
de cidades-chave, como Filadélfia.
											Vou ler exatamente o que ele disse.
											Estou a citar.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											They were using ""nonpublic posts
											whose viewership the campaign controls
											so that only the people
we want to see it see it.
											We modeled this.
											It will dramatically affect her ability
to turn these people out.""
									","
											''Görülebilirliğini siyasi
kampanyanın kontrol ettiği
											böylece sadece görmesini istediğimiz
insanların görebileceği
											herkese açık olmayan paylaşımlar.
											Bunu biz tasarladık.
											Bu, onun söz konusu insanları 

											kazanma yetisini önemli 
ölçüde etkileyecektir.''
									","
											Ils utilisaient « des posts non publics
											dont la campagne contrôle l'audience
											afin que seuls les voient les gens
dont nous voulons qu'ils les voient.
											Nous l'avons façonné.
											Ça affectera considérablement
sa capacité à retourner ces gens. »
									","
											Estaban usando ""publicaciones no públicas
											cuya audiencia controla la campaña
											para que solo la gente
que queremos pueda verlas"".
											""Modelamos esto"".
											""Esto afectará dramáticamente la habilidad
de ella para llevar votantes a las urnas"".
									","
											""Eles estavam a usar
publicações não públicas
											""cujas vizualizações
são controladas pela campanha,
											""de forma a que apenas as pessoas
que nós queremos que vejam, as vejam.
											""Nós modelámos isto.
											""Vai afetar drasticamente a capacidade
de afastar essas pessoas"".
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											What's in those dark posts?
											We have no idea.
											Facebook won't tell us.
									","
											Bu gizli paylaşımlarda ne var peki?
											Hiçbir fikrimiz yok.
											Facebook bize açıklamıyor.
									","
											Qu'y a-t-il dans ces dark posts ?
											Nous l'ignorons.
											Facebook refuse de le dire.
									","
											¿Qué hay en esas publicaciones
de página oculta?
											No tenemos idea.
											Facebook no nos lo dirá.
									","
											O que está nessas ""publicações negras""?
											Não fazemos ideia.
											O Facebook não nos diz.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So Facebook also algorithmically
arranges the posts
											that your friends put on Facebook,
or the pages you follow.
											It doesn't show you
everything chronologically.
											It puts the order in the way
that the algorithm thinks will entice you
											to stay on the site longer.
									","
											Facebook ayrıca algoritmik bir şekilde
arkadaşlarınızın paylaşımlarını
											ve takip ettiğiniz sayfaları düzenliyor.
											Size her şeyi
kronolojik olarak göstermiyor.
											Algoritmanın, sitede daha fazla 
kalmanızı sağlayacak şekilde
											kurduğu düzeni uyguluyor.
									","
											Facebook arrange également
algorithmiquement les posts
											que vos amis mettent sur Facebook
ou des pages que vous suivez.
											Il ne vous montre pas tout
chronologiquement.
											Il le met dans l'ordre qui,
selon l'algorithme, devrait vous pousser
											à rester plus longtemps sur le site.
									","
											Facebook también organiza
con un algoritmo las publicaciones
											que nuestros amigos ponen en Facebook,
o las páginas que seguimos.
											No nos muestra todo cronológicamente.
											Ordena según la manera en que el algoritmo
piensa que nos va a persuadir
											para quedarnos más tiempo en el sitio.
									","
											O Facebook também organiza
algoritmicamente essas publicações
											que os nossos amigos põem no Facebook
ou nas páginas que nós seguimos.
											Não nos mostra as publicações
por ordem cronológica.
											Ordena as publicações pela ordem
que o algoritmo acha
											que nos vai levar
a ficar mais tempo no ""site"".
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now, so this has a lot of consequences.
											You may be thinking
somebody is snubbing you on Facebook.
											The algorithm may never
be showing your post to them.
											The algorithm is prioritizing
some of them and burying the others.
									","
											Bunun pek çok sonucu var.
											Facebook'ta birinin takipçiniz olduğunu
düşünüyor olabiliirsiniz.
											Oysa algoritma sizin paylaşımınızı
asla onlara göstermiyor olabilir.
											Algoritma kimini öne çıkarırken
kimini ortadan kaldırıyor.
									","
											Ça a de nombreuses conséquences.
											Vous pensez peut-être que quelqu'un
vous ignore sur Facebook.
											L'algorithme ne lui montre
peut-être jamais vos posts.
											L'algorithme en priorise certains
et en enterre d'autres.
									","
											Esto tiene muchas consecuencias.
											Quizá estén pensando que alguien
los está desairando en Facebook.
											Pero quizá el algoritmo nunca
les muestra su publicación a ellos.
											El algoritmo prioriza 
algunas publicaciones e ignora otras.
									","
											Isto tem muitas consequências.
											Podemos achar que alguém
nos está a ignorar no Facebook.
											Mas o algoritmo pode não lhes estar
a mostrar as nossas publicações.
											O algoritmo está a dar prioridade
a algumas e a enterrar as outras.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Experiments show
											that what the algorithm picks to show you
can affect your emotions.
											But that's not all.
											It also affects political behavior.
											So in 2010, in the midterm elections,
											Facebook did an experiment
on 61 million people in the US
											that was disclosed after the fact.
											So some people were shown,
""Today is election day,""
											the simpler one,
											and some people were shown
the one with that tiny tweak
											with those little thumbnails
											of your friends who clicked on ""I voted.""
											This simple tweak.
											OK? So the pictures were the only change,
											and that post shown just once
											turned out an additional 340,000 voters
											in that election,
											according to this research
											as confirmed by the voter rolls.
											A fluke? No.
											Because in 2012,
they repeated the same experiment.
											And that time,
											that civic message shown just once
											turned out an additional 270,000 voters.
											For reference, the 2016
US presidential election
											was decided by about 100,000 votes.
											Now, Facebook can also
very easily infer what your politics are,
											even if you've never
disclosed them on the site.
											Right? These algorithms
can do that quite easily.
											What if a platform with that kind of power
											decides to turn out supporters
of one candidate over the other?
											How would we even know about it?
									","
											Deneyler gösteriyor ki
											algoritmanın sizin için seçtikleri
duygularınızı etkileyebilir.
											Bununla da bitmiyor.
											Siyasi davranışınızı da etkiliyor.
											2010 yılı orta dönem seçimlerinde,
											Facebook, ABD'deki 61 milyon insan üstünde
											daha sonra açıklanan bir deney yaptı.
											Bir grup insana
''Bugün seçim günü'' yazısı gösterildi,
											bu daha basit olandı,
											diğer bir gruba ise aynı şey, 
küçük bir farkla gösterildi:
											''Oy verdim'' butonuna 
tıklayan arkadaşlarının
											küçük fotoğraflarının bulunduğu versiyon.
											Bu kadar basit bir nüans.
											Değişen tek şey fotoğraflardı
											ve seçmen kütüğünce de onaylandığı üzere,
											bu araştırmaya istinaden
											yalnızca bir kez gösterilen bu paylaşım
											o seçimde
											340.000 ek seçmen olarak sonuçlandı.
											Şans eseri mi? Hayır.
											Çünkü 2012'de aynı deneyi tekrarladılar.
											O zaman,
											yalnızca bir kez gösterilen sivil mesaj
											270.000 ek seçmen olarak geri döndü.
											Hatırlatayım, 2016 ABD başkanlık seçimleri
											yaklaşık 100.000 oy farkıyla belirlendi.
											Yani Facebook kolaylıkla
politikanız hakkında çıkarım yapabiliyor,
											siz bunu sitede
hiç açıklamamış olsanız bile.
											Bu algoritmalar bunu
oldukça kolay başarabiliyorlar.
											Peki ya bu güce sahip bir platform
											bunu adaylardan birinin
destekçilerini arttırmak için kullanırsa?
											Bundan haberimiz olur mu?
									","
											Des expériences montrent
											que ce que l'algorithme
choisit de vous montrer
											peut influencer vos émotions.
											Mais ce n'est pas tout.
											Ça influence aussi
votre comportement politique.
											En 2010, aux élections de mi-mandat,
											Facebook a conduit une expérience
sur 61 millions de personnes américaines
											qui a été révélée après les faits.
											Certaines personnes ont vu
« Aujourd'hui, c'est jour d'élection »,
											le plus simple,
											et certaines personnes ont vu
celui avec ce petit ajustement
											avec les petites photos
											de vos amis ayant cliqué
sur « j'ai voté ».
											Ce simple ajustement.
											D'accord ? Les photos étaient
la seule modification
											et ce post montré qu'une seule fois
											a attiré 340 000 électeurs supplémentaires
											dans cette élection,
											d'après cette recherche
											et la liste des électeurs l'a confirmé.
											Un hasard ? Non.
											Parce qu'en 2012, ils ont reconduit
cette même expérience.
											A cette époque-là,
											ce message civique montré une seule fois
											a attiré 270 000 électeurs
supplémentaires.
											En guise de référence,
l'élection présidentielle de 2016
											s'est jouée à environ 100 000 votes.
											Facebook peut aussi très facilement
déduire vos opinions politiques,
											même si vous ne les avez pas
révélées sur le site.
											Ces algorithmes peuvent
le faire assez facilement.
											Et si une plateforme avec un tel pouvoir
											décidait de retourner les partisans
d'un candidat pour l'autre ?
											Comment le saurions-nous ?
									","
											Los experimentos muestran
											que lo que el algoritmo escoge
para mostrar, puede afectar las emociones.
											Pero eso no es todo.
											También afecta la conducta política.
											Así que en 2010, en la votación
a mitad de legislatura,
											Facebook hizo un experimento
con 61 millones de personas en EE. UU.
											y lo dio a conocer después.
											A algunas personas les mostraron
la publicación ""Hoy es día de votación"",
											la más sencilla,
											y a otras personas les mostraron 
la que tiene esa pequeña modificación,
											con esas miniaturas
											de tus amigos que cliquearon ""Voté"".
											Solo esa pequeña modificación.
											Así que las fotos 
fueron el único cambio,
											y esa publicación 
que fue mostrada solo una vez
											añadió 340 000 votantes
											en esa elección,
											según este estudio
											confirmado por los padrones electorales.
											¿Suerte? No.
											Porque en 2012, repitieron el experimento.
											Y esa vez,
											ese mensaje cívico mostrado una sola vez
											añadió 270 000 votantes.
											Como referencia, la elección 
presidencial de 2016 en EE. UU.
											se decidió por unos 100 000 votos.
											Facebook también puede inferir
muy fácilmente sus opiniones políticas,
											aun si nunca las han revelado en el sitio.
											Estos algoritmos pueden
lograrlo de manera sencilla.
											¿Qué pasaría si una plataforma
con ese tipo de poder
											decide ganar seguidores
para un candidato y no para el otro?
											¿Cómo lo sabríamos?
									","
											As experiências mostram
											que o que o algoritmo escolhe mostrar
pode afetar as nossas emoções.
											Mas isso não é tudo.
											Também afeta o comportamento político.
											Em 2010, nas eleições intercalares,
											o Facebook fez uma experiência
em 61 milhões de pessoas nos EUA
											facto que foi revelado depois do facto.
											Mostraram a algumas pessoas:
""Hoje é dia de eleições"",
											a versão mais simples,
											e a outras mostraram a versão
com aquela barrinha
											com as pequenas fotos dos amigos
que tinham clicado em ""Eu votei"".
											Essa simples barra, ok?
											As fotografias eram a única diferença,
											e essa publicação,
mostrada apenas uma vez
											mobilizou 340 mil votos adicionais
											naquelas eleições,
											de acordo com este estudo,
											como foi confirmado
pelos registos eleitorais.
											Um mero acaso? Não.
											Porque em 2012,
repetiram a mesma experiência.
											E dessa vez, aquela mensagem cívica
mostrada apenas uma vez,
											mobilizou 270 mil votos adicionais.
											Como referência, as eleições
presidenciais de 2016 nos EUA
											foram decididas apenas
por cerca de 100 mil votos.
											O Facebook consegue facilmente deduzir
quais são os nossos ideais políticos,
											mesmo que nunca os tenhamos
revelado no ""site"".
											Estes algoritmos conseguem
fazer isso muito facilmente.
											E se uma plataforma
com este tipo de poder
											decidir mobilizar apoiantes
de um candidato mais que de outro?
											Como é que sequer teríamos
conhecimento disso?
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now, we started from someplace
seemingly innocuous —
											online adds following us around —
											and we've landed someplace else.
											As a public and as citizens,
											we no longer know
if we're seeing the same information
											or what anybody else is seeing,
											and without a common basis of information,
											little by little,
											public debate is becoming impossible,
											and we're just at
the beginning stages of this.
											These algorithms can quite easily infer
											things like your people's ethnicity,
											religious and political views,
personality traits,
											intelligence, happiness,
use of addictive substances,
											parental separation, age and genders,
											just from Facebook likes.
											These algorithms can identify protesters
											even if their faces
are partially concealed.
											These algorithms may be able
to detect people's sexual orientation
											just from their dating profile pictures.
									","
											Masum gibi görünen bir yerden başladık:
											Bizi takip eden reklamlardan...
											şimdiyse çok farklı bir yerdeyiz.
											Hem halk hem de vatandaş olarak
											artık aynı bilgileri görüp görmediğimizi

											ve başkalarının ne gördüğünü bilmiyoruz
											ve ortak bir bilgi tabanı olmadan,
											adım adım,
											toplumsal tartışma imkansız hale geliyor,
											biz bunun sadece başlangıç aşamasındayız.
											Bu algoritmalar kolaylıkla
											insanların etnik özelliklerini,
											dini ve siyasi görüşlerini,
kişilik özelliklerini,
											zekasını, mutluluğunu,
madde kullanıp kullanmadığını,
											ailesinin durumunu, yaş ve cinsiyetini

											sadece Facebook beğenilerinden 
tahmin edebilir.
											Bu algoritmalar, yüzleri 
kısmen gizlenmiş olsa da
											protestocuların kimliğini belirleyebilir.
											Hatta bu algoritmalar
insanların cinsel yönelimini
											sadece tanışma uygulamalarındaki
profil fotoğraflarından anlayabilir.
									","
											Nous sommes partis de quelque chose
semble-t-il inoffensif —
											les pubs nous suivant partout en ligne —
											et sommes arrivés ailleurs.
											En tant que public et citoyens,
											nous ne savons plus
si nous voyons les mêmes informations
											ou ce que voient les autres
											et sans base d'informations commune,
											peu à peu,
											le débat public devient impossible
											et nous n'en sommes
qu'aux premières phases.
											Ces algorithmes peuvent facilement déduire
											des choses comme votre ethnie,
vos opinions religieuses, politiques,
											vos traits de personnalité,
											votre intelligence, votre bonheur,
votre usage de substances addictives,
											la situation maritale de vos parents,
votre âge et votre sexe,
											uniquement grâce
aux « J'aime » de Facebook.
											Ces algorithmes peuvent
identifier des manifestants
											même si leur visage
est partiellement caché.
											Ces algorithmes peuvent peut-être
détecter l'orientation sexuelle des gens
											simplement grâce à leur photo de profil
sur un site de rencontres.
									","
											Comenzamos en un lugar
aparentemente inocuo,
											anuncios en línea
siguiéndonos a todas partes,
											y hemos terminado en otro lugar.
											Como público y como ciudadanos,
											no sabemos ya si estamos viendo
la misma información
											o qué es lo que los demás ven,
											y sin una base común de información,
											poco a poco,
											el debate público
se está volviendo imposible,
											y eso que solo estamos
en las etapas iniciales de esto.
											Estos algoritmos pueden inferir fácilmente
											cosas como el origen étnico de la gente,
las ideas religiosas y políticas,
											la personalidad,
											la inteligencia, la felicidad,
el uso de sustancias adictivas,
											la separación de los padres,
la edad y género,
											solo con los ""me gusta"" de Facebook.
											Estos algoritmos pueden
identificar manifestantes
											incluso si sus caras están
parcialmente cubiertas.
											Estos algoritmos podrían detectar
la orientación sexual de la gente
											solo con sus fotos de perfil.
									","
											Começámos de um lugar
supostamente inócuo
											— anúncios ""online"" que nos perseguem —
											e chegámos a um local
completamente diferente.
											Como público e como cidadãos,
											nós já não sabemos se estamos a ver
as mesmas informações
											ou o que qualquer outra pessoa está a ver,
											e sem uma base comum de informações,
											pouco a pouco, o debate público
torna-se impossível,
											e estamos apenas no início de tudo isto.
											Estes algoritmos conseguem,
com bastante facilidade,
											deduzir coisas como a etnia das pessoas,
											as crenças religiosas e políticas,
traços de personalidade.
											inteligência, felicidade,
uso de substâncias aditivas,
											separações dos pais, idade e género,
											apenas pelos likes do Facebook.
											Estes algoritmos podem
identificar manifestantes
											mesmo se as suas caras estiverem
parcialmente escondidas.
											Estes algoritmos podem conseguir
detetar a orientação sexual duma pessoa
											apenas pelas fotografias
do perfil de encontros.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now, these are probabilistic guesses,
											so they're not going
to be 100 percent right,
											but I don't see the powerful resisting
the temptation to use these technologies
											just because there are
some false positives,
											which will of course create
a whole other layer of problems.
											Imagine what a state can do
											with the immense amount of data
it has on its citizens.
											China is already using
face detection technology
											to identify and arrest people.
											And here's the tragedy:
											we're building this infrastructure
of surveillance authoritarianism
											merely to get people to click on ads.
											And this won't be
Orwell's authoritarianism.
											This isn't ""1984.""
											Now, if authoritarianism
is using overt fear to terrorize us,
											we'll all be scared, but we'll know it,
											we'll hate it and we'll resist it.
											But if the people in power
are using these algorithms
											to quietly watch us,
											to judge us and to nudge us,
											to predict and identify
the troublemakers and the rebels,
											to deploy persuasion
architectures at scale
											and to manipulate individuals one by one
											using their personal, individual
weaknesses and vulnerabilities,
											and if they're doing it at scale
											through our private screens
											so that we don't even know
											what our fellow citizens
and neighbors are seeing,
											that authoritarianism
will envelop us like a spider's web
											and we may not even know we're in it.
									","
											Tabii bunlar olasılıksal tahminler,
											%100 doğru olamazlar
											ama insanlar sadece bazı
sonuçlar yanlış olduğu için
											bu teknolojileri kullanma 
arzularına direnmeyecekler,
											bu da beraberinde 
bir yığın farklı sorun getirecek.
											Devletlerin vatandaşları 
hakkında sahip oldukları
											müthiş miktarda veriyle
neler yapabileceklerini düşünün.
											Çin, insanları tespit etmek 
ve tutuklamak için
											yüz tanıma teknolojisini kullanıyor bile.
											İşin acı kısmı şu ki biz,
											gözetlemeye dayalı bu otoriter altyapıyı
											yalnızca insanların 
reklamlara tıklaması için geliştiriyoruz.
											Bu Orwell'in otoriter rejimi olmayacak.
											Bu ''1984'' değil.
											Eğer otoriterlik bizi paniğe sürüklemek 
için aleni korku kullanacaksa
											hepimiz korkacağız
ama bundan haberimiz olacak,
											nefret duyacağız ve karşı koyacağız.
											Ancak mevki sahibi insanlar
bu algoritmaları
											bizi sessizce izlemek,
											yargılamak ve dürtmek,
											sorun çıkaranlar ve asileri önceden
tahmin etmek ve kimliğini belirlemek,
											üzerimizde ikna mimarisi oluşturmak
											ve tek tek bireyleri manipüle etmek için
											kişisel zayıf ve hassas noktalarımızdan
yararlanarak kullanırlarsa,
											dahası bunu ölçeklendirip
											özel ekranlarımızdan
											çevremizdeki insanların
											ne gördüklerini bilemeyeceğimiz
bir şekilde yaparlarsa,
											bu otoriter rejim
bizi bir örümcek ağı gibi kıstırır
											ve biz yakalandığımızı bile anlamayız.
									","
											Ce sont des conjectures statistiques,
											ils n'auront pas raison à 100%,
											mais je ne vois pas les puissants résister
à la tentation d'utiliser ces technologies
											simplement parce qu'il y a
des faux positifs,
											ce qui, bien sûr, créera
un couche supplémentaire de problèmes.
											Imaginez ce qu'un Etat peut faire
											avec l'énorme volume de données
qu'il a sur ces citoyens.
											La Chine utilise déjà
une technologie de détection du visage
											pour identifier et arrêter des gens.
											Voici la tragédie :
											nous instaurons cette infrastructure
de surveillance d’autoritarisme
											simplement pour que les gens
cliquent sur des pubs.
											Ce ne sera pas l’autoritarisme d'Orwell.
											Ce n'est pas « 1984 ».
											Si l'autoritarisme une peur déclarée
pour nous terroriser,
											nous aurons tous peur
mais nous le saurons,
											nous détesterons ça et résisterons.
											Mais si les gens au pouvoir
utilisent ces algorithmes
											pour nous surveiller discrètement,
											pour nous juger et nous inciter,
											pour prédire et identifier
les fauteurs de trouble et les rebelles,
											pour déployer une architecture
de persuasion à grande échelle
											et pour manipuler les individus un par un
											grâce à leurs faiblesses et vulnérabilités
personnelles et individuelles
											et s'ils le font à grande échelle
											via nos écrans privés
											afin que nous ne sachions même pas
											ce que les autres citoyens
et nos voisins voient,
											l'autoritarisme nous enveloppera
tel une toile d'araignée
											et nous ignorons même
que nous sommes dans la toile.
									","
											Estas son especulaciones probables
											así que no serán 100 % atinadas,
											pero yo no me imagino a los poderosos
											resistiendo la tentación
de usar estas tecnologías
											solo porque haya algunos falsos positivos,
											lo cual creará, por supuesto,
otra oleada de problemas.
											Imaginen lo que puede hacer un estado
											con la enorme cantidad de datos
que tiene de sus ciudadanos.
											China ya está usando
tecnología de detección de rostros
											para identificar y arrestar gente.
											Y esta es la tragedia:
											Estamos construyendo esta infraestructura
de vigilancia y autoritarismo
											solo para obtener
más clics en los anuncios.
											Este no será el autoritarismo de Orwell.
											Esto no es ""1984"".
											Si el autoritarismo usa
el miedo para aterrorizarnos,
											todos estaremos asustados,
pero lo sabremos,
											lo odiaremos y lo resistiremos.
											Pero si la gente en el poder
está usando estos algoritmos
											para vigilarnos calladamente,
											para juzgarnos y empujarnos,
											para predecir e identificar
a los agitadores y a los rebeldes,
											para desplegar arquitecturas
de persuasión a escala
											y para manipularnos uno por uno
											usando las debilidades y vulnerabilidades
personales e individuales de cada uno,
											y si lo están haciendo a escala
											con nuestras pantallas personales
											para que ni siquiera sepamos
											lo que ven nuestros
compañeros ciudadanos y vecinos,
											ese autoritarismo nos atrapará
como una telaraña
											y quizá ni siquiera sepamos
que estamos en ella.
									","
											Estes são palpites probabilísticos,
											por isso não vão estar 100% corretos.
											Mas eu não vejo os poderosos a resistir
à tentação de usar estas tecnologias
											apenas porque há alguns falsos positivos,
											o que, claro, vai criar
toda uma outra camada de problemas.
											Imaginem o que um Estado pode fazer
											com a quantidade imensa de informações
que tiver dos seus cidadãos.
											A China já está a usar tecnologia
de reconhecimento facial.
											para identificar e deter pessoas.
											E a tragédia é esta:
											estamos a construir esta infraestrutura
de vigilância autoritária
											apenas para fazer as pessoas
clicar em anúncios.
											Este não vai ser
o autoritarismo de Orwell.
											Não é o ""1984"".
											Se o autoritarismo usar medo explícito
para nos aterrorizar
											nós ficaremos assustados,
mas temos consciência disso,
											vamos odiá-lo e vamos resistir-lhe.
											Mas se as pessoas no poder
usarem estes algoritmos
											para, silenciosamente, nos vigiarem,
											para nos julgarem
e para nos influenciarem,
											para preverem e para identificarem
os desordeiros e os rebeldes,
											para implementarem técnicas
de persuação em larga escala
											e para manipularem indivíduos,
um por um,
											usando fraquezas e vulnerabilidades
individuais e pessoais,
											e se o estão a fazer em larga escala,
											através dos nossos ecrãs privados,
											para que nós nem saibamos
											o que os outros cidadãos
e vizinhos estão a ver,
											esse autoritarismo vai envolver-nos
como uma teia de aranha
											e podemos nem dar conta
de que estamos nela.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So Facebook's market capitalization
											is approaching half a trillion dollars.
											It's because it works great
as a persuasion architecture.
											But the structure of that architecture
											is the same whether you're selling shoes
											or whether you're selling politics.
											The algorithms do not know the difference.
											The same algorithms set loose upon us
											to make us more pliable for ads
											are also organizing our political,
personal and social information flows,
											and that's what's got to change.
									","
											Facebook'un piyasa değeri
											yarım trilyon dolara yaklaşıyor.
											Bunun sebebi ikna mimarisi olarak
harika çalışıyor olması.
											Ancak bu mimari yapı
											ayakkabı satıyor olsanız da aynı
											siyaset satıyor olsanız da.
											Algoritmalar farkı anlamıyor.
											Reklamlara karşı bizi sabırlı kılmak için
											üzerimize salınan bu algoritmalar,
											aynı zamanda siyasi, kişisel ve sosyal
bilgi akışımızı da düzenliyor
											ve bu değişmek zorunda.
									","
											La capitalisation du marché de Facebook
											approche le demi milliard de dollars.
											C'est parce que c'est une très bonne
architecture de persuasion.
											Mais la structure de cette architecture
											est la même que vous vendiez
des chaussures
											ou de la politique.
											Les algorithmes
ne connaissent pas la différence.
											Les mêmes algorithmes utilisés sur nous
											pour nous rendre plus malléables
face aux publicités
											organisent aussi nos flux d'informations
politiques, personnelles et sociales
											et ça doit changer.
									","
											Así que la capitalización 
de mercado de Facebook
											se acerca a medio billón de dólares.
											Es porque funciona muy bien
como arquitectura de persuasión.
											Pero la estructura de esa arquitectura
											es la misma, sea que vendan zapatos
											o sea que vendan política.
											Los algoritmos no ven la diferencia.
											Los mismos algoritmos
utilizados en nosotros
											para hacernos más receptivos
a los anuncios,
											también organizan nuestros flujos
de información política, social y personal
											y eso debe cambiar.
									","
											A capitalização de mercado do Facebook
											está a aproximar-se
de meio bilião de dólares.
											É porque funciona lindamente
como arquitetura de persuasão.
											Mas a estrutura desta arquitetura
											é a mesma, quer estejam a vender sapatos
											ou a vender política.
											Os algoritmos não sabem a diferença.
											O mesmo algoritmo que faz
o que quer connosco,
											para nos deixar
mais vulveráveis a anúncios,
											também organiza o fluxo
das nossas informações
											políticas, pessoais e sociais
											e é isso que tem de mudar.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Now, don't get me wrong,
											we use digital platforms
because they provide us with great value.
											I use Facebook to keep in touch
with friends and family around the world.
											I've written about how crucial
social media is for social movements.
											I have studied how
these technologies can be used
											to circumvent censorship around the world.
											But it's not that the people who run,
you know, Facebook or Google
											are maliciously and deliberately trying
											to make the country
or the world more polarized
											and encourage extremism.
											I read the many
well-intentioned statements
											that these people put out.
											But it's not the intent or the statements
people in technology make that matter,
											it's the structures
and business models they're building.
											And that's the core of the problem.
											Either Facebook is a giant con
of half a trillion dollars
											and ads don't work on the site,
											it doesn't work
as a persuasion architecture,
											or its power of influence
is of great concern.
											It's either one or the other.
											It's similar for Google, too.
									","
											Beni yanlış anlamayın,
											bize büyük fayda sağladıkları için
dijital platformları kullanıyoruz.
											Facebook ile dünyanın her yerinden
aile ve arkadaşlarımla görüşebiliyorum.
											Sosyal medyanın, sosyal hareketler için
ne kadar önemli olduğu hakkında yazdım.
											Bu teknolojilerin dünyadaki
sansür uygulamalarını aşmak için
											nasıl kullanılabileceği üzerine çalıştım.
											Facebook ve Google yöneticilerinin
											kasten ve kötü niyetli bir şekilde
											ülkeyi ve dünyayı kutuplaştırmaya

											veya radikalliği teşvik etmeye 
çalıştığını söylemiyorum.
											Bu insanların yayınladığı
											pek çok iyi niyetli yazı okudum.
											Ancak bu konuda 
niyet veya ifadelerin bir önemi yok.
											Sorun, inşa ettikleri bu yapı 
ve iş modelleri.
											Sorunun kökeninde bu var.
											Ya Facebook yarım trilyon
değerinde dev bir yapı
											ve reklamlar bu sitede çalışmıyor,
											ikna mimarisi olarak faaliyet göstermiyor
											ya da etki gücü dehşet verici.
											İkisinden biri.
											Google için de aynısı söz konusu.
									","
											Ne vous méprenez pas,
											nous utilisons les plateformes numériques
car elles ont beaucoup de valeur.
											J'utilise Facebook pour garder contact
											avec des amis et de la famille
à travers le monde.
											J'ai écrit sur l'importance des réseaux
sociaux pour les mouvements sociaux.
											J'ai étudié comment ces technologies
peuvent être utilisées
											pour contourner la censure
à travers le monde.
											Ce n'est pas que les dirigeants
de Facebook ou Google
											essayent perfidement et délibérément
											de polariser plus le pays ou le monde
											et d'encourager l'extrémisme.
											J'ai lu les nombreuses déclarations
bien intentionnées
											que ces gens ont publiées.
											Mais ce n'est pas l'intention
ou les déclarations
											des gens dans les technologies
qui comptent,
											ce sont les structures
et les modèles commerciaux qu'ils créent.
											C'est le cœur du problème.
											Soit Facebook est un escroc
d'un demi milliard de dollars
											et les pubs ne marchent pas sur le site,
											ça ne marche pas
comme une architecture de persuasion
											ou son pouvoir d'influence
est très préoccupant.
											C'est l'un ou l'autre.
											Il en va de même pour Google.
									","
											No me malinterpreten,
											usamos plataformas digitales
porque nos ofrecen muchísimo.
											Yo uso Facebook para estar en contacto
con amigos y familia alrededor del mundo.
											He escrito acerca lo cruciales que son
las redes para los movimientos sociales.
											He estudiado cómo pueden
usarse estas tecnologías
											para eludir la censura en todo el mundo.
											Pero no es que la gente
que administra Facebook o Google
											esté tratando maliciosa y deliberadamente
											de polarizar un país o el mundo
											y promover el extremismo.
											He leído las muchas y
bien intencionadas afirmaciones
											que esa gente publica.
											Pero no son sus intenciones 
ni las afirmaciones lo que importa,
											son las estructuras y modelos de negocio
que están construyendo.
											Y ese es el meollo del problema.
											O Facebook es una estafa gigante
de medio billón de dólares,
											los avisos en el sitio no funcionan
											y no sirve como
arquitectura de persuasión,
											o su poder de influencia
es altamente preocupante.
											Debe ser una o la otra.
											Es similar también para Google.
									","
											Não me interpretem mal.
											Nós usamos plataformas digitais
porque são valiosas para nós.
											Eu uso o Facebook para me manter
em contacto
											com a família e amigos de todo o mundo.
											Eu já escrevi sobre o quão cruciais
são as redes sociais
											para os movimentos sociais.
											Já estudei o modo como estas tecnologias
podem ser usadas
											para contornar a censura a nível mundial.
											Não que as pessoas que controlam
o Facebook e o Google
											estejam, maliciosa e deliberadamente,
											a tentar tornar o país ou o mundo
mais polarizado
											e a encorajar o extremismo.
											Li as várias declarações bem-intencionadas
											que essas pessoas publicaram.
											Mas não é a intenção ou as declarações
que as pessoas da tecnologia fazem
											que importam.
											São as estruturas e os modelos de negócio
que estão a construir.
											E isso é a base do problema.
											Ou o Facebook é uma enorme fraude
de meio bilião de dólares
											e os anúncios não funcionam no ""site"",
											não funcionam como
uma arquitetura de persuasão,
											ou o seu poder e influência
são uma grande preocupação.
											Ou é uma coisa ou é outra.
											E passa-se o mesmo com o Google.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So what can we do?
											This needs to change.
											Now, I can't offer a simple recipe,
											because we need to restructure
											the whole way our
digital technology operates.
											Everything from the way
technology is developed
											to the way the incentives,
economic and otherwise,
											are built into the system.
											We have to face and try to deal with
											the lack of transparency
created by the proprietary algorithms,
											the structural challenge
of machine learning's opacity,
											all this indiscriminate data
that's being collected about us.
											We have a big task in front of us.
											We have to mobilize our technology,
											our creativity
											and yes, our politics
											so that we can build
artificial intelligence
											that supports us in our human goals
											but that is also constrained
by our human values.
											And I understand this won't be easy.
											We might not even easily agree
on what those terms mean.
											But if we take seriously
											how these systems that we
depend on for so much operate,
											I don't see how we can postpone
this conversation anymore.
											These structures
											are organizing how we function
											and they're controlling
											what we can and we cannot do.
											And many of these ad-financed platforms,
											they boast that they're free.
											In this context, it means
that we are the product that's being sold.
											We need a digital economy
											where our data and our attention
											is not for sale to the highest-bidding
authoritarian or demagogue.
									","
											Peki ne yapabiliriz?
											Bunun değişmesi gerekiyor.
											Basit bir formül öneremem
											çünkü dijital teknolojimizin
çalışma şeklini
											yeniden inşa etmemiz gerekiyor.
											Teknolojinin geliştirilme biçiminden, 

											ekonomik ve diğer alanlardaki teşviklerin
											sisteme taşınmasına kadar her şey...
											Tescilli algoritmalar tarafından yaratılan
şeffaflık noksanlığı,
											makine öğrenimi anlaşılmazlığının
yapısal zorluğu
											ve hakkımızda toplanan tüm bu
rastgele veri sorunlarıyla yüzleşmek
											ve bunların üstesinden
gelmeye çalışmak zorundayız.
											Bize büyük bir görev düşüyor.
											Teknolojimizi, yaratıcılığımızı
											ve evet, siyasetimizi
											harekete geçirmemiz lazım,
											böylece kişisel amaçlarımızda 
bizi destekleyen
											fakat insani değerlere de bağlı
											yapay zekayı inşa edebiliriz.
											Bunun kolay olmayacağını biliyorum.
											Bu terimlerin ne anlama geldiği
konusunda bile kolayca anlaşamayabiliriz.
											Ancak bu kadar çok faaliyet konusunda
											sürekli ihtiyaç duyduğumuz bu sistemlerin
çalışma şeklini ciddiye alırsak,
											bu konuşmayı ertelemek için
hiçbir sebep göremiyorum.
											Bu yapılar,
											bizim işleyişimizi düzenliyor
											ve ne yapıp ne yapamayacağımızı
kontrol ediyor.
											Reklamla finanse edilen 
bu platformların çoğu
											ücretsiz olmakla övünüyorlar.
											Bu bağlamda, bunun anlamı şu: 
Satılmakta olan ürün biziz.
											Veri ve dikkatimizin
											en yüksek ücreti veren 
otoriter veya demagoga satılmadığı
											bir dijital ekonomiye ihtiyacımız var.
									","
											Que pouvons-nous faire ?
											Ça doit changer.
											Je ne peux pas offrir de recette simple
											car nous devons restructurer
											tout le fonctionnement
de notre technologie numérique.
											Tout, de la façon dont
la technologie est développée
											à la façon dont les incitations,
économiques et autres,
											sont intégrées au système.
											Nous devons faire face et gérer
											le manque de transparence créé
par les algorithmes propriétaires,
											le défi structurel de l'opacité
de l'apprentissage des machines,
											toutes ces données
aveuglément collectées sur nous.
											Nous avons devant nous
une tâche importante.
											Nous devons mobiliser notre technologie,
											notre créativité
											et oui, notre science politique
											pour créer une intelligence artificielle
											qui soutient nos objectifs humains
											mais qui est aussi contrainte
par nos valeurs humaines.
											Je comprends que ce ne sera pas simple.
											Nous ne serons pas facilement d'accord
sur le sens de ces termes.
											Mais si nous prenons au sérieux
											le fonctionnement de ces systèmes
dont nous sommes si dépendants,
											je ne vois pas comment nous pouvons
encore retarder cette conversation.
											Ces structures organisent
notre fonctionnement
											et elles contrôlent
ce que nous pouvons faire ou non.
											Beaucoup de ces plateformes
financées par les pubs
											se proclament gratuites.
											Dans ce contexte, ça signifie
que nous sommes le produit qui est vendu.
											Nous avons besoin
d'une économie numérique
											où nos données et notre attention
											ne sont pas à vendre à l'autoritariste
ou au démagogue le plus offrant.
									","
											Así que, ¿qué podemos hacer?
											Esto necesita cambiar.
											No puedo ofrecerles una receta simple,
											porque necesitamos reestructurar
											completamente cómo opera
nuestra tecnología digital.
											Todo, desde la manera 
en que se desarrolla la tecnología
											hasta la manera en que los incentivos,
económicos y demás,
											están incorporados al sistema.
											Tenemos que encarar y tratar de lidiar
con la falta de transparencia
											creada por los algoritmos patentados,
											el desafío estructural en la opacidad
del aprendizaje automático,
											todos estos datos sobre nosotros
recolectados indiscriminadamente.
											Tenemos una gran tarea por delante.
											Tenemos que movilizar nuestra tecnología,
											nuestra creatividad
											y sí, nuestra política,
											para que podamos construir
inteligencia artificial
											que apoye nuestros objetivos humanos,
											pero que también esté limitada
por nuestros valores humanos.
											Entiendo que esto no será sencillo.
											Quizá ni siquiera acordemos fácilmente
qué significan esos términos.
											Pero si nos tomamos en serio
											cómo operan estos sistemas
de los que dependemos para tantas cosas,
											no veo cómo podemos seguir
posponiendo esta conversación.
											Estas estructuras
											están organizando cómo funcionamos
											y están controlando
											lo que podemos y no podemos hacer.
											Muchas de estas plataformas
financiadas por anuncios
											presumen de ser gratuitas.
											En este contexto, eso significa
que nosotros somos el producto de venta.
											Necesitamos una economía digital
											donde nuestros datos y nuestra atención
											no estén a la venta para el autoritario
o demagogo que pague más.
									","
											Então o que é que podemos fazer?
											Isto tem de mudar.
											Não consigo apresentar uma receita simples
											porque é preciso reestruturar
											toda a maneira como a nossa
tecnologia digital funciona.
											Tudo, desde a maneira
como a tecnologia é desenvolvida
											até à maneira como os incentivos,
económicos e não só,
											estão construídos no sistema.
											Temos de encarar e tentar lidar
com a falta de transparência
											criada pelos algoritmos patenteados,
											o problema estrutural da opacidade
da aprendizagem de máquinas,
											e todas estas informações indiscriminadas
que estão a ser recolhidas sobre nós.
											Temos uma grande tarefa à nossa frente.
											Temos de mobilizar a nossa tecnologia,
											a nossa criatividade
											e sim, a nossa política
											para conseguirmos construir
uma inteligência artificial
											que nos apoie nas nossas metas humanas
											mas que também seja limitada
pelos nossos valores humanos.
											Eu compreendo que não vai ser fácil.
											Podemos até nem concordar facilmente
no que significam estes termos.
											Mas, se levarmos a sério
											como funcionam estes sistemas
de que dependemos para tanta coisa,
											não vejo como podemos
adiar mais esta conversa.
											Estas estruturas estão a organizar
											o modo como nós funcionamos
											e estão a controlar
											o que podemos fazer ou não.
											Muitas destas plataformas
financiadas por anúncios
											gabam-se de serem gratuitas.
											O que, neste contexto, quer dizer
											que somos nós o produto
que estão a vender.
											Precisamos de uma economia digital
											em que as nossas informações
e a nossa atenção
											não estejam à venda
para o déspota ou o demagogo
											que esteja disposto a pagar mais.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											(Applause)
									","
											(Alkışlar)
									","
											(Applaudissements)
									","
											(Aplausos)
									","
											(Aplausos)
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											So to go back to
that Hollywood paraphrase,
											we do want the prodigious potential
											of artificial intelligence
and digital technology to blossom,
											but for that, we must face
this prodigious menace,
											open-eyed and now.
									","
											Şu Hollywood sözüne
geri dönmek gerekirse,
											yapay zeka ve dijital
teknolojinin müthiş potansiyelinin
											çiçek açmasını elbette istiyoruz
											fakat bunun olması için
bu müthiş tehditle yüzleşmemiz lazım,
											gözlerimiz tamamen açık ve şimdi.
									","
											Pour revenir à cette paraphrase
hollywoodienne,
											nous voulons que le grand pouvoir
											de l'intelligence artificielle
et de la technologie numérique fleurisse
											mais pour ça , nous devons
faire face à une grande menace,
											les yeux ouverts et maintenant.
									","
											Así que, volviendo
a la paráfrasis de Hollywood:
											Sí, queremos que el enorme potencial
											de la inteligencia artificial 
y la tecnología digital florezca,
											pero para eso debemos enfrentar
esta enorme amenaza,
											con los ojos abiertos y ahora.
									","
											Para voltar à paráfrase de Hollywood,
											nós queremos que o prodigioso potencial
											da inteligência artificial
e da tecnologia digital floresça
											mas, para isso, temos de enfrentar
esta prodigiosa ameaça
											de olhos bem abertos e já.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											Thank you.
									","
											Teşekkür ederim.
									","
											Merci.
									","
											Gracias.
									","
											Obrigada.
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
											(Applause)
									","
											(Alkışlar)
									","
											(Applaudissements)
									","
											(Aplausos)
									","
											(Aplausos)
									",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
"
","
","
","
","
",We're building a dystopia just to make people click on ads,Zeynep Tufekci,22:55,"machine learning,AI,politics,algorithm,business,sociology,corruption,consumerism,data,economics,government,democracy,social media,social change,society,technology"
