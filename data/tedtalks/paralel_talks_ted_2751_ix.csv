en,tr,de,title,speaker,duration,tags
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											After 13.8 billion years
of cosmic history,
											our universe has woken up
											and become aware of itself.
											From a small blue planet,
											tiny, conscious parts of our universe
have begun gazing out into the cosmos
											with telescopes,
											discovering something humbling.
											We've discovered that our universe
is vastly grander
											than our ancestors imagined
											and that life seems to be an almost
imperceptibly small perturbation
											on an otherwise dead universe.
											But we've also discovered
something inspiring,
											which is that the technology
we're developing has the potential
											to help life flourish like never before,
											not just for centuries
but for billions of years,
											and not just on earth but throughout
much of this amazing cosmos.
									","
											13,8 milyar yıllık kozmik geçmişin 
ardından
											evrenimiz uyandı
											ve kendi farkına vardı.
											Küçük mavi bir gezegenden
											evrenimizin ufacık, bilinçli parçaları 
uzayı teleskoplarla
											gözetlemeye başladılar
											ve mahçup edici bir şey keşfettiler.
											Evrenimizin atalarımızın düşündüğünden
											çok daha büyük olduğunu
											ve hayatın, aksi taktirde ölü olacak
bir evrende ufacık ve belli belirsiz
											bir sapma olduğunu keşfettik.
											Aynı zamanda büyüleyici
bir şey keşfettik;
											geliştirdiğimiz teknolojinin,
hayatın ilerlemesine
											yardım etme potansiyelinin daha önce 
hiç olmadığı kadar fazla olduğunu
											sadece yüzyıllardır değil
milyarlarca senedir
											ve sadece dünyada değil, 
bu müthiş evrenin birçok yerinde...
									","
											Nach 13,8 Milliarden Jahren
kosmischer Geschichte
											ist unser Universum aufgewacht
											und sich seiner selbst bewusst geworden.
											Von einem kleinen blauen Planeten aus
											haben winzige, bewusste
Teile unseres Universums begonnen,
											mit Teleskopen in den Kosmos zu schauen
											und etwas Demütigendes entdeckt.
											Nämlich, dass das Universum sehr viel
größer ist, als unsere Vorfahren glaubten,
											und das Leben eine fast
unmerklich kleine Störung
											eines sonst toten Universums
zu sein scheint.
											Aber wir haben auch
etwas Inspirierendes entdeckt,
											nämlich, dass unsere Technologie
das Potenzial hat,
											das Leben wie nie zuvor
florieren zu lassen.
											Nicht nur für Jahrhunderte,
sondern für Milliarden von Jahren.
											Nicht nur auf der Erde,
sondern in einem Großteil des Kosmos.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											I think of the earliest life as ""Life 1.0""
											because it was really dumb,
											like bacteria, unable to learn
anything during its lifetime.
											I think of us humans as ""Life 2.0""
because we can learn,
											which we in nerdy, geek speak,
											might think of as installing
new software into our brains,
											like languages and job skills.
											""Life 3.0,"" which can design not only
its software but also its hardware
											of course doesn't exist yet.
											But perhaps our technology
has already made us ""Life 2.1,""
											with our artificial knees,
pacemakers and cochlear implants.
									","
											En erken yaşamı ""Yaşam 1.0""
olarak düşünüyorum
											çünkü gerçekten aptaldı,
											bakteri gibi, yaşamı boyunca
öğrenmekten aciz.
											Biz insanları ""Yaşam 2.0"" olarak
tahayyül ediyorum çünkü öğrenebiliyoruz
											bilgisayar diliyle konuşursak
											beynimize yeni bir program kurmak
ile kıyaslanabilir,
											diller ve iş becerileri gibi.
											Kendi yazılımını ve donanımını
tasarlayan ""Yaşam 3.0""
											tabii ki henüz mevcut değil.
											Ama belki teknolojimiz bizi zaten
""Yaşam 2.1"" yapmıştır
											yapay dizlerimiz, kalp pillerimiz
ve biyonik kulaklarımız ile.
									","
											Ich denke an erstes Leben als ""Life 1.0"",
											weil es wirklich dumm war,
											wie etwa Bakterien, unfähig,
irgendetwas in seinem Leben zu lernen.
											Ich denke an uns Menschen als ""Life 2.0"",
weil wir lernen können.
											Etwas langweilig gesagt,
											entspricht das der Installation
neuer Software in unser Gehirn
											wie etwa Sprachen
oder berufliche Fertigkeiten.
											""Leben 3.0"", das neben seiner Software
auch seine Hardware entwerfen kann,
											existiert natürlich noch nicht.
											Aber vielleicht sind wir mit unserer
Technologie auch schon bei ""Life 2.1"",
											mit unseren künstlichen Knien,
Schrittmachern und Cochlea-Implantaten.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											So let's take a closer look
at our relationship with technology, OK?
											As an example,
											the Apollo 11 moon mission
was both successful and inspiring,
											showing that when we humans
use technology wisely,
											we can accomplish things
that our ancestors could only dream of.
											But there's an even more inspiring journey
											propelled by something
more powerful than rocket engines,
											where the passengers
aren't just three astronauts
											but all of humanity.
											Let's talk about our collective
journey into the future
											with artificial intelligence.
									","
											O zaman teknoloji ile olan ilişkimize
daha yakından bakalım mı?
											Örnek verecek olursak
											Apollo 11 ay misyonunun
hem başarılı hem de ilham verici olması
											biz insanların, teknolojiyi 
akıllıca kullandığımızda
											atalarımızın sadece hayal edebilecekleri 
şeyleri başarabildiğimizi gösteriyor.
											Ama daha da ilham verici bir yolculuk var
											roket motorundan daha güçlü
bir şey ile çalıştırılan,
											yolcuları sadece üç astronottan değil,
											bütün insanlıktan oluşan.
											Yapay zekâ ile geleceğe 

											ortak yolculuğumuzdan bahsedelim.
									","
											Sehen wir uns also unsere Beziehung
zur Technologie genauer an:
											Die Mondmission Apollo 11 etwa
											war sowohl erfolgreich
als auch inspirierend
											und zeigte, dass wir Menschen
bei weisem Umgang mit Technologie
											Dinge erreichen können, von denen
unsere Vorfahren nur träumen konnten.
											Aber es gibt eine
noch inspirierendere Reise,
											angetrieben von etwas,
das mächtiger ist als Raketentriebwerke,
											wo die Passagiere nicht nur
drei Astronauten,
											sondern die ganze Menschheit ist.
											Ich meine unsere gemeinsame Reise
											in eine Zukunft
mit künstlicher Intelligenz.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											My friend Jaan Tallinn likes to point out
that just as with rocketry,
											it's not enough to make
our technology powerful.
											We also have to figure out,
if we're going to be really ambitious,
											how to steer it
											and where we want to go with it.
											So let's talk about all three
for artificial intelligence:
											the power, the steering
and the destination.
									","
											Arkadaşım Jaan Tallinn, füze biliminde
olduğu gibi
											teknolojiyi güçlendirmemizin 
yeterli olmadığını ifade ediyor.
											Aynı zamanda gerçekten 
azimli olup olmayacağımızı,
											nasıl yönlendireceğimizi
											ve hedefimizi çözmemiz lazım.
											Yapay zekâ bakımından 
önemli üç konudan da bahsedelim:
											güç, yönlendirme ve hedef.
									","
											Mein Freund Jaan Tallinn zeigt gerne auf,
dass es, genau wie bei der Raketentechnik,
											nicht ausreicht, unsere Technologie
leistungsfähig zu machen.
											Wir müssen auch herausfinden,
wie wir sie steuern
											und wohin wir gehen wollen,
											wenn wir ehrgeizig sein wollen.
											Sprechen wir über alle drei Punkte,
die künstliche Intelligenz betreffend:
											die Leistung, die Lenkung und das Ziel.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											Let's start with the power.
											I define intelligence very inclusively —
											simply as our ability
to accomplish complex goals,
											because I want to include both
biological and artificial intelligence.
											And I want to avoid
the silly carbon-chauvinism idea
											that you can only be smart
if you're made of meat.
											It's really amazing how the power
of AI has grown recently.
											Just think about it.
											Not long ago, robots couldn't walk.
											Now, they can do backflips.
											Not long ago,
											we didn't have self-driving cars.
											Now, we have self-flying rockets.
											Not long ago,
											AI couldn't do face recognition.
											Now, AI can generate fake faces
											and simulate your face
saying stuff that you never said.
											Not long ago,
											AI couldn't beat us at the game of Go.
											Then, Google DeepMind's AlphaZero AI
took 3,000 years of human Go games
											and Go wisdom,
											ignored it all and became the world's best
player by just playing against itself.
											And the most impressive feat here
wasn't that it crushed human gamers,
											but that it crushed human AI researchers
											who had spent decades
handcrafting game-playing software.
											And AlphaZero crushed human AI researchers
not just in Go but even at chess,
											which we have been working on since 1950.
									","
											Güç ile başlayalım.
											Ben zekâyı çok kapsamlı ama
basit bir şekilde,
											karışık hedeflerin üstesinden
gelme yeteneğimiz olarak tanımlıyorum
											çünkü hem biyolojik hem de
yapay zekâyı dâhil etmek istiyorum.
											Karbon şovenizminin 'sadece 
etten kemikten isen zeki olabilirsin'
											şeklindeki saçma sapan fikrini 
çürütmek istiyorum.
											Son zamanlarda yapay zekânın gücü
inanılmaz derecede arttı.
											Sadece bir düşünün.
											Daha düne kadar
robotlar yürüyemiyordu.
											Şimdi ise ters takla atabiliyorlar.
											Daha düne kadar
											sürücüsüz arabalarımız yoktu.
											Şimdi ise pilotsuz roketlerimiz var.
											Daha düne kadar
											yapay zekânın yüz tanımlaması yoktu.
											Şimdi ise yapay zekâ 
sahte yüzler oluşturup
											yüzünü hiç söylemediğin şeyleri
söylüyormuş gibi taklit edebiliyor.
											Daha düne kadar
											yapay zekâ, Go oyununda bizi yenemezdi.
											Sonra Google DeepMind'ın AlphaZero
yapay zekâsı 3000 yıllık Go oyunlarını
											ve Go bilgeliğini alıp
											görmezden geldi ve kendisine karşı
oynayarak dünyanın en iyi oyuncusu oldu.
											Burada en çarpıcı başarı 
oyuncuları yenmesi değil
											senelerini oyun oynama yazılımlarının
geliştirilmesine adamış
											yapay zekâ araştırmacılarını yenmesi.
											Ve AlphaZero yapay zekâ araştırmacıları
sadece Go'da değil
											1950'den beri üzerinde çalıştığımız 
satrançta bile yendi.
									","
											Beginnen wir mit der Leistung.
											Ich definiere Intelligenz sehr offen,
											einfach als die Fähigkeit,
komplexe Ziele zu erreichen,
											weil ich sowohl biologische als auch
künstliche Intelligenz einbeziehen will.
											Ich möchte den albernen Kohlenstoff-
Chauvinismus vermeiden,
											dass nur klug sein kann,
was aus Fleisch besteht.
											Es ist erstaunlich, wie die Leistung
der KI in letzter Zeit gewachsen ist.
											Denken Sie mal nach.
											Vor nicht langer Zeit
konnten Roboter nicht laufen.
											Jetzt können sie Rückwärtssaltos machen.
											Vor nicht langer Zeit
											gab es keine selbstfahrenden Autos.
											Jetzt gibt es selbstfliegende Raketen.
											Vor nicht langer Zeit
											konnte KI keine Gesichtserkennung.
											Jetzt kann KI falsche Gesichter erzeugen
											und Ihr Gesicht vortäuschen lassen,
Dinge zu sagen, die Sie nie sagten.
											Vor nicht langer Zeit
											konnte KI uns nicht im Go-Spiel schlagen.
											Dann nahm AlphaZero von Google DeepMind

											3.000 Jahre menschlicher Go-Spiele
und Go-Weisheit, ignorierte alles
											und wurde zum weltweit besten Spieler,
indem es nur gegen sich selbst spielte.
											Das beeindruckendste Kunststück war nicht,
dass es menschliche Spieler schlug;
											sondern auch die menschlichen KI-Forscher,
											die jahrzehntelang an Go-Software
gearbeitet hatten.
											AlphaZero hat die KI-Forscher nicht nur
in Go, sondern auch im Schach geschlagen,
											an dem wir schon seit 1950 arbeiteten.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											So all this amazing recent progress in AI
really begs the question:
											How far will it go?
											I like to think about this question
											in terms of this abstract
landscape of tasks,
											where the elevation represents
how hard it is for AI to do each task
											at human level,
											and the sea level represents
what AI can do today.
											The sea level is rising
as AI improves,
											so there's a kind of global warming
going on here in the task landscape.
											And the obvious takeaway
is to avoid careers at the waterfront —
									","
											Yapay zekâda son zamanlardaki inanılmaz
ilerleme gerçekten şu soruyu ortaya atıyor
											Ne kadar ileriye gidecek?
											Bu soruyu yer şekillerinin

											görevleri temsil ettiği soyut bir alan 
olarak düşünmenizi istiyorum;
											rakım, her bir görevi insanlarla 
aynı seviyede yapmanın yapay zekâ için
											ne kadar zor olduğunu,
											deniz seviyesi ise yapay zekânın 
bugün yapabildiklerini gösteriyor.
											Yapay zekâ geliştikçe
deniz seviyesi yükseliyor
											yani bu görev alanında 
bir tür küresel ısınma gerçekleşiyor.
											Buradaki ana fikir deniz kıyısındaki
kariyerlerden kaçınmamız —
									","
											Alle diese erstaunlichen Fortschritte
in der KI werfen die Frage auf:
											Wie weit wird das gehen?
											Ich denke gerne über diese Frage anhand
dieser abstrakten Aufgabenlandschaft nach.
											Die Höhe stellt dar,
wie schwer es für KI ist,
											etwas auf menschlichem Niveau zu tun,
											und der Meeresspiegel repräsentiert,
was die KI heute kann.
											Der Wasserstand steigt mit wachsender KI,
											sodass es in der Aufgabenlandschaft
zu einer Art globaler Erwärmung kommt.
											Die offensichtliche Lehre ist,
Jobs am Wasser zu vermeiden —
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Laughter)
									","
											(Kahkaha)
									","
											(Lachen)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											which will soon be
automated and disrupted.
											But there's a much
bigger question as well.
											How high will the water end up rising?
											Will it eventually rise
to flood everything,
											matching human intelligence at all tasks.
											This is the definition
of artificial general intelligence —
											AGI,
											which has been the holy grail
of AI research since its inception.
											By this definition, people who say,
											""Ah, there will always be jobs
that humans can do better than machines,""
											are simply saying
that we'll never get AGI.
											Sure, we might still choose
to have some human jobs
											or to give humans income
and purpose with our jobs,
											but AGI will in any case
transform life as we know it
											with humans no longer being
the most intelligent.
											Now, if the water level does reach AGI,
											then further AI progress will be driven
mainly not by humans but by AI,
											which means that there's a possibility
											that further AI progress
could be way faster
											than the typical human research
and development timescale of years,
											raising the controversial possibility
of an intelligence explosion
											where recursively self-improving AI
											rapidly leaves human
intelligence far behind,
											creating what's known
as superintelligence.
									","
											yakında otomatikleştirilip
dağıtılacak.
											Ama ortada daha büyük
bir soru var.
											Su daha ne kadar yükselecek?
											Sonunda her şeyi 
sular altında mı bırakacak,
											insan zekâsıyla her görevde 
eşit bir seviyeye gelerek.
											İşte bu genel yapay zekânın tanımı —
											GYZ, başlangıçtan bu yana
											yapay zekâ araştırmalarının nihai 
ve ulaşılması neredeyse imkânsız hedefi.
											Bu tanım ile
											""Her zaman insanların makinelerden 
daha iyi yapabileceği işler olacak""
											diyen insanlar, hiçbir zaman GYZ'ye
ulaşamayacağımızı söylüyorlar.
											Tabii hâlâ beşeri bir iş seçebiliriz
											veya insanlar işlerimizle
maaş alabilir ya da amaç edinebilirler
											ama ne olursa olsun GYZ 
alışageldiğimiz hayatı değiştirecek
											ve artık insanlar en zeki olmayacak.
											Eğer GYZ deniz seviyesine ulaşırsa
yapay zekânın ilerleme süreci
											ağırlıklı olarak insanlar tarafından değil
yapay zekâ tarafından yönlendirilecek
											ve bu demektir ki bir ihtimal
											yapay zekâ yıllardır süregelen
insana özgü araştırma ve geliştirme
											zaman ölçeğinden
çok daha hızlı gelişebilir.
											Bununla birlikte tartışmalı
zekâ patlaması ihtimali yükseliyor,
											kendini geliştiren yapay zekâ
											insan zekâsını hızla mazide bırakarak
											süper zekâ olarak bilinen şeyi yaratıyor.
									","
											da die bald automatisiert werden.
											Aber es gibt auch eine viel größere Frage.
											Wie hoch wird das Wasser am Ende steigen?
											Wird es irgendwann alles fluten,
											menschliche Intelligenz
überall übertreffen?
											Dies ist die Definition
der Allgemeinen Künstlichen Intelligenz —
											AKI, die von Anfang an
der heilige Gral der KI-Forschung war.
											Demnach bedeutet die Aussage:
											""Es wird immer Jobs geben,
die Menschen besser als Maschinen machen"",
											einfach, dass wir AKI
niemals bekommen werden.
											Wir könnten uns zwar entscheiden,
einige Jobs für Menschen zu behalten,
											um Menschen Einkommen und Ziele zu geben,
											aber AKI wird auf jeden Fall das Leben,
wie wir es kennen, verändern,
											wenn der Mensch
nicht mehr intelligenter ist.
											Erreicht der Wasserspiegel AKI,
											dann treibt KI und nicht Menschen
den weiteren KI-Fortschritt voran,
											was bedeutet, dass weiterer KI-Fortschritt
wesentlich schneller sein könnte
											als der typische menschliche
Entwicklungszeitraum von Jahren,
											was die umstrittene Möglichkeit
einer Intelligenzexplosion eröffnet,
											in der sich rekursiv selbstverbessernde KI
											die menschliche Intelligenz
weit hinter sich lässt
											und so die sogenannte
Superintelligenz schafft.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											Alright, reality check:
											Are we going to get AGI any time soon?
											Some famous AI researchers,
like Rodney Brooks,
											think it won't happen
for hundreds of years.
											But others, like Google DeepMind
founder Demis Hassabis,
											are more optimistic
											and are working to try to make
it happen much sooner.
											And recent surveys have shown
that most AI researchers
											actually share Demis's optimism,
											expecting that we will
get AGI within decades,
											so within the lifetime of many of us,
											which begs the question — and then what?
											What do we want the role of humans to be
											if machines can do everything better
and cheaper than us?
									","
											Tamam, gerçeğe dönelim:
											Yakın zamanda GYZ olacak mı?
											Bazı ünlü yapay zekâ araştırmacıları,
Rodney Brooks gibi,
											bunun yüzlerce yıl daha
gerçekleşmeyeceğini düşünüyor.
											Ama başkaları, Google DeepMind
kurucusu Demis Hassabis gibi,
											daha olumlu bakıyorlar
											ve daha erken
olması için çalışıyorlar.
											En son yapılan anketlere göre
yapay zekâ araştırmacılarının çoğunluğu
											Demis'in iyimserliğini paylaşıyor,
											beklenti o ki, GYZ 
birkaç on yıl içerisinde ortaya çıkacak
											yani birçoğumuz hâlen hayattayken,
											bu da akıllara şu soruyu getiriyor
— peki ya sonra?
											İnsanın rolü ne olmalı,
											eğer makineler her şeyi bizden daha iyi
ve daha ucuza yapabiliyorsa?
									","
											Okay, die Fakten:
											Werden wir in naher Zukunft AKI bekommen?
											Einige berühmte KI-Forscher,
wie Rodney Brooks, glauben,
											dass es für Hunderte von Jahren
nicht passieren wird.
											Andere wie Demis Hassabis,
der Google DeepMind-Gründer,
											sind da optimistischer
											und arbeiten daran,
es viel früher zu verwirklichen.
											Neuere Umfragen haben gezeigt,
dass die meisten KI-Forscher
											tatsächlich Demis' Optimismus teilen
											und erwarten, dass wir AKI innerhalb
von Jahrzehnten bekommen werden,
											also im Laufe der Lebenszeit
von vielen von uns,
											was die Frage aufwirft — und was dann?
											Was soll die Rolle des Menschen sein,
											wenn Maschinen alles besser
und billiger machen können als wir?
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											The way I see it, we face a choice.
											One option is to be complacent.
											We can say, ""Oh, let's just build machines
that can do everything we can do
											and not worry about the consequences.
											Come on, if we build technology
that makes all humans obsolete,
											what could possibly go wrong?""
									","
											Bence bir tercih yapmalıyız.
											İlk seçenek, ilgisiz kalmak.
											Diyebiliriz ki, ""Bizim yapabildiklerimizi
yapabilen makineler geliştirelim
											ve sonuçlarını düşünmeyelim.
											Hadi ama, teknoloji biz insanları
işe yaramaz bir yığına dönüştürüyorsa
											sorun bunun neresinde?
									","
											Ich denke, wir stehen vor einer Wahl.
											Eine Option ist, selbstgefällig zu sein:
											""Lasst uns KI bauen,
die alles kann, was wir können,
											und uns nicht um die Folgen kümmern.
											Wenn wir Technologie schaffen,
die alle Menschen obsolet macht,
											was könnte da schon schiefgehen?""
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Laughter)
									","
											(Kahkaha)
									","
											(Lachen)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											But I think that would be
embarrassingly lame.
											I think we should be more ambitious —
in the spirit of TED.
											Let's envision a truly inspiring
high-tech future
											and try to steer towards it.
											This brings us to the second part
of our rocket metaphor: the steering.
											We're making AI more powerful,
											but how can we steer towards a future
											where AI helps humanity flourish
rather than flounder?
											To help with this,
											I cofounded the Future of Life Institute.
											It's a small nonprofit promoting
beneficial technology use,
											and our goal is simply
for the future of life to exist
											and to be as inspiring as possible.
											You know, I love technology.
											Technology is why today
is better than the Stone Age.
											And I'm optimistic that we can create
a really inspiring high-tech future ...
											if — and this is a big if —
											if we win the wisdom race —
											the race between the growing
power of our technology
											and the growing wisdom
with which we manage it.
											But this is going to require
a change of strategy
											because our old strategy
has been learning from mistakes.
											We invented fire,
											screwed up a bunch of times —
											invented the fire extinguisher.
									","
											Ama bence bu utandırıcı bir şekilde
saçma olur.
											Bence daha hırslı olmalıyız —
TED'i örnek alarak.
											Gerçekten ilham veren yüksek
teknolojili bir gelecek hayal edip
											ona doğru yönelmeyi deneyelim.
											Bu bizi roket metaforunun ikinci
bölümüne getiriyor: yönlendirme.
											Biz yapay zekâyı daha güçlü yapıyoruz
											ama nasıl bir geleceğe doğru 
yönlendirelim ki
											YZ insanlığın ilerlemesine
yardım etsin, bocalamasından ziyade?
											Buna yardım etmek için
											Yaşamın Geleceği Enstitüsünü kurduk,
											küçük, kâr amacı olmayan,
faydalı teknoloji kullanımını
											destekleyen... Amacımız sadece
yaşamın geleceğinin var olması
											ve bunun mümkün olduğunca 
ilham verici olması.
											Ben teknolojiyi seviyorum biliyorsunuz.
											Bugünün taş devrinden
daha iyi olması teknoloji sayesinde.
											Gerçekten ilham verici yüksek teknolojili
bir gelecek yaratabileceğimize inanıyorum,
											eğer — ve bu büyük bir eğer —
											eğer akıl yarışını kazanırsak —
											ki bu yarış, teknolojimizin büyüyen gücü

											ve onu yöneten aklın gelişen 
bilgeliği arasında.
											Ama bunun için stratejinin
değişmesi gerekiyor
											çünkü eski stratejimiz
hatalardan ders çıkarıyor.
											Ateşi keşfettik,
											birkaç kere çuvalladık —
											yangın tüpünü icat ettik.
									","
											Aber das wäre peinlich faul.
											Wir sollten im Geiste von TED
ehrgeiziger sein.
											Stellen wir uns eine wahrhaft
inspirierende Hightech-Zukunft vor
											und versuchen, dahin zu steuern.
											Das bringt uns zum zweiten Teil
unserer Raketenmetapher: die Lenkung.
											Wir machen die KI leistungsfähiger,
											aber wie können wir
in eine Zukunft steuern,
											wo KI der Menschheit hilft zu florieren,
anstatt sich abzumühen?
											Das Future of Life Institute
habe ich dazu mitgegründet.
											Ein gemeinnütziges Unternehmen
											zur Förderung nutzbringender Technik.
											Unser Ziel ist einfach, für die Zukunft
des Lebens fortzubestehen
											und so inspirierend wie möglich zu sein.
											Ich liebe nämlich Technologie.
											Technologie ist der Grund, warum
das Heute besser als die Steinzeit ist.
											Ich bin optimistisch, dass wir eine
inspirierende Zukunft schaffen können,
											wenn — und das ist ein großes wenn —
											wir das Weisheitsrennen gewinnen —
											den Wettlauf zwischen unserer Technologie
mit ihrer zunehmenden Macht
											und der zunehmenden Klugheit,
sie zu managen.
											Aber das erfordert eine neue Strategie,
											weil unsere alte Strategie war,
aus Fehlern zu lernen.
											Wir haben das Feuer erfunden,
											vermasselten es einige Male —
											und erfanden den Feuerlöscher.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Laughter)
									","
											(Kahkaha)
									","
											(Lachen)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											We invented the car,
screwed up a bunch of times —
											invented the traffic light,
the seat belt and the airbag,
											but with more powerful technology
like nuclear weapons and AGI,
											learning from mistakes
is a lousy strategy,
											don't you think?
									","
											Arabayı icat ettik,
birkaç kere çuvalladık —
											trafik ışıklarını, emniyet kemerini
ve hava yastığını icat ettik
											ama daha güçlü teknolojiyle,
nükleer silah ve GYZ gibi
											hatalardan öğrenmek
kötü bir strateji,
											öyle değil mi?
									","
											Wir erfanden das Auto,
vermasselten es einige Male —
											und erfanden die Ampel,
den Sicherheitsgurt und den Airbag.
											Aber mit mächtigeren Technologien
wie Atomwaffen und AKI
											ist das Lernen aus Fehlern
eine lausige Strategie, finden Sie nicht?
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Laughter)
									","
											(Kahkaha)
									","
											(Lachen)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											It's much better to be proactive
rather than reactive;
											plan ahead and get things
right the first time
											because that might be
the only time we'll get.
											But it is funny because
sometimes people tell me,
											""Max, shhh, don't talk like that.
											That's Luddite scaremongering.""
											But it's not scaremongering.
											It's what we at MIT
call safety engineering.
											Think about it:
											before NASA launched
the Apollo 11 mission,
											they systematically thought through
everything that could go wrong
											when you put people
on top of explosive fuel tanks
											and launch them somewhere
where no one could help them.
											And there was a lot that could go wrong.
											Was that scaremongering?
											No.
											That's was precisely
the safety engineering
											that ensured the success of the mission,
											and that is precisely the strategy
I think we should take with AGI.
											Think through what can go wrong
to make sure it goes right.
									","
											Önetkin olmak tepkili olmaktan
çok daha iyi;
											ileriye dönük planlayıp ilk seferde
doğru yapmak...
											çünkü bu tek şansımız olabilir.
											Komik bir durum çünkü bazen
insanlar bana diyor ki
											""Max, öyle deme.
											Bu korku tellallığı.""
											Ama korku tellallığı değil bu.
											MIT'de iş güvenliği mühendisliği
olarak adlandırdığımız şey.
											Düşünün:
											NASA Apollo 11 misyonunu
fırlatmadan önce,
											insanları patlayıcı yakıt tanklarının
üstüne koyup
											kimsenin yardım edemeyeceği
bir yere fırlattığında
											ters gidebilecek her şeyi
sistematik olarak düşündüler.
											Ve ters gidecek birçok şey vardı.
											O korku tellallığı mıydı?
											Hayır.
											O tam olarak bu misyonun
											başarısını sağlayan iş güvenliği
											ve bu tam olarak GYZ için
kullanmamız gereken strateji.
											Doğru gitmesini sağlamak için yanlış
gidebilecekleri düşün.
									","
											Es ist viel besser,
proaktiv statt reaktiv zu sein,
											gut zu planen und die Dinge
sofort richtigzumachen,
											weil wir vielleicht
nur eine Chance bekommen.
											Aber es ist lustig, 
manchmal sagen mir Leute:
											""Max, pssst, rede nicht so.
											Das ist technikfeindliche Panikmache.""
											Aber es ist keine Panikmache.
											Das nennen wir am MIT Sicherheitstechnik.
											Bedenken Sie:
											Bevor die NASA Apollo 11 startete,
											durchdachten sie systematisch alles,
was schiefgehen könnte,
											wenn man Menschen
auf explosive Treibstofftanks setzt
											und sie dorthin schießt,
wo ihnen keiner helfen kann.
											Da könnte eine Menge schiefgehen.
											War das Panikmache?
											Nein.
											Das war genau die Sicherheitstechnik,
											die den Erfolg der Mission sicherstellte,
											und genau das ist die Strategie,
die wir bei AKI wählen sollten.
											Durchdenken, was schiefgehen kann,
um sicherzustellen, dass es gut verläuft.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											So in this spirit,
we've organized conferences,
											bringing together leading
AI researchers and other thinkers
											to discuss how to grow this wisdom
we need to keep AI beneficial.
											Our last conference
was in Asilomar, California last year
											and produced this list of 23 principles
											which have since been signed
by over 1,000 AI researchers
											and key industry leaders,
											and I want to tell you
about three of these principles.
									","
											Bunun için 
en iyi, yapay zekâ araştırmacılarını
											ve diğer düşünürleri bir araya getirip
YZ'yi faydalı tutmak için ihtiyacımız olan
											akıl nasıl büyür diye konuşmak için
konferanslar düzenledik.
											En son konferansımız geçen sene
Asilomar, Kaliforniya'daydı
											ve orada 23 maddeden oluşan 
bir liste yapıldı,
											şu ana dek binden fazla YZ araştırmacısı
ve üst düzey endüstri liderleri
											tarafından imzalandı
											ve size bu maddelerin üçünden
bahsetmek istiyorum.
									","
											In diesem Sinne
organisierten wir Konferenzen,
											an denen führende KI-Forscher
und andere Denker teilnahmen,
											um zu diskutieren, wie wir diese Weisheit
entwickeln, damit die KI nützlich bleibt.
											Unsere letzte Konferenz
in Asilomar, Kalifornien,
											brachte letztes Jahr diese Liste
von 23 Prinzipien hervor,
											die seitdem über 1000 KI-Forscher und
führende Industrielle unterzeichnet haben.
											Ich möchte Ihnen drei
dieser Prinzipien näher bringen.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											One is that we should avoid an arms race
and lethal autonomous weapons.
											The idea here is that any science
can be used for new ways of helping people
											or new ways of harming people.
											For example, biology and chemistry
are much more likely to be used
											for new medicines or new cures
than for new ways of killing people,
											because biologists
and chemists pushed hard —
											and successfully —
											for bans on biological
and chemical weapons.
											And in the same spirit,
											most AI researchers want to stigmatize
and ban lethal autonomous weapons.
											Another Asilomar AI principle
											is that we should mitigate
AI-fueled income inequality.
											I think that if we can grow
the economic pie dramatically with AI
											and we still can't figure out
how to divide this pie
											so that everyone is better off,
											then shame on us.
									","
											Bir, cephane yarışı ve
ölümcül özerk silahları bırakmalıyız.
											Buradaki fikir, her bilim insanlara
yardım etmek ya da zarar vermek için
											kullanılabilir.
											Mesela biyoloji ve kimya insanları
öldürmek için yeni yollar bulmak yerine
											daha çok yeni ilaçlar
ve yeni tedaviler için kullanılır,
											çünkü biyologlar ve kimyagerler

											biyolojik ve kimyasal silahların 
yasaklanması için çok direndiler
											ve başarılı oldular.
											Ve aynı düşünceyle
											çoğu YZ araştırmacısı ölümcül özerk
silahları kınayıp yasaklamak istiyor.
											Başka bir Asilomar yapay zekâ prensibi ise
											yapay zekâ bölümündeki
maaş ayrımcılığını azaltmak.
											Bence biz milli gelir pastasını yapay 
zekâ ile önemli ölçüde büyütebiliyorsak
											ve herkesin durumunun 
daha iyi olması için
											hâlâ bu pastayı nasıl bölüşeceğimizi
çözemiyorsak
											bize yazıklar olsun.
									","
											Eines davon ist, dass wir ein Wettrüsten
und tödliche autonome Waffen vermeiden.
											Jede Wissenschaft kann genutzt werden,
											um Menschen zu helfen
oder auf neue Weise zu schaden.
											Zum Beispiel werden Biologie und Chemie
viel eher für neue Medikamente eingesetzt
											als für neue Arten, Menschen zu töten,
											weil Biologen und Chemiker
unnachgiebig und erfolgreich
											auf Verbote von biologischen
und chemischen Waffen drängten.
											Im gleichen Sinne
wollen die meisten KI-Forscher
											tödliche autonome Waffen
stigmatisieren und verbieten.
											Ein weiteres Asilomar KI-Prinzip besagt,
											dass das KI-bedingte Einkommensgefälle
verringert werden sollte.
											Wenn wir den wirtschaftlichen Kuchen
mit KI dramatisch vergrößern können,
											aber nicht wissen, wie wir den Kuchen
zum Nutzen aller verteilen können,
											dann Schande über uns!
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Applause)
									","
											(Alkış)
									","
											(Beifall)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											Alright, now raise your hand
if your computer has ever crashed.
									","
											Peki, şimdi elinizi kaldırın eğer
bilgisayarınız bir kere bile çöktüyse.
									","
											Okay, jetzt heben Sie die Hand,
wenn Ihr Computer jemals abgestürzt ist.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Laughter)
									","
											(Kahkaha)
									","
											(Lachen)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											Wow, that's a lot of hands.
											Well, then you'll appreciate
this principle
											that we should invest much more
in AI safety research,
											because as we put AI in charge
of even more decisions and infrastructure,
											we need to figure out how to transform
today's buggy and hackable computers
											into robust AI systems
that we can really trust,
											because otherwise,
											all this awesome new technology
can malfunction and harm us,
											or get hacked and be turned against us.
											And this AI safety work
has to include work on AI value alignment,
											because the real threat
from AGI isn't malice,
											like in silly Hollywood movies,
											but competence —
											AGI accomplishing goals
that just aren't aligned with ours.
											For example, when we humans drove
the West African black rhino extinct,
											we didn't do it because we were a bunch
of evil rhinoceros haters, did we?
											We did it because
we were smarter than them
											and our goals weren't aligned with theirs.
											But AGI is by definition smarter than us,
											so to make sure that we don't put
ourselves in the position of those rhinos
											if we create AGI,
											we need to figure out how
to make machines understand our goals,
											adopt our goals and retain our goals.
									","
											Vay be, baya bir kişi.
											O zaman yapay zekâ güvenlik
araştırmalarına
											daha çok para yatırmamız
hoşunuza gider
											çünkü yapay zekâya daha çok karar
ve altyapı sorumluluğu verdikçe
											bugünün sorunlu ve hacklenebilen
bilgisayarları nasıl gerçekten güvenilir
											ve sağlam yapay zekâ sistemlerine dönüşür
çözmemiz lazım
											çünkü aksi hâlde
											bütün bu muhteşem yeni teknoloji
arızalı çalışıp bize zarar verir
											veya hacklenip bize karşı kullanılabilir.
											Ve bu yapay zekâ güvenlik çalışmasının, 
YZ değer sırası çalışmasını içermesi lazım
											çünkü GYZ'den gelen gerçek tehlike
saçma Hollywood filmlerindeki
											kötülük değil
											aksine beceri —
											GYZ'nin bizim hedeflerimizle paralel
olmayan hedeflere ulaşması...
											Mesela biz insanlar Batı Afrika
gergedanının neslini tükettiğimizde
											bunu, onlardan nefret ettiğimiz
için yapmadık, değil mi?
											Onlardan daha akıllı olduğumuz
için yaptık
											ve bizim hedeflerimiz onlarınkine uymadı.
											Ama GYZ doğası gereği bizden daha akıllı
											yani GYZ'yi yaratırken
o gergedanlarla aynı duruma
											düşmemek için
											makinelerin bizim hedeflerimizi
anlamasını, benimsemesini ve sürdürmesini
											nasıl sağlayabileceğimizi çözmeliyiz.
									","
											Wow, das sind viele Hände.
											Dann werden Sie das Prinzip
zu schätzen wissen,
											dass wir viel mehr Forschung in die
KI-Sicherheit stecken sollten.
											Wenn wir die KI immer mehr Entscheidungen
und Infrastruktur steuern lassen,
											müssen wir die heutigen störanfälligen
und hackbaren Computer
											zu robusten Systemen machen,
denen wir vertrauen können,
											denn sonst könnte diese neue
Technologie versagen und uns schaden
											oder gehackt und gegen uns
eingesetzt werden.
											Diese KI-Sicherheitsarbeit muss
die KI-Werte-Ausrichtung beinhalten.
											Die wirkliche Bedrohung
durch AKI ist nicht Bosheit,
											wie in albernen Hollywoodfilmen,
											sondern Befähigung —
											AKI, die Ziele erreicht,
die nicht mit unseren übereinstimmen.
											Zum Beispiel, als wir Menschen das
Spitzmaul-Nashorn ausgerottet haben,
											taten wir das nicht, weil wir
böse Nashorn-Hasser waren, oder?
											Wir taten es, weil wir schlauer waren
											und unsere Ziele nicht zu ihren passten.
											Aber AKI ist definitionsgemäß
schlauer als wir,
											also um sicherzugehen, dass wir nicht
in die Lage dieser Nashörner geraten,
											wenn wir AKI schaffen,
											müssen wir herausfinden, wie wir KI
dazu bringen, unsere Ziele zu verstehen,
											unsere Ziele zu übernehmen
und unsere Ziele beizubehalten.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											And whose goals should these be, anyway?
											Which goals should they be?
									","
											Peki kimin hedefleri olmalı?
											Hangi hedefler olmalı?
									","
											Wessen Ziele sollten das sein?
											Welche Ziele sollten sie haben?
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											This brings us to the third part
of our rocket metaphor: the destination.
											We're making AI more powerful,
											trying to figure out how to steer it,
											but where do we want to go with it?
											This is the elephant in the room
that almost nobody talks about —
											not even here at TED —
											because we're so fixated
on short-term AI challenges.
											Look, our species is trying to build AGI,
											motivated by curiosity and economics,
											but what sort of future society
are we hoping for if we succeed?
											We did an opinion poll on this recently,
											and I was struck to see
											that most people actually
want us to build superintelligence:
											AI that's vastly smarter
than us in all ways.
											What there was the greatest agreement on
was that we should be ambitious
											and help life spread into the cosmos,
											but there was much less agreement
about who or what should be in charge.
											And I was actually quite amused
											to see that there's some some people
who want it to be just machines.
									","
											Bu bizi roket metaforumuzun 
üçüncü bölümüne getiriyor: istikâmet.
											yapay zekâyı daha güçlü yapıp
											nasıl yönlendireceğimizi
çözmeye çalışıyoruz
											ama bununla nereye varmak istiyoruz?
											Bu, burada TED'de
bile konuşulmayan
											görmezden gelinen aşikâr gerçek
											çünkü biz kısa süreli zorlu
yapay zekâ işlerine şartlanmışız.
											Bizim cinsimiz GYZ'yi

											meraktan ve ekonomiden motive olarak
geliştirmeye çalışıyor
											ama gelecekte ne tür bir toplum
başarmayı umuyoruz?
											Geçenlerde bununla ilgili bir
görüş anketi yaptık
											ve çoğu insanın aslında
											süper zekâ, bizden her yönden
çok daha akıllı olan yapay zekâ
											geliştirmemizi istediklerini
görmeme şaşırdım.
											Hemfikir olduğumuz konu azimli olmamız
											ve yaşamın uzaya dağılmasına
yardım etmemiz
											ama kimin veya neyin sorumlu olacağı 
konusunda pek aynı fikirde olamadık.
											Ve aslında oldukça eğlendim
											bazı insanların sadece makinelerin
sorumlu olmasını istediklerini görünce.
									","
											Dies bringt uns zum dritten Teil
unserer Raketenmetapher: das Ziel.
											Wir machen KI leistungsfähiger,
											versuchen herauszufinden,
wie man sie steuert,
											aber wohin wollen wir damit gehen?
											Das ist das offensichtliche Problem,
über das fast niemand spricht —
											nicht einmal hier bei TED —
											weil wir so fixiert sind
auf kurzfristige KI-Herausforderungen.
											Durch Neugier und Wirtschaft motiviert,
											versucht unsere Spezies AKI zu schaffen.
											Aber was für eine zukünftige Gesellschaft
erhoffen wir, falls wir es schaffen?
											Wir machten eine Umfrage
und ich war verblüfft,
											dass die meisten Leute wollen,
dass wir Superintelligenz bauen:
											KI, die in jeder Hinsicht
schlauer ist als wir.
											Die größte Übereinstimmung war,
dass wir ehrgeizig sein sollten
											und helfen, das Leben
im Kosmos zu verbreiten,
											aber es gab weniger Einigkeit darüber,
wer oder was die Macht haben sollte.
											Ich fand es ziemlich lustig,
											dass es einige Leute gibt, die wollen,
dass es nur Maschinen sind.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Laughter)
									","
											(Kahkaha)
									","
											(Lachen)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											And there was total disagreement
about what the role of humans should be,
											even at the most basic level,
											so let's take a closer look
at possible futures
											that we might choose
to steer toward, alright?
									","
											İnsanın rolü hakkında
en basit seviyede bile
											büyük fikir ayrımı vardı.
											Şimdi yönelebileceğimiz
muhtemel geleceklere
											daha yakından bakalım.
									","
											Es gab völlige Uneinigkeit darüber,
was die Rolle des Menschen sein sollte,
											selbst auf der grundlegendsten Ebene.
											Sehen wir uns also
die mögliche Zukunft genauer an,
											auf die wir vielleicht hinsteuern.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											So don't get me wrong here.
											I'm not talking about space travel,
											merely about humanity's
metaphorical journey into the future.
											So one option that some
of my AI colleagues like
											is to build superintelligence
and keep it under human control,
											like an enslaved god,
											disconnected from the internet
											and used to create unimaginable
technology and wealth
											for whoever controls it.
											But Lord Acton warned us
											that power corrupts,
and absolute power corrupts absolutely,
											so you might worry that maybe
we humans just aren't smart enough,
											or wise enough rather,
											to handle this much power.
											Also, aside from any
moral qualms you might have
											about enslaving superior minds,
											you might worry that maybe
the superintelligence could outsmart us,
											break out and take over.
											But I also have colleagues
who are fine with AI taking over
											and even causing human extinction,
											as long as we feel the the AIs
are our worthy descendants,
											like our children.
											But how would we know that the AIs
have adopted our best values
											and aren't just unconscious zombies
tricking us into anthropomorphizing them?
											Also, shouldn't those people
who don't want human extinction
											have a say in the matter, too?
											Now, if you didn't like either
of those two high-tech options,
											it's important to remember
that low-tech is suicide
											from a cosmic perspective,
											because if we don't go far
beyond today's technology,
											the question isn't whether humanity
is going to go extinct,
											merely whether
we're going to get taken out
											by the next killer asteroid, supervolcano
											or some other problem
that better technology could have solved.
									","
											Beni yanlış anlamayın.
											Uzay yolculuğundan değil,
											sadece insanlığın geleceğe
mecazi yolculuğundan bahsediyorum.
											YZ iş arkadaşlarımın beğendiği
bir seçenek, esir edilmiş bir tanrı gibi
											internet bağlantısı kesilmiş
ve onu kontrol eden için
											akıl almaz teknoloji
											ve zenginlik getiren
											süper zekâ geliştirip onu
insan denetiminin
											altında tutmak.
											Ama Acton efendi bizi uyardı;
											güç bozar ve sınırsız güç
mutlaka bozar.
											O yüzden insanların yeteri kadar zeki,
daha doğrusu bilgili olmadıklarından
											bu kadar güçle başa çıkmak için,
											endişe edebilirsiniz.
											Üstün akılları esir almakla ilgili
											her ahlaki şüphenin yanında
											süper zekânın belki bizi
zekâsıyla yenip zincirlerini kırıp
											yönetimi ele geçirebileceğinden
endişe edebilirsiniz.
											Ama yapay zekânın yönetimi ele geçirmesine
ve insanın neslinin tükenmesine
											kafa yormayan iş arkadaşlarım var,
											yeter ki yapay zekânın gelecekteki
kıymetli kuşağımız olduğunu hissedelim,
											çocuklarımız gibi.
											Ama nasıl bilebiliriz ki, yapay zekâların
en iyi değerlerimizi benimseyip
											sadece bilinçsiz zombiler olup bizi onları
insanlaştırmak için kandırmadıklarını?
											İnsan neslinin tükenmesini istemeyen
insanların da
											bunda söz hakkı olması gerekmiyor mu?
											Bu iki yüksek teknoloji opsiyonunu
beğenmediyseniz
											uzay açısından düşük teknolojinin
intihar olduğunu
											hatırlamak önemli,
											çünkü bugünkü teknolojinin
çok ilerisine gitmezsek
											soru insanlığın tükeneceği
değil
											ancak daha iyi teknolojinin
çözebileceği
											bir sonraki katil asteroitin,
											yanardağın veya başka sorunun
bizi yok etmesi.
									","
											Verstehen Sie mich nicht falsch,
ich spreche nicht über Raumfahrt.
											Sondern nur über die metaphorische Reise
der Menschheit in die Zukunft.
											Eine Möglichkeit,
die einige meiner KI-Kollegen mögen,
											ist Superintelligenz zu bauen
und unter menschlicher Kontrolle zu halten
											wie einen versklavten,
vom Internet getrennten Gott,
											und sie einzusetzen, um unvorstellbare
Technologien und Reichtum
											für den zu schaffen, der sie kontrolliert.
											Aber Lord Acton warnte uns,
											dass Macht korrumpiert und
absolute Macht absolut korrumpiert,
											also könnte man befürchten,
dass wir Menschen vielleicht nicht klug
											oder vielmehr weise genug sind,
											um mit so viel Macht umzugehen.
											Abgesehen von allen moralischen Problemen,
											die Sie vielleicht
mit versklavten Göttern haben,
											könnten Sie befürchten, dass
die Superintelligenz uns austrickst,
											ausbricht und die Macht übernimmt.
											Aber ich habe auch Kollegen,
die eine Übernahme durch KI gut fänden,
											selbst wenn sie
zu unserer Ausrottung führt,
											solange wir glauben, dass die KIs
unsere würdigen Nachkommen sind,
											wie unsere Kinder.
											Aber wie können wir wissen,
dass die KIs unsere Werte angenommen haben
											und nicht nur dumme Zombies sind,
die uns Menschlichkeit vorspiegeln?
											Sollten nicht auch jene Menschen
ein Mitspracherecht haben,
											die keine menschliche Auslöschung wollen?
											Wenn Sie keine dieser
beiden High-Tech-Optionen mögen,
											sollten Sie bedenken, dass Low-Tech
aus kosmischer Sicht Selbstmord ist.
											Wenn unsere Technologien
nicht viel besser werden,
											ist das Aussterben
der Menschheit keine Frage,
											sondern nur, ob wir durch den nächsten
Killer-Asteroiden, Supervulkan,
											oder etwas anderes sterben,
das bessere Technologie lösen könnte.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											So, how about having
our cake and eating it ...
											with AGI that's not enslaved
											but treats us well because its values
are aligned with ours?
											This is the gist of what Eliezer Yudkowsky
has called ""friendly AI,""
											and if we can do this,
it could be awesome.
											It could not only eliminate negative
experiences like disease, poverty,
											crime and other suffering,
											but it could also give us
the freedom to choose
											from a fantastic new diversity
of positive experiences —
											basically making us
the masters of our own destiny.
									","
											Peki, değerlerimiz uyumlu olduğu için
bize iyi davranan
											köleleştirilmemiş genel yapay zekâ ile
											oturup pasta yemeye ne dersiniz?
											Bu Eliezer Yudkowsky'nin ""samimi 
yapay zekâ ''dediği ana fikir
											ve bunu yapabilirsek
mükemmel olur.
											Sadece hastalık, fakirlik, suç
ve başka işkenceler gibi kötü tecrübeleri
											yok etmekle kalmaz,
											aynı zamanda müthiş çeşitlilikte 
pozitif tecrübeleri
											seçme özgürlüğünü verir —
											bizi kendi kaderimizin efendisi
yaparak.
									","
											Wie wäre es, beides gleichzeitig zu haben?
											Eine AKI, die nicht versklavt ist,
											sondern uns gut behandelt,
weil ihre Werte zu unseren passen?
											Das ist der Kern dessen, was
Eliezer Yudkowsky ""freundliche KI"" nannte
											und wenn wir das schaffen,
wäre es wunderbar.
											Es könnte nicht nur negative Erfahrungen

											wie Krankheit, Armut, Kriminalität
und andere Leiden beseitigen,
											sondern es könnte uns auch
die Freiheit geben,
											aus einer fantastischen neuen Vielfalt
positiver Erfahrungen zu wählen.
											Das würde uns zu Herren
unseres eigenen Schicksals machen.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											So in summary,
											our situation with technology
is complicated,
											but the big picture is rather simple.
											Most AI researchers
expect AGI within decades,
											and if we just bumble
into this unprepared,
											it will probably be
the biggest mistake in human history —
											let's face it.
											It could enable brutal,
global dictatorship
											with unprecedented inequality,
surveillance and suffering,
											and maybe even human extinction.
											But if we steer carefully,
											we could end up in a fantastic future
where everybody's better off:
											the poor are richer, the rich are richer,
											everybody is healthy
and free to live out their dreams.
									","
											Özet olarak
											teknolojiyle olan durumumuz karışık
											ama büyük resim oldukça basit.
											Çoğu yapay zekâ araştırmacısı
GYZ'yi birkaç on yıl içinde bekliyor
											ve biz buna hazırlıksız girişirsek
											bu muhtemelen insanlık tarihinin
en büyük hatası olur —
											gerçekçi olmak gerekirse.
											Eşi görülmemiş eşitsizlikle
acımasız diktatörlük,
											gözetim ve işkence, hatta belki
insan neslinin tükenmesine
											yol açabilir.
											Ama dikkatlice yönelirsek
											herkesin çok daha iyi durumda olduğu
müthiş bir geleceğe varabiliriz:
											fakir daha zengin, zengin daha zengin,
											herkes sağlıklı
ve hayallerini gerçekleştirmekte özgür.
									","
											Alles in allem ist unsere Situation
mit der Technologie kompliziert,
											aber das große Bild ist ziemlich einfach.
											Die meisten KI-Forscher
erwarten AKI innerhalb von Jahrzehnten,
											und stolpern wir da unvorbereitet hinein,
											wäre dies wohl der größte Fehler
in der Geschichte der Menschheit,
											wenn wir ehrlich sind.
											Es könnte eine brutale, globale Diktatur
											mit beispielloser Ungleichheit,
Überwachung und Leid ermöglichen
											und vielleicht sogar
das Aussterben der Menschen.
											Aber wenn wir vorsichtig steuern,
											könnten wir eine Zukunft haben,
in der es allen besser geht:
											die Armen sind reicher,
die Reichen sind reicher.
											Jeder ist gesund und frei,
seine Träume zu leben.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											Now, hang on.
											Do you folks want the future
that's politically right or left?
											Do you want the pious society
with strict moral rules,
											or do you an hedonistic free-for-all,
											more like Burning Man 24/7?
											Do you want beautiful beaches,
forests and lakes,
											or would you prefer to rearrange
some of those atoms with the computers,
											enabling virtual experiences?
											With friendly AI, we could simply
build all of these societies
											and give people the freedom
to choose which one they want to live in
											because we would no longer
be limited by our intelligence,
											merely by the laws of physics.
											So the resources and space
for this would be astronomical —
											literally.
									","
											Şimdi durun.
											Sizler sağcı mı solcu mu
bir gelecek istiyorsunuz?
											Sıkı ahlaki kuralları olan
muhafazakâr mı
											ya da 7/24 Burning Man gibi
hedonistik
											herkese bedava toplum mu istiyorsunuz?
											Güzel plajlar, ormanlar ve göller mi
istersiniz
											yoksa sanal tecrübe sağlayarak
bu atomların birkaçını
											bilgisayarla düzeltmek mi?
											Samimi yapay zekâ ile kolaylıkla
bu toplumları geliştirip
											insanlara yaşamak istedikleri yeri
seçme özgürlüğünü verebiliriz
											çünkü artık zekâmızla değil,
sadece fizik kurallarıyla
											sınırlanacağız.
											Bunun için kaynaklar ve mekân
											aşırı büyük olur.
									","
											Warten Sie mal.
											Wollen Sie eine Zukunft haben,
die politisch rechts oder links ist?
											Wollen Sie die fromme Gesellschaft
mit strengen moralischen Regeln,
											oder eine hedonistische Anarchie,
											mehr wie Burning Man rund um die Uhr?
											Wollen Sie schöne Strände,
Wälder und Seen,
											oder wollen Sie lieber
mit Computern Atome neu ordnen,
											um virtuelle Erfahrungen zu machen?
											Mit freundlicher KI könnten wir
all diese Gesellschaften aufbauen
											und die Menschen wählen lassen,
wie ​​sie leben wollen,
											weil wir nicht mehr durch
unsere Intelligenz limitiert wären,
											sondern nur noch durch die Physik.
											So wären die Ressourcen
und der Raum dafür astronomisch —
											buchstäblich.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											So here's our choice.
											We can either be complacent
about our future,
											taking as an article of blind faith
											that any new technology
is guaranteed to be beneficial,
											and just repeat that to ourselves
as a mantra over and over and over again
											as we drift like a rudderless ship
towards our own obsolescence.
											Or we can be ambitious —
											thinking hard about how
to steer our technology
											and where we want to go with it
											to create the age of amazement.
											We're all here to celebrate
the age of amazement,
											and I feel that its essence should lie
in becoming not overpowered
											but empowered by our technology.
									","
											Seçeneklerimiz şunlar;
											ya geleceğimizle ilgili
kayıtsız kalırız,
											her yeni teknolojinin kârlı
olacağına körü körüne inanıp
											bunu mantra olarak
											dümensiz bir gemi gibi
kendi eskimemize doğru yönelirken,
											kendimize sürekli
tekrarlayabiliriz.
											Ya da hırslı olabiliriz —
											teknolojimizi nasıl yönlendireceğimizi

											ve nereye varmak istediğimizi 
iyice düşünerek
											muhteşem çağı geliştirmek için.
											Hepimiz muhteşem çağı kutlamak
için buradayız
											ve hissediyorum ki özünde
ona boyun eğmek değil
											teknolojimizle güçlenmek var.
									","
											Also, wir haben die Wahl.
											Wir können entweder selbstgefällig
hinsichtlich unserer Zukunft sein,
											in dem blindem Glauben,
											dass jede neue Technologie
garantiert von Nutzen ist,
											und das einfach als ein Mantra
immer und immer wiederholen,
											während wir wie ein Schiff ohne Ruder
auf unsere Überflüssigkeit zutreiben.
											Oder wir können ehrgeizig sein —
											und darüber nachdenken,
wie wir unsere Technologie steuern
											und wohin wir gehen wollen,
											um das Zeitalter des Staunens zu schaffen.
											Wir sind alle hier, um das Zeitalter
des Staunens zu feiern,
											und ich meine, das Wesentliche dabei
sollte sein, nicht überwältigt zu werden,
											sondern durch unsere Technologie
gestärkt zu werden.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											Thank you.
									","
											Teşekkürler.
									","
											Vielen Dank.
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
											(Applause)
									","
											(Alkış)
									","
											(Beifall)
									","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
"
","
","
","How to get empowered, not overpowered, by AI",Max Tegmark,17:15,"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers"
